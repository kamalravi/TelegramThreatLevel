{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b295be7-c667-40bc-8f00-3aba590f0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from natsort import natsorted\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8bc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import friedmanchisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b9e64b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9500000000000028 0.58284897105255\n"
     ]
    }
   ],
   "source": [
    "# Performance data from the table for 5 models and 4 metrics (Accuracy, Precision, Recall, F1)\n",
    "# Models: [LightGBM, fastText, Pretrained GPT-2, Pretrained RoBERTa, RoBERTa with Additional Pretraining]\n",
    "# Metrics order: Accuracy, Precision, Recall, F1\n",
    "data = np.array([\n",
    "    [73.91, 75.57, 73.91, 74.13],   # LightGBM\n",
    "    [75.86, 76.44, 75.90, 76.04],   # fastText\n",
    "    [81.07, 81.07, 81.07, 81.05],   # Pretrained GPT-2\n",
    "    [90.00, 89.98, 90.00, 89.97],   # Pretrained RoBERTa\n",
    "    [90.28, 90.27, 90.27, 90.27]    # Pretrained RoBERTa with Additional Pretraining\n",
    "])\n",
    "\n",
    "# Run the Friedman test\n",
    "stat, p_value = friedmanchisquare(data[:, 0], data[:, 1], data[:, 2], data[:, 3])\n",
    "print(stat, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "983b5c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9500000000000028 0.58284897105255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# Performance data\n",
    "data = np.array([\n",
    "    [73.91, 75.57, 73.91, 74.13],   # LightGBM\n",
    "    [75.86, 76.44, 75.90, 76.04],   # fastText\n",
    "    [81.07, 81.07, 81.07, 81.05],   # Pretrained GPT-2\n",
    "    [90.00, 89.98, 90.00, 89.97],   # Pretrained RoBERTa\n",
    "    [90.28, 90.27, 90.27, 90.27]    # Pretrained RoBERTa with Additional Pretraining\n",
    "])\n",
    "\n",
    "# Extract F1 scores (last column)\n",
    "f1_scores = data[:, 3]\n",
    "\n",
    "# Since you need to compare across models, we need to reshape data to fit Friedman test format\n",
    "f1_data = data[:, [0, 1, 2, 3]].T  # Transpose to have models in rows\n",
    "\n",
    "# Run the Friedman test\n",
    "stat, p_value = friedmanchisquare(*f1_data)\n",
    "\n",
    "print(stat, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d4646b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         2         3         4         5\n",
      "1  1.000000  0.995321  0.938448  0.772482  0.524931\n",
      "2  0.995321  1.000000  0.995321  0.938448  0.772482\n",
      "3  0.938448  0.995321  1.000000  0.995321  0.938448\n",
      "4  0.772482  0.938448  0.995321  1.000000  0.995321\n",
      "5  0.524931  0.772482  0.938448  0.995321  1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scikit_posthocs import posthoc_nemenyi\n",
    "\n",
    "# F1 scores data for each model\n",
    "data = np.array([\n",
    "    [74.13],  # LightGBM\n",
    "    [76.04],  # fastText\n",
    "    [81.05],  # Pretrained GPT-2\n",
    "    [89.97],  # Pretrained RoBERTa\n",
    "    [90.27]   # Pretrained RoBERTa with Additional Pretraining\n",
    "]).T  # Transpose to fit the test format\n",
    "\n",
    "# Run Nemenyi test for pairwise comparisons\n",
    "posthoc_results = posthoc_nemenyi(data.T)  # Transpose back for the post-hoc test\n",
    "\n",
    "print(posthoc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf4b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for Accuracy: [73.91, 75.86, 81.07, 90.0, 90.28]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "at least two inputs are required; got 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     scores \u001b[38;5;241m=\u001b[39m [data[j, i] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]  \u001b[38;5;66;03m# scores for the i-th metric\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScores for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     stat, p \u001b[38;5;241m=\u001b[39m \u001b[43mf_oneway\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Unpack the list correctly\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     anova_results[metric] \u001b[38;5;241m=\u001b[39m (stat, p)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(anova_results)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers/lib/python3.10/site-packages/scipy/stats/stats.py:3604\u001b[0m, in \u001b[0;36mf_oneway\u001b[0;34m(axis, *args)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;124;03m\"\"\"Perform one-way ANOVA.\u001b[39;00m\n\u001b[1;32m   3477\u001b[0m \n\u001b[1;32m   3478\u001b[0m \u001b[38;5;124;03mThe one-way ANOVA tests the null hypothesis that two or more groups have\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3601\u001b[0m \n\u001b[1;32m   3602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 3604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least two inputs are required; got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3606\u001b[0m args \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(arg, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m   3608\u001b[0m \u001b[38;5;66;03m# ANOVA on N groups, each in its own array\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: at least two inputs are required; got 1."
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    scores = [data[j, i] for j in range(data.shape[0])]  # scores for the i-th metric\n",
    "    print(f\"Scores for {metric}: {scores}\")\n",
    "    stat, p = f_oneway(*([scores]))  # Unpack the list correctly\n",
    "    anova_results[metric] = (stat, p)\n",
    "\n",
    "print(anova_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a341e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (5, 4), indices imply (5, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for each metric\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Melt the DataFrame for Tukey's test\u001b[39;00m\n\u001b[1;32m     12\u001b[0m df_melted \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmelt(var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, value_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers/lib/python3.10/site-packages/pandas/core/frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    692\u001b[0m         )\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers/lib/python3.10/site-packages/pandas/core/internals/construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    349\u001b[0m )\n\u001b[0;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers/lib/python3.10/site-packages/pandas/core/internals/construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5, 4), indices imply (5, 5)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Convert data to a suitable format\n",
    "model_names = ['LightGBM', 'fastText', 'Pretrained GPT-2', 'Pretrained RoBERTa', 'Pretrained RoBERTa with Additional Pretraining']\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "\n",
    "# Create a DataFrame for each metric\n",
    "df = pd.DataFrame(data, columns=model_names)\n",
    "\n",
    "# Melt the DataFrame for Tukey's test\n",
    "df_melted = df.melt(var_name='Model', value_name='Score')\n",
    "\n",
    "# Perform Tukey's HSD for one metric (e.g., Accuracy)\n",
    "tukey = pairwise_tukeyhsd(df_melted['Score'][df_melted['variable'] == 'Accuracy'], df_melted['Model'][df_melted['variable'] == 'Accuracy'])\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20208b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
