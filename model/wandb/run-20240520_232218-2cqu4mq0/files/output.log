
  0%|                                                                                                            | 0/8800 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/ravi/raviProject/CODE/model/transformersMain.py", line 133, in <module>
    Transformers_train(logger, model_select, model_train, model_type, model_folder)
  File "/home/ravi/raviProject/CODE/model/models/TFs/Transformers_model.py", line 359, in Transformers_train
    trainer.train()
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/trainer.py", line 1422, in train
    tr_loss_step = self.training_step(model, inputs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/trainer.py", line 2011, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/trainer.py", line 2043, in compute_loss
    outputs = model(**inputs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/_utils.py", line 461, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 1209, in forward
    outputs = self.roberta(
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 851, in forward
    encoder_outputs = self.encoder(
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 527, in forward
    layer_outputs = layer_module(
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 413, in forward
    self_attention_outputs = self.attention(
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 340, in forward
    self_outputs = self.self(
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 204, in forward
    mixed_query_layer = self.query(hidden_states)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
/opt/conda/conda-bld/pytorch_1656352630480/work/aten/src/ATen/native/cuda/Loss.cu:271: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.