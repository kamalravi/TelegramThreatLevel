  0%|                                                                                                                                                                   | 0/300 [00:00<?, ?it/s]2024-04-05 01:33:55,426 | Transformers_model.py: 352: compute_loss() | INFO: inputs are
 {'input_ids': tensor([[50256, 50256, 50256, 50256, 50256,    40, 12472,   326,   262,  3071,
          9253,  2058,   284,  1657,  2582,   290, 17586,    82,   262,  2482,
            13,   220,   314,   892,  5689,   290, 12670,  6081,   290,   262,
          1854, 10925,   257,  3621,  2685,    13],
        [50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,    47,  1071,
           320,   287,  7356,   355,   499,    13],
        [ 2437,   318,   257,  1923,  4219,   597,  1180, 10117,   296,   644,
           356,   447,   247,   303,  2982,   379, 22558,   220, 19622,   220,
           220, 28416,  2147,    13,   220,   679, 33930,   284,  2222,   517,
          9975,    13,   220, 18581,   220, 34635],
        [50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 28042,
           428, 31497,   306,   366,  1197,     1,   468,  1682,   587,  5047,
            11,  5169,   290,   318,  3058,   287, 41722,  4146,    11,  1674,
          2188,   262,  2056,   582,   544, 10185]], device='cuda:0'), 'attention_mask': tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}
2024-04-05 01:33:55,426 | Transformers_model.py: 354: compute_loss() | INFO: labels are
 None
2024-04-05 01:33:58,934 | Transformers_model.py: 358: compute_loss() | INFO: logits are
 tensor([[-2.7559, -7.0859, -3.7344],
        [-2.5508, -3.7070, -0.6333],
        [-3.5684, -5.5000, -2.5703],
        [-2.0801, -2.7285, -1.8223]], device='cuda:0', dtype=torch.float16,
       grad_fn=<GatherBackward>)
Traceback (most recent call last):
  File "/home/ravi/raviProject/CODE/model/transformersAWS.py", line 129, in <module>
    Transformers_train(logger, model_select, model_train, model_type, model_folder, train_data)
  File "/home/ravi/raviProject/CODE/model/models/TFs/Transformers_model.py", line 374, in Transformers_train
    trainer.train()
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/trainer.py", line 1422, in train
    tr_loss_step = self.training_step(model, inputs)
  File "/home/ravi/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/trainer.py", line 2011, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/ravi/raviProject/CODE/model/models/TFs/Transformers_model.py", line 361, in compute_loss
    loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))
AttributeError: 'NoneType' object has no attribute 'view'