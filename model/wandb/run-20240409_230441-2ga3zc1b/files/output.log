
  0%|                                                                                                                                                                  | 0/1200 [00:00<?, ?it/s]
  0%|▏                                                                                                                                                       | 1/1200 [00:03<1:12:13,  3.61s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|▏                                                                                                                                                       | 1/1200 [00:04<1:12:13,  3.61s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1/special_tokens_map.json
{'eval_loss': 3.905083179473877, 'eval_f1': 0.2158730158730159, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.932, 'eval_steps_per_second': 5.847, 'epoch': 0.17}
  0%|▎                                                                                                                                                       | 2/1200 [00:08<1:28:52,  4.45s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|▎                                                                                                                                                       | 2/1200 [00:09<1:28:52,  4.45s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-2
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-2/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-2/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-2/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-2/special_tokens_map.json
  0%|▍                                                                                                                                                       | 3/1200 [00:13<1:32:13,  4.62s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-3/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-3/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-3/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-3/special_tokens_map.json
{'eval_loss': 2.7995212078094482, 'eval_f1': 0.24146730462519936, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.529, 'eval_steps_per_second': 5.876, 'epoch': 0.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1] due to args.save_total_limit
  0%|▌                                                                                                                                                       | 4/1200 [00:16<1:18:22,  3.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|▌                                                                                                                                                       | 4/1200 [00:16<1:18:22,  3.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-4
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-4/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-4/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-4/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-4/special_tokens_map.json
{'eval_loss': 2.2272796630859375, 'eval_f1': 0.2327327327327327, 'eval_runtime': 0.5164, 'eval_samples_per_second': 116.181, 'eval_steps_per_second': 5.809, 'epoch': 0.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-2] due to args.save_total_limit
  0%|▋                                                                                                                                                       | 5/1200 [00:19<1:10:20,  3.53s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|▋                                                                                                                                                       | 5/1200 [00:19<1:10:20,  3.53s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-5/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-5/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-5/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-5/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-3] due to args.save_total_limit
{'eval_loss': 1.7821400165557861, 'eval_f1': 0.24394158241052796, 'eval_runtime': 0.5116, 'eval_samples_per_second': 117.275, 'eval_steps_per_second': 5.864, 'epoch': 0.5}
  0%|▊                                                                                                                                                       | 6/1200 [00:22<1:08:47,  3.46s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|▊                                                                                                                                                       | 6/1200 [00:22<1:08:47,  3.46s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-6
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-6/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-6/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-6/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-6/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-4] due to args.save_total_limit
  1%|▉                                                                                                                                                       | 7/1200 [00:25<1:05:20,  3.29s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.13it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-7/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-7/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-7/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-7/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-5] due to args.save_total_limit
{'eval_loss': 1.51157546043396, 'eval_f1': 0.2784722222222223, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.777, 'eval_steps_per_second': 5.889, 'epoch': 0.67}
  1%|█                                                                                                                                                       | 8/1200 [00:28<1:03:05,  3.18s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  1%|█                                                                                                                                                       | 8/1200 [00:28<1:03:05,  3.18s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-8
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-8/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-8/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-8/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-8/special_tokens_map.json
{'eval_loss': 1.548938512802124, 'eval_f1': 0.2657495590828924, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.559, 'eval_steps_per_second': 5.878, 'epoch': 0.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-6] due to args.save_total_limit
  1%|█▏                                                                                                                                                      | 9/1200 [00:31<1:01:10,  3.08s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  1%|█▏                                                                                                                                                      | 9/1200 [00:31<1:01:10,  3.08s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-9
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-9/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-9/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-9/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-9/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-7] due to args.save_total_limit
  1%|█▎                                                                                                                                                       | 10/1200 [00:34<59:54,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.5848233699798584, 'eval_f1': 0.2654761904761905, 'eval_runtime': 0.5191, 'eval_samples_per_second': 115.591, 'eval_steps_per_second': 5.78, 'epoch': 0.83}
  1%|█▎                                                                                                                                                       | 10/1200 [00:34<59:54,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-10
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-10/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-10/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-10/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-10/special_tokens_map.json
{'eval_loss': 1.620739221572876, 'eval_f1': 0.24640634486945961, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.884, 'eval_steps_per_second': 5.844, 'epoch': 0.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-9] due to args.save_total_limit
  1%|█▍                                                                                                                                                       | 11/1200 [00:37<59:07,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  1%|█▍                                                                                                                                                       | 11/1200 [00:37<59:07,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-11
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-11/config.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-10] due to args.save_total_limit
{'eval_loss': 1.6304709911346436, 'eval_f1': 0.278197409231892, 'eval_runtime': 0.5086, 'eval_samples_per_second': 117.972, 'eval_steps_per_second': 5.899, 'epoch': 1.0}
  1%|█▌                                                                                                                                                       | 12/1200 [00:39<58:48,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  1%|█▌                                                                                                                                                       | 12/1200 [00:40<58:48,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-12
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-12/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-12/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-12/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-12/special_tokens_map.json
{'eval_loss': 1.5986597537994385, 'eval_f1': 0.2714278367084539, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.633, 'eval_steps_per_second': 5.882, 'epoch': 1.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-11] due to args.save_total_limit
  1%|█▋                                                                                                                                                       | 13/1200 [00:42<58:12,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  1%|█▋                                                                                                                                                       | 13/1200 [00:43<58:12,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-13
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-13/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-13/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-13/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-13/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-12] due to args.save_total_limit
  1%|█▊                                                                                                                                                       | 14/1200 [00:45<58:10,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-14/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-14/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-14/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-14/special_tokens_map.json
{'eval_loss': 1.4907829761505127, 'eval_f1': 0.24868088130774701, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.676, 'eval_steps_per_second': 5.884, 'epoch': 1.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-13] due to args.save_total_limit
  1%|█▉                                                                                                                                                       | 15/1200 [00:48<58:16,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  1%|█▉                                                                                                                                                       | 15/1200 [00:49<58:16,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-15
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-15/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-15/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-15/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-15/special_tokens_map.json
{'eval_loss': 1.4346768856048584, 'eval_f1': 0.2357085346215781, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.41, 'eval_steps_per_second': 5.871, 'epoch': 1.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-8] due to args.save_total_limit
  1%|██                                                                                                                                                       | 16/1200 [00:51<57:47,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  1%|██                                                                                                                                                       | 16/1200 [00:52<57:47,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-16
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-16/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-16/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-16/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-16/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-14] due to args.save_total_limit
{'eval_loss': 1.396998643875122, 'eval_f1': 0.2016692749087115, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.562, 'eval_steps_per_second': 5.878, 'epoch': 1.42}
  1%|██▏                                                                                                                                                      | 17/1200 [00:54<57:35,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  1%|██▏                                                                                                                                                      | 17/1200 [00:55<57:35,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-17
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-17/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-17/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-17/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-17/special_tokens_map.json
{'eval_loss': 1.3694987297058105, 'eval_f1': 0.2016692749087115, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.12, 'eval_steps_per_second': 5.856, 'epoch': 1.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-15] due to args.save_total_limit
  2%|██▎                                                                                                                                                      | 18/1200 [00:57<57:05,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|██▎                                                                                                                                                      | 18/1200 [00:57<57:05,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-18
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-18/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-18/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-18/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-18/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-16] due to args.save_total_limit
  2%|██▍                                                                                                                                                      | 19/1200 [01:00<57:18,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-19/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-19/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-19/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-19/special_tokens_map.json
{'eval_loss': 1.3462255001068115, 'eval_f1': 0.1995335665500583, 'eval_runtime': 0.5231, 'eval_samples_per_second': 114.701, 'eval_steps_per_second': 5.735, 'epoch': 1.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-17] due to args.save_total_limit
  2%|██▌                                                                                                                                                      | 20/1200 [01:03<57:19,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|██▌                                                                                                                                                      | 20/1200 [01:03<57:19,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-20
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-20/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-20/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-20/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-20/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-18] due to args.save_total_limit
{'eval_loss': 1.347614049911499, 'eval_f1': 0.2411764705882353, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.758, 'eval_steps_per_second': 5.888, 'epoch': 1.75}
  2%|██▋                                                                                                                                                      | 21/1200 [01:06<59:44,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|██▋                                                                                                                                                      | 21/1200 [01:07<59:44,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-21
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-21/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-21/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-21/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-21/special_tokens_map.json
{'eval_loss': 1.357346773147583, 'eval_f1': 0.2685185185185185, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.557, 'eval_steps_per_second': 5.878, 'epoch': 1.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-19] due to args.save_total_limit
  2%|██▊                                                                                                                                                      | 22/1200 [01:09<58:31,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|██▊                                                                                                                                                      | 22/1200 [01:09<58:31,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-22
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-22/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-22/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-22/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-22/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-21] due to args.save_total_limit
{'eval_loss': 1.36195707321167, 'eval_f1': 0.23714884696016772, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.703, 'eval_steps_per_second': 5.885, 'epoch': 1.92}
  2%|██▉                                                                                                                                                      | 23/1200 [01:12<58:34,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|██▉                                                                                                                                                      | 23/1200 [01:12<58:34,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-23
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-23/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-23/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-23/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-23/special_tokens_map.json
{'eval_loss': 1.3693596124649048, 'eval_f1': 0.22485065710872162, 'eval_runtime': 0.5118, 'eval_samples_per_second': 117.233, 'eval_steps_per_second': 5.862, 'epoch': 2.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-22] due to args.save_total_limit
  2%|███                                                                                                                                                      | 24/1200 [01:15<57:54,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|███                                                                                                                                                      | 24/1200 [01:15<57:54,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-24
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-24/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-24/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-24/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-24/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-23] due to args.save_total_limit
  2%|███▏                                                                                                                                                     | 25/1200 [01:18<57:27,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-25/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-25/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-25/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-25/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-24] due to args.save_total_limit
{'eval_loss': 1.370571494102478, 'eval_f1': 0.2329963087786872, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.67, 'eval_steps_per_second': 5.884, 'epoch': 2.17}
  2%|███▎                                                                                                                                                     | 26/1200 [01:21<57:04,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|███▎                                                                                                                                                     | 26/1200 [01:21<57:04,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-26
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-26/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-26/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-26/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-26/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-25] due to args.save_total_limit
  2%|███▍                                                                                                                                                     | 27/1200 [01:24<57:22,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|███▍                                                                                                                                                     | 27/1200 [01:24<57:22,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-27
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-27/config.json
{'eval_loss': 1.3634659051895142, 'eval_f1': 0.20476438880194747, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.671, 'eval_steps_per_second': 5.884, 'epoch': 2.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-27/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-27/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-27/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-26] due to args.save_total_limit
{'eval_loss': 1.3455816507339478, 'eval_f1': 0.20476438880194747, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.642, 'eval_steps_per_second': 5.882, 'epoch': 2.33}
  2%|███▌                                                                                                                                                     | 28/1200 [01:26<57:09,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|███▌                                                                                                                                                     | 28/1200 [01:27<57:09,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-28
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-28/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-28/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-28/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-28/special_tokens_map.json
{'eval_loss': 1.321054220199585, 'eval_f1': 0.2252207229718474, 'eval_runtime': 0.5138, 'eval_samples_per_second': 116.784, 'eval_steps_per_second': 5.839, 'epoch': 2.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-20] due to args.save_total_limit
  2%|███▋                                                                                                                                                     | 29/1200 [01:29<56:48,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|███▋                                                                                                                                                     | 29/1200 [01:30<56:48,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-29
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-29/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-29/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-29/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-29/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-27] due to args.save_total_limit
{'eval_loss': 1.301323413848877, 'eval_f1': 0.22588235294117645, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.685, 'eval_steps_per_second': 5.884, 'epoch': 2.5}
  2%|███▊                                                                                                                                                     | 30/1200 [01:33<59:03,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  2%|███▊                                                                                                                                                     | 30/1200 [01:33<59:03,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-30
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-30/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-30/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-30/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-30/special_tokens_map.json
{'eval_loss': 1.279351830482483, 'eval_f1': 0.2157920077034184, 'eval_runtime': 0.517, 'eval_samples_per_second': 116.057, 'eval_steps_per_second': 5.803, 'epoch': 2.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-28] due to args.save_total_limit
  3%|███▉                                                                                                                                                     | 31/1200 [01:36<58:14,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  3%|███▉                                                                                                                                                     | 31/1200 [01:36<58:14,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-31
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-31/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-31/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-31/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-31/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-29] due to args.save_total_limit
{'eval_loss': 1.26042902469635, 'eval_f1': 0.2501636278634876, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.495, 'eval_steps_per_second': 5.875, 'epoch': 2.67}
  3%|████                                                                                                                                                     | 32/1200 [01:38<57:27,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  3%|████                                                                                                                                                     | 32/1200 [01:39<57:27,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-32
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-32/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-32/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-32/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-32/special_tokens_map.json
{'eval_loss': 1.2368652820587158, 'eval_f1': 0.28971777563484413, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.784, 'eval_steps_per_second': 5.889, 'epoch': 2.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-30] due to args.save_total_limit
  3%|████▏                                                                                                                                                    | 33/1200 [01:41<57:30,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  3%|████▏                                                                                                                                                    | 33/1200 [01:42<57:30,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-33
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-33/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-33/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-33/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-33/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-31] due to args.save_total_limit
  3%|████▎                                                                                                                                                    | 34/1200 [01:44<57:29,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-34/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-34/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-34/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-34/special_tokens_map.json
{'eval_loss': 1.2106080055236816, 'eval_f1': 0.30812260536398467, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.782, 'eval_steps_per_second': 5.889, 'epoch': 2.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-32] due to args.save_total_limit
  3%|████▍                                                                                                                                                    | 35/1200 [01:47<57:09,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  3%|████▍                                                                                                                                                    | 35/1200 [01:48<57:09,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-35
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-35/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-35/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-35/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-35/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-33] due to args.save_total_limit
  3%|████▌                                                                                                                                                    | 36/1200 [01:50<56:36,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  3%|████▌                                                                                                                                                    | 36/1200 [01:51<56:36,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-36
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-36/config.json
{'eval_loss': 1.203966736793518, 'eval_f1': 0.3317298622901339, 'eval_runtime': 0.5138, 'eval_samples_per_second': 116.766, 'eval_steps_per_second': 5.838, 'epoch': 3.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-36/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-36/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-36/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-34] due to args.save_total_limit
{'eval_loss': 1.2009499073028564, 'eval_f1': 0.33256704980842916, 'eval_runtime': 0.5162, 'eval_samples_per_second': 116.238, 'eval_steps_per_second': 5.812, 'epoch': 3.08}
  3%|████▋                                                                                                                                                    | 37/1200 [01:53<56:54,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  3%|████▋                                                                                                                                                    | 37/1200 [01:54<56:54,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-37
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-37/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-37/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-37/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-37/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-35] due to args.save_total_limit
  3%|████▊                                                                                                                                                    | 38/1200 [01:56<56:44,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  3%|████▊                                                                                                                                                    | 38/1200 [01:56<56:44,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-38
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-38/config.json
{'eval_loss': 1.2022908926010132, 'eval_f1': 0.2597048361089571, 'eval_runtime': 0.512, 'eval_samples_per_second': 117.186, 'eval_steps_per_second': 5.859, 'epoch': 3.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-38/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-38/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-38/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-36] due to args.save_total_limit
  3%|████▉                                                                                                                                                    | 39/1200 [01:59<56:28,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.2104665040969849, 'eval_f1': 0.24781009823382708, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.606, 'eval_steps_per_second': 5.88, 'epoch': 3.25}
  3%|████▉                                                                                                                                                    | 39/1200 [01:59<56:28,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-39
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-39/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-39/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-39/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-39/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-38] due to args.save_total_limit
  3%|█████                                                                                                                                                    | 40/1200 [02:02<56:19,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  3%|█████                                                                                                                                                    | 40/1200 [02:02<56:19,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-40
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-40/config.json
{'eval_loss': 1.2133184671401978, 'eval_f1': 0.24781009823382708, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.828, 'eval_steps_per_second': 5.891, 'epoch': 3.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-40/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-40/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-40/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-39] due to args.save_total_limit
  3%|█████▏                                                                                                                                                   | 41/1200 [02:05<55:53,  2.89s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.2125530242919922, 'eval_f1': 0.24781009823382708, 'eval_runtime': 0.5124, 'eval_samples_per_second': 117.105, 'eval_steps_per_second': 5.855, 'epoch': 3.42}
  3%|█████▏                                                                                                                                                   | 41/1200 [02:05<55:53,  2.89s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-41
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-41/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-41/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-41/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-41/special_tokens_map.json
{'eval_loss': 1.2113068103790283, 'eval_f1': 0.282770278668556, 'eval_runtime': 0.5117, 'eval_samples_per_second': 117.25, 'eval_steps_per_second': 5.862, 'epoch': 3.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-40] due to args.save_total_limit
  4%|█████▎                                                                                                                                                   | 42/1200 [02:08<55:54,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  4%|█████▎                                                                                                                                                   | 42/1200 [02:08<55:54,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-42
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-42/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-42/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-42/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-42/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-41] due to args.save_total_limit
  4%|█████▍                                                                                                                                                   | 43/1200 [02:11<57:57,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.2161725759506226, 'eval_f1': 0.31147589470570836, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.79, 'eval_steps_per_second': 5.89, 'epoch': 3.58}
  4%|█████▍                                                                                                                                                   | 43/1200 [02:11<57:57,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-43
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-43/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-43/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-43/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-43/special_tokens_map.json
{'eval_loss': 1.2261322736740112, 'eval_f1': 0.28518518518518515, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.53, 'eval_steps_per_second': 5.876, 'epoch': 3.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-42] due to args.save_total_limit
  4%|█████▌                                                                                                                                                   | 44/1200 [02:14<57:13,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  4%|█████▌                                                                                                                                                   | 44/1200 [02:14<57:13,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-44
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-44/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-44/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-44/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-44/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-43] due to args.save_total_limit
  4%|█████▋                                                                                                                                                   | 45/1200 [02:17<57:11,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-45/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-45/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-45/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-45/special_tokens_map.json
{'eval_loss': 1.2288981676101685, 'eval_f1': 0.2869062720225511, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.704, 'eval_steps_per_second': 5.885, 'epoch': 3.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-44] due to args.save_total_limit
  4%|█████▊                                                                                                                                                   | 46/1200 [02:19<56:22,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  4%|█████▊                                                                                                                                                   | 46/1200 [02:20<56:22,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-46
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-46/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-46/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-46/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-46/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-45] due to args.save_total_limit
  4%|█████▉                                                                                                                                                   | 47/1200 [02:22<55:45,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.53it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-47/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-47/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-47/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-47/special_tokens_map.json
{'eval_loss': 1.2095266580581665, 'eval_f1': 0.2845402298850575, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.623, 'eval_steps_per_second': 5.881, 'epoch': 4.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-46] due to args.save_total_limit
  4%|██████                                                                                                                                                   | 48/1200 [02:25<56:11,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  4%|██████                                                                                                                                                   | 48/1200 [02:26<56:11,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-48
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-48/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-48/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-48/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-48/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-47] due to args.save_total_limit
  4%|██████▏                                                                                                                                                  | 49/1200 [02:29<58:16,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.2011405229568481, 'eval_f1': 0.2984126984126984, 'eval_runtime': 0.5239, 'eval_samples_per_second': 114.532, 'eval_steps_per_second': 5.727, 'epoch': 4.08}
  4%|██████▏                                                                                                                                                  | 49/1200 [02:29<58:16,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-49
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-49/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-49/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-49/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-49/special_tokens_map.json
{'eval_loss': 1.190284013748169, 'eval_f1': 0.3267094017094017, 'eval_runtime': 0.513, 'eval_samples_per_second': 116.96, 'eval_steps_per_second': 5.848, 'epoch': 4.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-48] due to args.save_total_limit
  4%|██████▍                                                                                                                                                  | 50/1200 [02:32<57:36,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  4%|██████▍                                                                                                                                                  | 50/1200 [02:32<57:36,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-50
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-50/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-50/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-50/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-50/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-37] due to args.save_total_limit
  4%|██████▌                                                                                                                                                  | 51/1200 [02:34<56:37,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  4%|██████▌                                                                                                                                                  | 51/1200 [02:35<56:37,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-51
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-51/config.json
{'eval_loss': 1.1787022352218628, 'eval_f1': 0.3411437908496732, 'eval_runtime': 0.5124, 'eval_samples_per_second': 117.094, 'eval_steps_per_second': 5.855, 'epoch': 4.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-51/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-51/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-51/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-49] due to args.save_total_limit
{'eval_loss': 1.1769105195999146, 'eval_f1': 0.32663313552371304, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.108, 'eval_steps_per_second': 5.855, 'epoch': 4.33}
  4%|██████▋                                                                                                                                                  | 52/1200 [02:37<56:52,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  4%|██████▋                                                                                                                                                  | 52/1200 [02:38<56:52,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-52
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-52/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-52/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-52/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-52/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-50] due to args.save_total_limit
  4%|██████▊                                                                                                                                                  | 53/1200 [02:40<57:33,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  4%|██████▊                                                                                                                                                  | 53/1200 [02:41<57:33,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-53
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-53/config.json
{'eval_loss': 1.1828196048736572, 'eval_f1': 0.28906830559372926, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.679, 'eval_steps_per_second': 5.884, 'epoch': 4.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-53/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-53/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-53/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-51] due to args.save_total_limit
{'eval_loss': 1.18184494972229, 'eval_f1': 0.26686169091292433, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.631, 'eval_steps_per_second': 5.882, 'epoch': 4.5}
  4%|██████▉                                                                                                                                                  | 54/1200 [02:43<56:36,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  4%|██████▉                                                                                                                                                  | 54/1200 [02:44<56:36,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-54
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-54/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-54/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-54/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-54/special_tokens_map.json
{'eval_loss': 1.1771385669708252, 'eval_f1': 0.26686169091292433, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.695, 'eval_steps_per_second': 5.885, 'epoch': 4.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-53] due to args.save_total_limit
  5%|███████                                                                                                                                                  | 55/1200 [02:46<55:52,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|███████                                                                                                                                                  | 55/1200 [02:47<55:52,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-55
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-55/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-55/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-55/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-55/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-54] due to args.save_total_limit
{'eval_loss': 1.1744619607925415, 'eval_f1': 0.26686169091292433, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.681, 'eval_steps_per_second': 5.884, 'epoch': 4.67}
  5%|███████▏                                                                                                                                                 | 56/1200 [02:49<55:46,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|███████▏                                                                                                                                                 | 56/1200 [02:50<55:46,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-56
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-56/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-56/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-56/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-56/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-52] due to args.save_total_limit
  5%|███████▎                                                                                                                                                 | 57/1200 [02:52<55:34,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|███████▎                                                                                                                                                 | 57/1200 [02:53<55:34,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-57
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-57/config.json
{'eval_loss': 1.173214077949524, 'eval_f1': 0.27774248840492033, 'eval_runtime': 0.5139, 'eval_samples_per_second': 116.753, 'eval_steps_per_second': 5.838, 'epoch': 4.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-57/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-57/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-57/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-55] due to args.save_total_limit
  5%|███████▍                                                                                                                                                 | 58/1200 [02:55<55:15,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|███████▍                                                                                                                                                 | 58/1200 [02:55<55:15,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-58
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-58/config.json
{'eval_loss': 1.168319582939148, 'eval_f1': 0.28606753812636165, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.584, 'eval_steps_per_second': 5.879, 'epoch': 4.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-58/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-58/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-58/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-56] due to args.save_total_limit
{'eval_loss': 1.1575566530227661, 'eval_f1': 0.3138888888888889, 'eval_runtime': 0.5116, 'eval_samples_per_second': 117.287, 'eval_steps_per_second': 5.864, 'epoch': 4.92}
  5%|███████▌                                                                                                                                                 | 59/1200 [02:58<55:09,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|███████▌                                                                                                                                                 | 59/1200 [02:58<55:09,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-59
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-59/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-59/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-59/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-59/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-57] due to args.save_total_limit
  5%|███████▋                                                                                                                                                 | 60/1200 [03:01<55:04,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|███████▋                                                                                                                                                 | 60/1200 [03:01<55:04,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-60
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-60/config.json
{'eval_loss': 1.1467403173446655, 'eval_f1': 0.336965811965812, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.709, 'eval_steps_per_second': 5.885, 'epoch': 5.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-60/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-60/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-60/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-58] due to args.save_total_limit
{'eval_loss': 1.1368104219436646, 'eval_f1': 0.3381607949412827, 'eval_runtime': 0.5138, 'eval_samples_per_second': 116.772, 'eval_steps_per_second': 5.839, 'epoch': 5.08}
  5%|███████▊                                                                                                                                                 | 61/1200 [03:04<54:52,  2.89s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|███████▊                                                                                                                                                 | 61/1200 [03:04<54:52,  2.89s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-61
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-61/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-61/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-61/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-61/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-59] due to args.save_total_limit
  5%|███████▉                                                                                                                                                 | 62/1200 [03:06<54:48,  2.89s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|███████▉                                                                                                                                                 | 62/1200 [03:07<54:48,  2.89s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-62
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-62/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-62/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-62/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-62/special_tokens_map.json
{'eval_loss': 1.1285983324050903, 'eval_f1': 0.3381607949412827, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.661, 'eval_steps_per_second': 5.883, 'epoch': 5.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-60] due to args.save_total_limit
{'eval_loss': 1.1202771663665771, 'eval_f1': 0.43165220111032915, 'eval_runtime': 0.5114, 'eval_samples_per_second': 117.316, 'eval_steps_per_second': 5.866, 'epoch': 5.25}
  5%|████████                                                                                                                                                 | 63/1200 [03:10<56:47,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|████████                                                                                                                                                 | 63/1200 [03:10<56:47,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-63
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-63/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-63/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-63/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-63/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-61] due to args.save_total_limit
  5%|████████▏                                                                                                                                                | 64/1200 [03:13<57:13,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  5%|████████▏                                                                                                                                                | 64/1200 [03:13<57:13,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-64
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-64/config.json
{'eval_loss': 1.1135224103927612, 'eval_f1': 0.4193635807325815, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.737, 'eval_steps_per_second': 5.887, 'epoch': 5.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-64/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-64/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-64/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-62] due to args.save_total_limit
  5%|████████▎                                                                                                                                                | 65/1200 [03:16<56:16,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.1107174158096313, 'eval_f1': 0.4935400516795865, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.559, 'eval_steps_per_second': 5.878, 'epoch': 5.42}
  5%|████████▎                                                                                                                                                | 65/1200 [03:16<56:16,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-65
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-65/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-65/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-65/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-65/special_tokens_map.json
{'eval_loss': 1.1099265813827515, 'eval_f1': 0.47798941798941796, 'eval_runtime': 0.5128, 'eval_samples_per_second': 117.0, 'eval_steps_per_second': 5.85, 'epoch': 5.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-63] due to args.save_total_limit
  6%|████████▍                                                                                                                                                | 66/1200 [03:19<55:48,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  6%|████████▍                                                                                                                                                | 66/1200 [03:19<55:48,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-66
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-66/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-66/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-66/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-66/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-64] due to args.save_total_limit
  6%|████████▌                                                                                                                                                | 67/1200 [03:21<55:33,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.1102110147476196, 'eval_f1': 0.4935400516795865, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.166, 'eval_steps_per_second': 5.858, 'epoch': 5.58}
  6%|████████▌                                                                                                                                                | 67/1200 [03:22<55:33,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-67
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-67/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-67/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-67/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-67/special_tokens_map.json
{'eval_loss': 1.1124966144561768, 'eval_f1': 0.4630435977788772, 'eval_runtime': 0.5124, 'eval_samples_per_second': 117.095, 'eval_steps_per_second': 5.855, 'epoch': 5.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-65] due to args.save_total_limit
  6%|████████▋                                                                                                                                                | 68/1200 [03:24<55:42,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  6%|████████▋                                                                                                                                                | 68/1200 [03:25<55:42,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-68
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-68/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-68/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-68/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-68/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-67] due to args.save_total_limit
  6%|████████▊                                                                                                                                                | 69/1200 [03:27<55:43,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-69/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-69/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-69/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-69/special_tokens_map.json
{'eval_loss': 1.123874306678772, 'eval_f1': 0.3519793072424651, 'eval_runtime': 0.5159, 'eval_samples_per_second': 116.305, 'eval_steps_per_second': 5.815, 'epoch': 5.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-68] due to args.save_total_limit
  6%|████████▉                                                                                                                                                | 70/1200 [03:30<55:17,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  6%|████████▉                                                                                                                                                | 70/1200 [03:31<55:17,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-70
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-70/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-70/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-70/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-70/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-69] due to args.save_total_limit
  6%|█████████                                                                                                                                                | 71/1200 [03:33<55:07,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  6%|█████████                                                                                                                                                | 71/1200 [03:34<55:07,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-71
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-71/config.json
{'eval_loss': 1.1351293325424194, 'eval_f1': 0.3660335057896033, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.446, 'eval_steps_per_second': 5.872, 'epoch': 5.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-71/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-71/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-71/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-70] due to args.save_total_limit
  6%|█████████▏                                                                                                                                               | 72/1200 [03:36<54:36,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.142564296722412, 'eval_f1': 0.3777777777777778, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.54, 'eval_steps_per_second': 5.877, 'epoch': 6.0}
  6%|█████████▏                                                                                                                                               | 72/1200 [03:37<54:36,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-72
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-72/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-72/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-72/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-72/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-71] due to args.save_total_limit
  6%|█████████▎                                                                                                                                               | 73/1200 [03:39<54:50,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  6%|█████████▎                                                                                                                                               | 73/1200 [03:39<54:50,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-73
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-73/config.json
{'eval_loss': 1.1501357555389404, 'eval_f1': 0.34711810052420594, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.508, 'eval_steps_per_second': 5.875, 'epoch': 6.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-73/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-73/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-73/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-72] due to args.save_total_limit
{'eval_loss': 1.1559282541275024, 'eval_f1': 0.31792394401090057, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.764, 'eval_steps_per_second': 5.888, 'epoch': 6.17}
  6%|█████████▍                                                                                                                                               | 74/1200 [03:42<54:47,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  6%|█████████▍                                                                                                                                               | 74/1200 [03:42<54:47,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-74
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-74/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-74/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-74/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-74/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-73] due to args.save_total_limit
  6%|█████████▌                                                                                                                                               | 75/1200 [03:45<55:23,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  6%|█████████▌                                                                                                                                               | 75/1200 [03:45<55:23,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-75
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-75/config.json
{'eval_loss': 1.157793641090393, 'eval_f1': 0.31792394401090057, 'eval_runtime': 0.5115, 'eval_samples_per_second': 117.296, 'eval_steps_per_second': 5.865, 'epoch': 6.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-75/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-75/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-75/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-74] due to args.save_total_limit
  6%|█████████▋                                                                                                                                               | 76/1200 [03:48<55:00,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.52it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-76/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-76/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-76/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-76/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-75] due to args.save_total_limit
  6%|█████████▊                                                                                                                                               | 77/1200 [03:51<54:41,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  6%|█████████▊                                                                                                                                               | 77/1200 [03:51<54:41,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-77
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-77/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-77/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-77/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-77/special_tokens_map.json
{'eval_loss': 1.1433145999908447, 'eval_f1': 0.3325478386347952, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.571, 'eval_steps_per_second': 5.879, 'epoch': 6.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-76] due to args.save_total_limit
  6%|█████████▉                                                                                                                                               | 78/1200 [03:54<56:40,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.1337097883224487, 'eval_f1': 0.3641093474426808, 'eval_runtime': 0.5232, 'eval_samples_per_second': 114.683, 'eval_steps_per_second': 5.734, 'epoch': 6.5}
  6%|█████████▉                                                                                                                                               | 78/1200 [03:55<56:40,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-78
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-78/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-78/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-78/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-78/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-77] due to args.save_total_limit
  7%|██████████                                                                                                                                               | 79/1200 [03:57<56:07,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|██████████                                                                                                                                               | 79/1200 [03:57<56:07,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-79
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-79/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-79/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-79/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-79/special_tokens_map.json
{'eval_loss': 1.1258594989776611, 'eval_f1': 0.3660335057896033, 'eval_runtime': 0.5167, 'eval_samples_per_second': 116.129, 'eval_steps_per_second': 5.806, 'epoch': 6.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-78] due to args.save_total_limit
  7%|██████████▏                                                                                                                                              | 80/1200 [04:00<55:33,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-80/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-80/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-80/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-80/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-79] due to args.save_total_limit
  7%|██████████▎                                                                                                                                              | 81/1200 [04:03<55:27,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|██████████▎                                                                                                                                              | 81/1200 [04:03<55:27,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-81
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-81/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-81/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-81/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-81/special_tokens_map.json
{'eval_loss': 1.11407470703125, 'eval_f1': 0.3715555555555555, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.395, 'eval_steps_per_second': 5.87, 'epoch': 6.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-80] due to args.save_total_limit
  7%|██████████▍                                                                                                                                              | 82/1200 [04:06<55:21,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|██████████▍                                                                                                                                              | 82/1200 [04:06<55:21,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-82
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-82/config.json
{'eval_loss': 1.1057733297348022, 'eval_f1': 0.4146771130104464, 'eval_runtime': 0.5156, 'eval_samples_per_second': 116.371, 'eval_steps_per_second': 5.819, 'epoch': 6.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-82/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-82/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-82/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-66] due to args.save_total_limit
{'eval_loss': 1.102662205696106, 'eval_f1': 0.3793103448275862, 'eval_runtime': 0.5113, 'eval_samples_per_second': 117.358, 'eval_steps_per_second': 5.868, 'epoch': 6.92}
  7%|██████████▌                                                                                                                                              | 83/1200 [04:09<54:56,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|██████████▌                                                                                                                                              | 83/1200 [04:09<54:56,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-83
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-83/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-83/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-83/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-83/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-81] due to args.save_total_limit
  7%|██████████▋                                                                                                                                              | 84/1200 [04:12<54:34,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|██████████▋                                                                                                                                              | 84/1200 [04:12<54:34,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-84
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-84/config.json
{'eval_loss': 1.1026488542556763, 'eval_f1': 0.358534239236314, 'eval_runtime': 0.5138, 'eval_samples_per_second': 116.769, 'eval_steps_per_second': 5.838, 'epoch': 7.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-84/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-84/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-84/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-82] due to args.save_total_limit
{'eval_loss': 1.105245590209961, 'eval_f1': 0.33941416388579904, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.613, 'eval_steps_per_second': 5.881, 'epoch': 7.08}
  7%|██████████▊                                                                                                                                              | 85/1200 [04:15<54:49,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|██████████▊                                                                                                                                              | 85/1200 [04:15<54:49,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-85
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-85/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-85/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-85/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-85/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-83] due to args.save_total_limit
  7%|██████████▉                                                                                                                                              | 86/1200 [04:17<54:28,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|██████████▉                                                                                                                                              | 86/1200 [04:18<54:28,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-86
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-86/config.json
{'eval_loss': 1.1085504293441772, 'eval_f1': 0.31375661375661373, 'eval_runtime': 0.5129, 'eval_samples_per_second': 116.983, 'eval_steps_per_second': 5.849, 'epoch': 7.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-86/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-86/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-86/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-85] due to args.save_total_limit
  7%|███████████                                                                                                                                              | 87/1200 [04:20<53:58,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|███████████                                                                                                                                              | 87/1200 [04:21<53:58,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-87
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-87/config.json
{'eval_loss': 1.1114497184753418, 'eval_f1': 0.2909642401021711, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.566, 'eval_steps_per_second': 5.878, 'epoch': 7.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-87/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-87/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-87/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-86] due to args.save_total_limit
  7%|███████████▏                                                                                                                                             | 88/1200 [04:24<55:57,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|███████████▏                                                                                                                                             | 88/1200 [04:24<55:57,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-88
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-88/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-88/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-88/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-88/special_tokens_map.json
{'eval_loss': 1.1154006719589233, 'eval_f1': 0.3034047919293821, 'eval_runtime': 0.5183, 'eval_samples_per_second': 115.774, 'eval_steps_per_second': 5.789, 'epoch': 7.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-87] due to args.save_total_limit
  7%|███████████▎                                                                                                                                             | 89/1200 [04:26<55:09,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  7%|███████████▎                                                                                                                                             | 89/1200 [04:27<55:09,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-89
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-89/config.json
{'eval_loss': 1.128551959991455, 'eval_f1': 0.3421515423779574, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.39, 'eval_steps_per_second': 5.869, 'epoch': 7.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-89/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-89/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-89/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-88] due to args.save_total_limit
  8%|███████████▍                                                                                                                                             | 90/1200 [04:29<54:33,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  8%|███████████▍                                                                                                                                             | 90/1200 [04:30<54:33,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-90
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-90/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-90/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-90/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-90/special_tokens_map.json
{'eval_loss': 1.1425174474716187, 'eval_f1': 0.31108581752484193, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.721, 'eval_steps_per_second': 5.886, 'epoch': 7.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-89] due to args.save_total_limit
  8%|███████████▌                                                                                                                                             | 91/1200 [04:32<54:17,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  8%|███████████▌                                                                                                                                             | 91/1200 [04:33<54:17,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-91
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-91/config.json
{'eval_loss': 1.1582813262939453, 'eval_f1': 0.2769240019240019, 'eval_runtime': 0.5145, 'eval_samples_per_second': 116.622, 'eval_steps_per_second': 5.831, 'epoch': 7.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-91/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-91/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-91/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-90] due to args.save_total_limit
  8%|███████████▋                                                                                                                                             | 92/1200 [04:35<53:59,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  8%|███████████▋                                                                                                                                             | 92/1200 [04:36<53:59,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-92
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-92/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-92/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-92/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-92/special_tokens_map.json
{'eval_loss': 1.1678528785705566, 'eval_f1': 0.2769240019240019, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.582, 'eval_steps_per_second': 5.879, 'epoch': 7.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-91] due to args.save_total_limit
  8%|███████████▊                                                                                                                                             | 93/1200 [04:38<54:05,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  8%|███████████▊                                                                                                                                             | 93/1200 [04:39<54:05,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-93
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-93/config.json
{'eval_loss': 1.1796499490737915, 'eval_f1': 0.2643520901240922, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.553, 'eval_steps_per_second': 5.878, 'epoch': 7.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-93/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-93/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-93/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-92] due to args.save_total_limit
{'eval_loss': 1.1839003562927246, 'eval_f1': 0.2627684407096172, 'eval_runtime': 0.5089, 'eval_samples_per_second': 117.891, 'eval_steps_per_second': 5.895, 'epoch': 7.83}
  8%|███████████▉                                                                                                                                             | 94/1200 [04:41<54:02,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  8%|███████████▉                                                                                                                                             | 94/1200 [04:42<54:02,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-94
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-94/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-94/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-94/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-94/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-93] due to args.save_total_limit
  8%|████████████                                                                                                                                             | 95/1200 [04:44<54:11,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  8%|████████████                                                                                                                                             | 95/1200 [04:45<54:11,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-95
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-95/config.json
{'eval_loss': 1.175354242324829, 'eval_f1': 0.2627684407096172, 'eval_runtime': 0.5203, 'eval_samples_per_second': 115.32, 'eval_steps_per_second': 5.766, 'epoch': 7.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-95/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-95/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-95/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-94] due to args.save_total_limit
  8%|████████████▏                                                                                                                                            | 96/1200 [04:47<53:49,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.1551475524902344, 'eval_f1': 0.2550038314176245, 'eval_runtime': 0.5089, 'eval_samples_per_second': 117.893, 'eval_steps_per_second': 5.895, 'epoch': 8.0}
  8%|████████████▏                                                                                                                                            | 96/1200 [04:47<53:49,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-96
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-96/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-96/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-96/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-96/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-95] due to args.save_total_limit
  8%|████████████▎                                                                                                                                            | 97/1200 [04:50<53:55,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  8%|████████████▎                                                                                                                                            | 97/1200 [04:50<53:55,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-97
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-97/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-97/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-97/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-97/special_tokens_map.json
{'eval_loss': 1.1414703130722046, 'eval_f1': 0.28339438339438333, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.531, 'eval_steps_per_second': 5.877, 'epoch': 8.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-96] due to args.save_total_limit
  8%|████████████▍                                                                                                                                            | 98/1200 [04:53<54:04,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.51it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-98/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-98/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-98/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-98/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-97] due to args.save_total_limit
  8%|████████████▌                                                                                                                                            | 99/1200 [04:56<54:13,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  8%|████████████▌                                                                                                                                            | 99/1200 [04:56<54:13,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-99
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-99/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-99/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-99/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-99/special_tokens_map.json
{'eval_loss': 1.1160705089569092, 'eval_f1': 0.326068376068376, 'eval_runtime': 0.5137, 'eval_samples_per_second': 116.802, 'eval_steps_per_second': 5.84, 'epoch': 8.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-98] due to args.save_total_limit
  8%|████████████▋                                                                                                                                           | 100/1200 [04:59<56:00,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-100/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-100/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-100/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-100/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-99] due to args.save_total_limit
  8%|████████████▊                                                                                                                                           | 101/1200 [05:02<54:51,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  8%|████████████▊                                                                                                                                           | 101/1200 [05:02<54:51,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-101
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-101/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-101/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-101/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-101/special_tokens_map.json
{'eval_loss': 1.1134213209152222, 'eval_f1': 0.34111111111111114, 'eval_runtime': 0.5178, 'eval_samples_per_second': 115.88, 'eval_steps_per_second': 5.794, 'epoch': 8.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-100] due to args.save_total_limit
  8%|████████████▉                                                                                                                                           | 102/1200 [05:05<54:30,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-102/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-102/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-102/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-102/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-101] due to args.save_total_limit
  9%|█████████████                                                                                                                                           | 103/1200 [05:08<54:08,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|█████████████                                                                                                                                           | 103/1200 [05:08<54:08,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-103
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-103/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-103/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-103/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-103/special_tokens_map.json
{'eval_loss': 1.1095339059829712, 'eval_f1': 0.4004078605858361, 'eval_runtime': 0.5137, 'eval_samples_per_second': 116.795, 'eval_steps_per_second': 5.84, 'epoch': 8.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-102] due to args.save_total_limit
  9%|█████████████▏                                                                                                                                          | 104/1200 [05:11<53:46,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|█████████████▏                                                                                                                                          | 104/1200 [05:11<53:46,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-104
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-104/config.json
{'eval_loss': 1.1083248853683472, 'eval_f1': 0.3817094951704027, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.887, 'eval_steps_per_second': 5.844, 'epoch': 8.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-104/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-104/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-104/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-103] due to args.save_total_limit
  9%|█████████████▎                                                                                                                                          | 105/1200 [05:14<53:23,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|█████████████▎                                                                                                                                          | 105/1200 [05:14<53:23,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-105
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-105/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-105/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-105/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-105/special_tokens_map.json
{'eval_loss': 1.1031306982040405, 'eval_f1': 0.47951559934318555, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.686, 'eval_steps_per_second': 5.884, 'epoch': 8.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-104] due to args.save_total_limit
  9%|█████████████▍                                                                                                                                          | 106/1200 [05:17<53:29,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|█████████████▍                                                                                                                                          | 106/1200 [05:17<53:29,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-106
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-106/config.json
{'eval_loss': 1.0956499576568604, 'eval_f1': 0.511056370836245, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.476, 'eval_steps_per_second': 5.874, 'epoch': 8.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-106/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-106/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-106/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-84] due to args.save_total_limit
  9%|█████████████▌                                                                                                                                          | 107/1200 [05:19<52:52,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.0902975797653198, 'eval_f1': 0.5038507989594947, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.584, 'eval_steps_per_second': 5.879, 'epoch': 8.92}
  9%|█████████████▌                                                                                                                                          | 107/1200 [05:20<52:52,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-107
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-107/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-107/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-107/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-107/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-105] due to args.save_total_limit
  9%|█████████████▋                                                                                                                                          | 108/1200 [05:22<52:42,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|█████████████▋                                                                                                                                          | 108/1200 [05:23<52:42,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-108
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-108/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-108/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-108/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-108/special_tokens_map.json
{'eval_loss': 1.0865936279296875, 'eval_f1': 0.5097334311567622, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.771, 'eval_steps_per_second': 5.889, 'epoch': 9.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-106] due to args.save_total_limit
  9%|█████████████▊                                                                                                                                          | 109/1200 [05:25<52:25,  2.88s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|█████████████▊                                                                                                                                          | 109/1200 [05:26<52:25,  2.88s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-109
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-109/config.json
{'eval_loss': 1.0864285230636597, 'eval_f1': 0.4792460317460317, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.503, 'eval_steps_per_second': 5.875, 'epoch': 9.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-109/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-109/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-109/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-107] due to args.save_total_limit
  9%|█████████████▉                                                                                                                                          | 110/1200 [05:28<52:16,  2.88s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|█████████████▉                                                                                                                                          | 110/1200 [05:28<52:16,  2.88s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-110
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-110/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-110/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-110/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-110/special_tokens_map.json
{'eval_loss': 1.0838513374328613, 'eval_f1': 0.5144540767182276, 'eval_runtime': 0.5116, 'eval_samples_per_second': 117.29, 'eval_steps_per_second': 5.864, 'epoch': 9.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-108] due to args.save_total_limit
  9%|██████████████                                                                                                                                          | 111/1200 [05:31<52:46,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|██████████████                                                                                                                                          | 111/1200 [05:31<52:46,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-111
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-111/config.json
{'eval_loss': 1.0860952138900757, 'eval_f1': 0.46309523809523806, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.583, 'eval_steps_per_second': 5.879, 'epoch': 9.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-111/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-111/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-111/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-109] due to args.save_total_limit
  9%|██████████████▏                                                                                                                                         | 112/1200 [05:34<53:21,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|██████████████▏                                                                                                                                         | 112/1200 [05:34<53:21,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-112
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-112/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-112/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-112/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-112/special_tokens_map.json
{'eval_loss': 1.0970642566680908, 'eval_f1': 0.38333333333333336, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.505, 'eval_steps_per_second': 5.875, 'epoch': 9.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-111] due to args.save_total_limit
  9%|██████████████▎                                                                                                                                         | 113/1200 [05:37<53:37,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  9%|██████████████▎                                                                                                                                         | 113/1200 [05:37<53:37,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-113
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-113/config.json
{'eval_loss': 1.121378779411316, 'eval_f1': 0.34950219036240543, 'eval_runtime': 0.513, 'eval_samples_per_second': 116.961, 'eval_steps_per_second': 5.848, 'epoch': 9.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-113/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-113/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-113/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-112] due to args.save_total_limit
 10%|██████████████▍                                                                                                                                         | 114/1200 [05:40<53:20,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|██████████████▍                                                                                                                                         | 114/1200 [05:40<53:20,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-114
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-114/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-114/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-114/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-114/special_tokens_map.json
{'eval_loss': 1.1376591920852661, 'eval_f1': 0.34821869488536156, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.382, 'eval_steps_per_second': 5.869, 'epoch': 9.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-113] due to args.save_total_limit
 10%|██████████████▌                                                                                                                                         | 115/1200 [05:43<53:05,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|██████████████▌                                                                                                                                         | 115/1200 [05:43<53:05,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-115
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-115/config.json
{'eval_loss': 1.1408476829528809, 'eval_f1': 0.34950219036240543, 'eval_runtime': 0.5288, 'eval_samples_per_second': 113.471, 'eval_steps_per_second': 5.674, 'epoch': 9.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-115/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-115/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-115/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-114] due to args.save_total_limit
 10%|██████████████▋                                                                                                                                         | 116/1200 [05:46<52:55,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-116/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-116/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-116/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-116/special_tokens_map.json
{'eval_loss': 1.1302443742752075, 'eval_f1': 0.35099170208459823, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.057, 'eval_steps_per_second': 5.853, 'epoch': 9.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-115] due to args.save_total_limit
 10%|██████████████▊                                                                                                                                         | 117/1200 [05:49<52:39,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|██████████████▊                                                                                                                                         | 117/1200 [05:49<52:39,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-117
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-117/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-117/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-117/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-117/special_tokens_map.json
{'eval_loss': 1.1115797758102417, 'eval_f1': 0.36088369070825216, 'eval_runtime': 0.5168, 'eval_samples_per_second': 116.105, 'eval_steps_per_second': 5.805, 'epoch': 9.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-116] due to args.save_total_limit
 10%|██████████████▉                                                                                                                                         | 118/1200 [05:52<52:40,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.58it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-118/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-118/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-118/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-118/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-117] due to args.save_total_limit
 10%|███████████████                                                                                                                                         | 119/1200 [05:55<54:24,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|███████████████                                                                                                                                         | 119/1200 [05:55<54:24,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-119
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-119/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-119/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-119/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-119/special_tokens_map.json
{'eval_loss': 1.0829280614852905, 'eval_f1': 0.4983168284472334, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.561, 'eval_steps_per_second': 5.878, 'epoch': 9.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-110] due to args.save_total_limit
 10%|███████████████▏                                                                                                                                        | 120/1200 [05:58<53:31,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|███████████████▏                                                                                                                                        | 120/1200 [05:58<53:31,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-120
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-120/config.json
{'eval_loss': 1.078005313873291, 'eval_f1': 0.5049039958484691, 'eval_runtime': 0.5124, 'eval_samples_per_second': 117.096, 'eval_steps_per_second': 5.855, 'epoch': 10.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-120/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-120/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-120/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-118] due to args.save_total_limit
 10%|███████████████▎                                                                                                                                        | 121/1200 [06:01<52:59,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|███████████████▎                                                                                                                                        | 121/1200 [06:01<52:59,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-121
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-121/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-121/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-121/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-121/special_tokens_map.json
{'eval_loss': 1.0718530416488647, 'eval_f1': 0.5139926240766576, 'eval_runtime': 0.512, 'eval_samples_per_second': 117.183, 'eval_steps_per_second': 5.859, 'epoch': 10.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-119] due to args.save_total_limit
 10%|███████████████▍                                                                                                                                        | 122/1200 [06:03<52:47,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-122/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-122/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-122/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-122/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-120] due to args.save_total_limit
 10%|███████████████▌                                                                                                                                        | 123/1200 [06:06<53:01,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|███████████████▌                                                                                                                                        | 123/1200 [06:07<53:01,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-123
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-123/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-123/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-123/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-123/special_tokens_map.json
{'eval_loss': 1.0673840045928955, 'eval_f1': 0.4169044992467646, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.772, 'eval_steps_per_second': 5.889, 'epoch': 10.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-121] due to args.save_total_limit
 10%|███████████████▋                                                                                                                                        | 124/1200 [06:09<52:54,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|███████████████▋                                                                                                                                        | 124/1200 [06:10<52:54,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-124
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-124/config.json
{'eval_loss': 1.065768837928772, 'eval_f1': 0.44014939309056955, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.604, 'eval_steps_per_second': 5.88, 'epoch': 10.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-124/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-124/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-124/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-122] due to args.save_total_limit
 10%|███████████████▊                                                                                                                                        | 125/1200 [06:12<52:35,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|███████████████▊                                                                                                                                        | 125/1200 [06:13<52:35,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-125
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-125/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-125/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-125/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-125/special_tokens_map.json
{'eval_loss': 1.0633667707443237, 'eval_f1': 0.4600127087872186, 'eval_runtime': 0.5137, 'eval_samples_per_second': 116.79, 'eval_steps_per_second': 5.839, 'epoch': 10.42}
{'eval_loss': 1.0681278705596924, 'eval_f1': 0.5009590235396686, 'eval_runtime': 0.5149, 'eval_samples_per_second': 116.526, 'eval_steps_per_second': 5.826, 'epoch': 10.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-123] due to args.save_total_limit
 10%|███████████████▉                                                                                                                                        | 126/1200 [06:15<52:40,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 10%|███████████████▉                                                                                                                                        | 126/1200 [06:16<52:40,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-126
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-126/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-126/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-126/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-126/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-124] due to args.save_total_limit
 11%|████████████████                                                                                                                                        | 127/1200 [06:18<52:44,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.0727150440216064, 'eval_f1': 0.4984713234887451, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.684, 'eval_steps_per_second': 5.884, 'epoch': 10.58}
 11%|████████████████                                                                                                                                        | 127/1200 [06:19<52:44,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-127
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-127/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-127/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-127/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-127/special_tokens_map.json
{'eval_loss': 1.0764585733413696, 'eval_f1': 0.4984713234887451, 'eval_runtime': 0.5091, 'eval_samples_per_second': 117.862, 'eval_steps_per_second': 5.893, 'epoch': 10.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-126] due to args.save_total_limit
 11%|████████████████▏                                                                                                                                       | 128/1200 [06:21<54:19,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 11%|████████████████▏                                                                                                                                       | 128/1200 [06:22<54:19,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-128
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-128/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-128/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-128/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-128/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-127] due to args.save_total_limit
 11%|████████████████▎                                                                                                                                       | 129/1200 [06:24<53:23,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.0900726318359375, 'eval_f1': 0.46283524904214557, 'eval_runtime': 0.5141, 'eval_samples_per_second': 116.701, 'eval_steps_per_second': 5.835, 'epoch': 10.75}
 11%|████████████████▎                                                                                                                                       | 129/1200 [06:25<53:23,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-129
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-129/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-129/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-129/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-129/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-128] due to args.save_total_limit
 11%|████████████████▍                                                                                                                                       | 130/1200 [06:27<52:40,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 11%|████████████████▍                                                                                                                                       | 130/1200 [06:28<52:40,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-130
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-130/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-130/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-130/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-130/special_tokens_map.json
{'eval_loss': 1.1000036001205444, 'eval_f1': 0.3848872180451128, 'eval_runtime': 0.5082, 'eval_samples_per_second': 118.065, 'eval_steps_per_second': 5.903, 'epoch': 10.83}
{'eval_loss': 1.0969477891921997, 'eval_f1': 0.3848872180451128, 'eval_runtime': 0.5165, 'eval_samples_per_second': 116.155, 'eval_steps_per_second': 5.808, 'epoch': 10.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-129] due to args.save_total_limit
 11%|████████████████▌                                                                                                                                       | 131/1200 [06:30<52:11,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 11%|████████████████▌                                                                                                                                       | 131/1200 [06:31<52:11,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-131
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-131/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-131/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-131/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-131/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-130] due to args.save_total_limit
{'eval_loss': 1.107226014137268, 'eval_f1': 0.3944689020960208, 'eval_runtime': 0.5258, 'eval_samples_per_second': 114.105, 'eval_steps_per_second': 5.705, 'epoch': 11.0}
 11%|████████████████▋                                                                                                                                       | 132/1200 [06:33<52:00,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 11%|████████████████▋                                                                                                                                       | 132/1200 [06:33<52:00,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-132
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-132/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-132/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-132/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-132/special_tokens_map.json
{'eval_loss': 1.1202212572097778, 'eval_f1': 0.38701940035273363, 'eval_runtime': 0.5127, 'eval_samples_per_second': 117.016, 'eval_steps_per_second': 5.851, 'epoch': 11.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-131] due to args.save_total_limit
 11%|████████████████▊                                                                                                                                       | 133/1200 [06:36<52:06,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 11%|████████████████▊                                                                                                                                       | 133/1200 [06:36<52:06,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-133
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-133/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-133/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-133/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-133/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-132] due to args.save_total_limit
 11%|████████████████▉                                                                                                                                       | 134/1200 [06:39<51:35,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.1223928928375244, 'eval_f1': 0.3839506172839505, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.549, 'eval_steps_per_second': 5.877, 'epoch': 11.17}
 11%|████████████████▉                                                                                                                                       | 134/1200 [06:39<51:35,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-134
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-134/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-134/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-134/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-134/special_tokens_map.json
{'eval_loss': 1.1296288967132568, 'eval_f1': 0.3608669108669108, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.672, 'eval_steps_per_second': 5.884, 'epoch': 11.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-133] due to args.save_total_limit
 11%|█████████████████                                                                                                                                       | 135/1200 [06:42<51:52,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 11%|█████████████████                                                                                                                                       | 135/1200 [06:42<51:52,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-135
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-135/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-135/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-135/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-135/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-134] due to args.save_total_limit
{'eval_loss': 1.1325675249099731, 'eval_f1': 0.3608669108669108, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.819, 'eval_steps_per_second': 5.891, 'epoch': 11.33}
 11%|█████████████████▏                                                                                                                                      | 136/1200 [06:45<51:33,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 11%|█████████████████▏                                                                                                                                      | 136/1200 [06:45<51:33,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-136
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-136/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-136/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-136/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-136/special_tokens_map.json
{'eval_loss': 1.1200664043426514, 'eval_f1': 0.3608669108669108, 'eval_runtime': 0.5122, 'eval_samples_per_second': 117.136, 'eval_steps_per_second': 5.857, 'epoch': 11.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-135] due to args.save_total_limit
 11%|█████████████████▎                                                                                                                                      | 137/1200 [06:48<51:29,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 11%|█████████████████▎                                                                                                                                      | 137/1200 [06:48<51:29,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-137
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-137/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-137/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-137/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-137/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-136] due to args.save_total_limit
{'eval_loss': 1.0985825061798096, 'eval_f1': 0.37400921658986175, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.758, 'eval_steps_per_second': 5.888, 'epoch': 11.5}
 12%|█████████████████▍                                                                                                                                      | 138/1200 [06:51<53:17,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|█████████████████▍                                                                                                                                      | 138/1200 [06:51<53:17,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-138
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-138/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-138/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-138/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-138/special_tokens_map.json
{'eval_loss': 1.0742168426513672, 'eval_f1': 0.4367074527252503, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.697, 'eval_steps_per_second': 5.885, 'epoch': 11.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-137] due to args.save_total_limit
 12%|█████████████████▌                                                                                                                                      | 139/1200 [06:54<52:59,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|█████████████████▌                                                                                                                                      | 139/1200 [06:54<52:59,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-139
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-139/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-139/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-139/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-139/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-138] due to args.save_total_limit
 12%|█████████████████▋                                                                                                                                      | 140/1200 [06:57<52:15,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-140/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-140/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-140/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-140/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-125] due to args.save_total_limit
{'eval_loss': 1.0564488172531128, 'eval_f1': 0.4977152600170503, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.769, 'eval_steps_per_second': 5.888, 'epoch': 11.75}
 12%|█████████████████▊                                                                                                                                      | 141/1200 [06:59<51:44,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|█████████████████▊                                                                                                                                      | 141/1200 [07:00<51:44,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-141
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-141/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-141/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-141/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-141/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-139] due to args.save_total_limit
 12%|█████████████████▉                                                                                                                                      | 142/1200 [07:02<51:20,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|█████████████████▉                                                                                                                                      | 142/1200 [07:03<51:20,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-142
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-142/config.json
{'eval_loss': 1.0551975965499878, 'eval_f1': 0.5081724581724582, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.762, 'eval_steps_per_second': 5.888, 'epoch': 11.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-142/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-142/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-142/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-140] due to args.save_total_limit
 12%|██████████████████                                                                                                                                      | 143/1200 [07:05<51:04,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.0546271800994873, 'eval_f1': 0.5079630514413123, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.705, 'eval_steps_per_second': 5.885, 'epoch': 11.92}
 12%|██████████████████                                                                                                                                      | 143/1200 [07:06<51:04,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-143
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-143/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-143/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-143/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-143/special_tokens_map.json
{'eval_loss': 1.0585390329360962, 'eval_f1': 0.4953899782135076, 'eval_runtime': 0.517, 'eval_samples_per_second': 116.058, 'eval_steps_per_second': 5.803, 'epoch': 12.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-141] due to args.save_total_limit
 12%|██████████████████▏                                                                                                                                     | 144/1200 [07:08<50:53,  2.89s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|██████████████████▏                                                                                                                                     | 144/1200 [07:09<50:53,  2.89s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-144
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-144/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-144/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-144/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-144/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-142] due to args.save_total_limit
{'eval_loss': 1.0698240995407104, 'eval_f1': 0.4811546840958606, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.746, 'eval_steps_per_second': 5.887, 'epoch': 12.08}
 12%|██████████████████▎                                                                                                                                     | 145/1200 [07:11<52:50,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|██████████████████▎                                                                                                                                     | 145/1200 [07:12<52:50,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-145
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-145/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-145/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-145/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-145/special_tokens_map.json
{'eval_loss': 1.089419960975647, 'eval_f1': 0.44800194398882204, 'eval_runtime': 0.5173, 'eval_samples_per_second': 115.995, 'eval_steps_per_second': 5.8, 'epoch': 12.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-144] due to args.save_total_limit
 12%|██████████████████▍                                                                                                                                     | 146/1200 [07:14<52:07,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|██████████████████▍                                                                                                                                     | 146/1200 [07:15<52:07,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-146
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-146/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-146/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-146/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-146/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-145] due to args.save_total_limit
{'eval_loss': 1.1160205602645874, 'eval_f1': 0.3487390633041689, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.688, 'eval_steps_per_second': 5.884, 'epoch': 12.25}
 12%|██████████████████▌                                                                                                                                     | 147/1200 [07:17<52:15,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|██████████████████▌                                                                                                                                     | 147/1200 [07:18<52:15,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-147
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-147/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-147/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-147/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-147/special_tokens_map.json
{'eval_loss': 1.1600682735443115, 'eval_f1': 0.35471781305114636, 'eval_runtime': 0.5279, 'eval_samples_per_second': 113.667, 'eval_steps_per_second': 5.683, 'epoch': 12.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-146] due to args.save_total_limit
 12%|██████████████████▋                                                                                                                                     | 148/1200 [07:20<51:56,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|██████████████████▋                                                                                                                                     | 148/1200 [07:21<51:56,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-148
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-148/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-148/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-148/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-148/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-147] due to args.save_total_limit
 12%|██████████████████▊                                                                                                                                     | 149/1200 [07:23<51:57,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|██████████████████▊                                                                                                                                     | 149/1200 [07:24<51:57,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-149
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-149/config.json
{'eval_loss': 1.201417088508606, 'eval_f1': 0.32908491812601404, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.479, 'eval_steps_per_second': 5.874, 'epoch': 12.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-149/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-149/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-149/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-148] due to args.save_total_limit
{'eval_loss': 1.2205678224563599, 'eval_f1': 0.32908491812601404, 'eval_runtime': 0.5169, 'eval_samples_per_second': 116.085, 'eval_steps_per_second': 5.804, 'epoch': 12.5}
 12%|███████████████████                                                                                                                                     | 150/1200 [07:26<51:23,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 12%|███████████████████                                                                                                                                     | 150/1200 [07:27<51:23,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-150
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-150/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-150/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-150/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-150/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-149] due to args.save_total_limit
 13%|███████████████████▏                                                                                                                                    | 151/1200 [07:29<51:01,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 13%|███████████████████▏                                                                                                                                    | 151/1200 [07:29<51:01,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-151
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-151/config.json
{'eval_loss': 1.2191144227981567, 'eval_f1': 0.32908491812601404, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.744, 'eval_steps_per_second': 5.887, 'epoch': 12.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-151/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-151/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-151/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-150] due to args.save_total_limit
{'eval_loss': 1.2034757137298584, 'eval_f1': 0.32908491812601404, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.484, 'eval_steps_per_second': 5.874, 'epoch': 12.67}
 13%|███████████████████▎                                                                                                                                    | 152/1200 [07:32<50:52,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 13%|███████████████████▎                                                                                                                                    | 152/1200 [07:32<50:52,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-152
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-152/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-152/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-152/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-152/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-151] due to args.save_total_limit
 13%|███████████████████▍                                                                                                                                    | 153/1200 [07:35<50:53,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 13%|███████████████████▍                                                                                                                                    | 153/1200 [07:35<50:53,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-153
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-153/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-153/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-153/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-153/special_tokens_map.json
{'eval_loss': 1.1659529209136963, 'eval_f1': 0.35259333780460544, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.72, 'eval_steps_per_second': 5.886, 'epoch': 12.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-152] due to args.save_total_limit
 13%|███████████████████▌                                                                                                                                    | 154/1200 [07:38<50:51,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-154/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-154/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-154/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-154/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-153] due to args.save_total_limit
 13%|███████████████████▋                                                                                                                                    | 155/1200 [07:40<50:31,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 13%|███████████████████▋                                                                                                                                    | 155/1200 [07:41<50:31,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-155
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-155/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-155/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-155/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-155/special_tokens_map.json
{'eval_loss': 1.0810396671295166, 'eval_f1': 0.47586206896551725, 'eval_runtime': 0.5182, 'eval_samples_per_second': 115.791, 'eval_steps_per_second': 5.79, 'epoch': 12.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-154] due to args.save_total_limit
 13%|███████████████████▊                                                                                                                                    | 156/1200 [07:43<50:39,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-156/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-156/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-156/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-156/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-155] due to args.save_total_limit
 13%|███████████████████▉                                                                                                                                    | 157/1200 [07:47<52:41,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 13%|███████████████████▉                                                                                                                                    | 157/1200 [07:47<52:41,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-157
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-157/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-157/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-157/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-157/special_tokens_map.json
{'eval_loss': 1.0616793632507324, 'eval_f1': 0.437037037037037, 'eval_runtime': 0.5168, 'eval_samples_per_second': 116.11, 'eval_steps_per_second': 5.806, 'epoch': 13.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-156] due to args.save_total_limit
 13%|████████████████████                                                                                                                                    | 158/1200 [07:50<51:50,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-158/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-158/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-158/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-158/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-157] due to args.save_total_limit
 13%|████████████████████▏                                                                                                                                   | 159/1200 [07:53<51:28,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 13%|████████████████████▏                                                                                                                                   | 159/1200 [07:53<51:28,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-159
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-159/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-159/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-159/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-159/special_tokens_map.json
{'eval_loss': 1.0715032815933228, 'eval_f1': 0.41318248481039177, 'eval_runtime': 0.5119, 'eval_samples_per_second': 117.2, 'eval_steps_per_second': 5.86, 'epoch': 13.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-158] due to args.save_total_limit
 13%|████████████████████▎                                                                                                                                   | 160/1200 [07:55<51:27,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 13%|████████████████████▎                                                                                                                                   | 160/1200 [07:56<51:27,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-160
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-160/config.json
{'eval_loss': 1.0758644342422485, 'eval_f1': 0.4280555817141183, 'eval_runtime': 0.5137, 'eval_samples_per_second': 116.806, 'eval_steps_per_second': 5.84, 'epoch': 13.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-160/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-160/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-160/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-159] due to args.save_total_limit
 13%|████████████████████▍                                                                                                                                   | 161/1200 [07:58<51:20,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 13%|████████████████████▍                                                                                                                                   | 161/1200 [07:59<51:20,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-161
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-161/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-161/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-161/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-161/special_tokens_map.json
{'eval_loss': 1.0795811414718628, 'eval_f1': 0.4138801592289964, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.129, 'eval_steps_per_second': 5.856, 'epoch': 13.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-160] due to args.save_total_limit
 14%|████████████████████▌                                                                                                                                   | 162/1200 [08:01<50:47,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|████████████████████▌                                                                                                                                   | 162/1200 [08:02<50:47,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-162
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-162/config.json
{'eval_loss': 1.0843087434768677, 'eval_f1': 0.43842127842127837, 'eval_runtime': 0.5152, 'eval_samples_per_second': 116.453, 'eval_steps_per_second': 5.823, 'epoch': 13.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-162/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-162/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-162/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-161] due to args.save_total_limit
{'eval_loss': 1.0944104194641113, 'eval_f1': 0.4371047518106342, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.942, 'eval_steps_per_second': 5.847, 'epoch': 13.58}
 14%|████████████████████▋                                                                                                                                   | 163/1200 [08:04<50:48,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|████████████████████▋                                                                                                                                   | 163/1200 [08:05<50:48,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-163
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-163/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-163/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-163/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-163/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-162] due to args.save_total_limit
 14%|████████████████████▊                                                                                                                                   | 164/1200 [08:07<50:22,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|████████████████████▊                                                                                                                                   | 164/1200 [08:08<50:22,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-164
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-164/config.json
{'eval_loss': 1.1060396432876587, 'eval_f1': 0.444824016563147, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.668, 'eval_steps_per_second': 5.883, 'epoch': 13.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-164/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-164/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-164/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-163] due to args.save_total_limit
 14%|████████████████████▉                                                                                                                                   | 165/1200 [08:10<50:12,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-165/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-165/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-165/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-165/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-164] due to args.save_total_limit
 14%|█████████████████████                                                                                                                                   | 166/1200 [08:13<50:17,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|█████████████████████                                                                                                                                   | 166/1200 [08:13<50:17,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-166
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-166/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-166/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-166/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-166/special_tokens_map.json
{'eval_loss': 1.145229458808899, 'eval_f1': 0.41781109445277365, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.616, 'eval_steps_per_second': 5.881, 'epoch': 13.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-165] due to args.save_total_limit
 14%|█████████████████████▏                                                                                                                                  | 167/1200 [08:16<50:09,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|█████████████████████▏                                                                                                                                  | 167/1200 [08:16<50:09,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-167
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-167/config.json
{'eval_loss': 1.157012939453125, 'eval_f1': 0.3947204968944099, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.605, 'eval_steps_per_second': 5.88, 'epoch': 13.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-167/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-167/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-167/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-166] due to args.save_total_limit
 14%|█████████████████████▎                                                                                                                                  | 168/1200 [08:19<50:24,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|█████████████████████▎                                                                                                                                  | 168/1200 [08:19<50:24,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-168
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-168/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-168/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-168/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-168/special_tokens_map.json
{'eval_loss': 1.1651389598846436, 'eval_f1': 0.3959776334776335, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.551, 'eval_steps_per_second': 5.878, 'epoch': 14.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-167] due to args.save_total_limit
 14%|█████████████████████▍                                                                                                                                  | 169/1200 [08:22<50:12,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|█████████████████████▍                                                                                                                                  | 169/1200 [08:22<50:12,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-169
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-169/config.json
{'eval_loss': 1.1598823070526123, 'eval_f1': 0.41781109445277365, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.756, 'eval_steps_per_second': 5.888, 'epoch': 14.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-169/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-169/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-169/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-168] due to args.save_total_limit
 14%|█████████████████████▌                                                                                                                                  | 170/1200 [08:25<50:25,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|█████████████████████▌                                                                                                                                  | 170/1200 [08:25<50:25,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-170
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-170/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-170/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-170/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-170/special_tokens_map.json
{'eval_loss': 1.1433192491531372, 'eval_f1': 0.4333778847010603, 'eval_runtime': 0.5091, 'eval_samples_per_second': 117.845, 'eval_steps_per_second': 5.892, 'epoch': 14.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-169] due to args.save_total_limit
 14%|█████████████████████▋                                                                                                                                  | 171/1200 [08:28<50:42,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|█████████████████████▋                                                                                                                                  | 171/1200 [08:28<50:42,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-171
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-171/config.json
{'eval_loss': 1.125632405281067, 'eval_f1': 0.41021724818959837, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.714, 'eval_steps_per_second': 5.886, 'epoch': 14.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-171/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-171/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-171/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-170] due to args.save_total_limit
 14%|█████████████████████▊                                                                                                                                  | 172/1200 [08:31<52:08,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|█████████████████████▊                                                                                                                                  | 172/1200 [08:31<52:08,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-172
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-172/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-172/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-172/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-172/special_tokens_map.json
{'eval_loss': 1.112984538078308, 'eval_f1': 0.4501664816870144, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.16, 'eval_steps_per_second': 5.858, 'epoch': 14.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-171] due to args.save_total_limit
 14%|█████████████████████▉                                                                                                                                  | 173/1200 [08:34<51:31,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|█████████████████████▉                                                                                                                                  | 173/1200 [08:34<51:31,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-173
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-173/config.json
{'eval_loss': 1.106835961341858, 'eval_f1': 0.4394524469691847, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.716, 'eval_steps_per_second': 5.886, 'epoch': 14.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-173/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-173/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-173/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-172] due to args.save_total_limit
 14%|██████████████████████                                                                                                                                  | 174/1200 [08:37<51:26,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 14%|██████████████████████                                                                                                                                  | 174/1200 [08:37<51:26,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-174
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-174/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-174/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-174/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-174/special_tokens_map.json
{'eval_loss': 1.1088805198669434, 'eval_f1': 0.38166666666666665, 'eval_runtime': 0.5141, 'eval_samples_per_second': 116.718, 'eval_steps_per_second': 5.836, 'epoch': 14.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-173] due to args.save_total_limit
 15%|██████████████████████▏                                                                                                                                 | 175/1200 [08:40<51:11,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 15%|██████████████████████▏                                                                                                                                 | 175/1200 [08:40<51:11,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-175
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-175/config.json
{'eval_loss': 1.1071888208389282, 'eval_f1': 0.38166666666666665, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.166, 'eval_steps_per_second': 5.858, 'epoch': 14.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-175/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-175/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-175/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-174] due to args.save_total_limit
 15%|██████████████████████▎                                                                                                                                 | 176/1200 [08:43<50:37,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.102484941482544, 'eval_f1': 0.3630578921326076, 'eval_runtime': 0.5143, 'eval_samples_per_second': 116.668, 'eval_steps_per_second': 5.833, 'epoch': 14.67}
 15%|██████████████████████▎                                                                                                                                 | 176/1200 [08:43<50:37,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-176
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-176/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-176/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-176/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-176/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-175] due to args.save_total_limit
 15%|██████████████████████▍                                                                                                                                 | 177/1200 [08:46<50:00,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 15%|██████████████████████▍                                                                                                                                 | 177/1200 [08:46<50:00,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-177
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-177/config.json
{'eval_loss': 1.0926871299743652, 'eval_f1': 0.399672187715666, 'eval_runtime': 0.5155, 'eval_samples_per_second': 116.4, 'eval_steps_per_second': 5.82, 'epoch': 14.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-177/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-177/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-177/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-176] due to args.save_total_limit
 15%|██████████████████████▌                                                                                                                                 | 178/1200 [08:48<49:39,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.0840357542037964, 'eval_f1': 0.4744870744870745, 'eval_runtime': 0.5163, 'eval_samples_per_second': 116.215, 'eval_steps_per_second': 5.811, 'epoch': 14.83}
 15%|██████████████████████▌                                                                                                                                 | 178/1200 [08:49<49:39,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-178
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-178/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-178/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-178/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-178/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-177] due to args.save_total_limit
 15%|██████████████████████▋                                                                                                                                 | 179/1200 [08:51<49:36,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 15%|██████████████████████▋                                                                                                                                 | 179/1200 [08:52<49:36,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-179
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-179/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-179/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-179/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-179/special_tokens_map.json
{'eval_loss': 1.0847396850585938, 'eval_f1': 0.5095977193538169, 'eval_runtime': 0.5177, 'eval_samples_per_second': 115.899, 'eval_steps_per_second': 5.795, 'epoch': 14.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-178] due to args.save_total_limit
 15%|██████████████████████▊                                                                                                                                 | 180/1200 [08:54<49:35,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.45it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-180/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-180/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-180/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-180/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-179] due to args.save_total_limit
 15%|██████████████████████▉                                                                                                                                 | 181/1200 [08:57<49:27,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 15%|██████████████████████▉                                                                                                                                 | 181/1200 [08:58<49:27,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-181
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-181/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-181/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-181/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-181/special_tokens_map.json
{'eval_loss': 1.1208993196487427, 'eval_f1': 0.49000000000000005, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.443, 'eval_steps_per_second': 5.872, 'epoch': 15.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-180] due to args.save_total_limit
 15%|███████████████████████                                                                                                                                 | 182/1200 [09:00<49:03,  2.89s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 15%|███████████████████████                                                                                                                                 | 182/1200 [09:01<49:03,  2.89s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-182
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-182/config.json
{'eval_loss': 1.1529027223587036, 'eval_f1': 0.4247619047619048, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.477, 'eval_steps_per_second': 5.874, 'epoch': 15.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-182/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-182/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-182/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-181] due to args.save_total_limit
 15%|███████████████████████▏                                                                                                                                | 183/1200 [09:03<49:08,  2.90s/it]
 15%|███████████████████████▏                                                                                                                                | 183/1200 [09:03<49:08,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 15%|███████████████████████▏                                                                                                                                | 183/1200 [09:04<49:08,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-183
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-183/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-183/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-183/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-183/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-182] due to args.save_total_limit
 15%|███████████████████████▎                                                                                                                                | 184/1200 [09:06<49:20,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 15%|███████████████████████▎                                                                                                                                | 184/1200 [09:06<49:20,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-184
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-184/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-184/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-184/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-184/special_tokens_map.json
{'eval_loss': 1.2095650434494019, 'eval_f1': 0.39131080389144907, 'eval_runtime': 0.5113, 'eval_samples_per_second': 117.347, 'eval_steps_per_second': 5.867, 'epoch': 15.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-183] due to args.save_total_limit
 15%|███████████████████████▍                                                                                                                                | 185/1200 [09:09<49:00,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.58it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-185/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-185/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-185/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-185/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-184] due to args.save_total_limit
 16%|███████████████████████▌                                                                                                                                | 186/1200 [09:12<48:49,  2.89s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|███████████████████████▌                                                                                                                                | 186/1200 [09:12<48:49,  2.89s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-186
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-186/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-186/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-186/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-186/special_tokens_map.json
{'eval_loss': 1.2269093990325928, 'eval_f1': 0.38508540444024314, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.84, 'eval_steps_per_second': 5.892, 'epoch': 15.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-185] due to args.save_total_limit
 16%|███████████████████████▋                                                                                                                                | 187/1200 [09:15<48:55,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|███████████████████████▋                                                                                                                                | 187/1200 [09:15<48:55,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-187
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-187/config.json
{'eval_loss': 1.204530954360962, 'eval_f1': 0.4318532818532818, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.669, 'eval_steps_per_second': 5.883, 'epoch': 15.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-187/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-187/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-187/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-186] due to args.save_total_limit
 16%|███████████████████████▊                                                                                                                                | 188/1200 [09:18<50:45,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|███████████████████████▊                                                                                                                                | 188/1200 [09:18<50:45,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-188
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-188/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-188/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-188/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-188/special_tokens_map.json
{'eval_loss': 1.1712908744812012, 'eval_f1': 0.41959917477158853, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.671, 'eval_steps_per_second': 5.884, 'epoch': 15.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-187] due to args.save_total_limit
 16%|███████████████████████▉                                                                                                                                | 189/1200 [09:21<50:06,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-189/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-189/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-189/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-189/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-188] due to args.save_total_limit
 16%|████████████████████████                                                                                                                                | 190/1200 [09:24<49:59,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|████████████████████████                                                                                                                                | 190/1200 [09:24<49:59,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-190
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-190/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-190/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-190/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-190/special_tokens_map.json
{'eval_loss': 1.1238439083099365, 'eval_f1': 0.47225806451612906, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.742, 'eval_steps_per_second': 5.887, 'epoch': 15.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-189] due to args.save_total_limit
 16%|████████████████████████▏                                                                                                                               | 191/1200 [09:27<49:59,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|████████████████████████▏                                                                                                                               | 191/1200 [09:27<49:59,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-191
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-191/config.json
{'eval_loss': 1.1162762641906738, 'eval_f1': 0.47759689922480625, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.581, 'eval_steps_per_second': 5.879, 'epoch': 15.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-191/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-191/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-191/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-190] due to args.save_total_limit
 16%|████████████████████████▎                                                                                                                               | 192/1200 [09:30<49:37,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|████████████████████████▎                                                                                                                               | 192/1200 [09:30<49:37,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-192
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-192/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-192/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-192/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-192/special_tokens_map.json
{'eval_loss': 1.104546308517456, 'eval_f1': 0.47759689922480625, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.944, 'eval_steps_per_second': 5.847, 'epoch': 16.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-191] due to args.save_total_limit
 16%|████████████████████████▍                                                                                                                               | 193/1200 [09:32<49:10,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|████████████████████████▍                                                                                                                               | 193/1200 [09:33<49:10,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-193
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-193/config.json
{'eval_loss': 1.1054717302322388, 'eval_f1': 0.47759689922480625, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.051, 'eval_steps_per_second': 5.853, 'epoch': 16.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-193/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-193/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-193/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-192] due to args.save_total_limit
 16%|████████████████████████▌                                                                                                                               | 194/1200 [09:36<51:00,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|████████████████████████▌                                                                                                                               | 194/1200 [09:36<51:00,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-194
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-194/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-194/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-194/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-194/special_tokens_map.json
{'eval_loss': 1.117462158203125, 'eval_f1': 0.49051679586563307, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.052, 'eval_steps_per_second': 5.853, 'epoch': 16.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-193] due to args.save_total_limit
 16%|████████████████████████▋                                                                                                                               | 195/1200 [09:39<50:22,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.48it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-195/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-195/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-195/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-195/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-194] due to args.save_total_limit
{'eval_loss': 1.1367536783218384, 'eval_f1': 0.47023786249592703, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.709, 'eval_steps_per_second': 5.885, 'epoch': 16.33}
 16%|████████████████████████▊                                                                                                                               | 196/1200 [09:42<49:47,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|████████████████████████▊                                                                                                                               | 196/1200 [09:42<49:47,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-196
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-196/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-196/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-196/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-196/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-195] due to args.save_total_limit
 16%|████████████████████████▉                                                                                                                               | 197/1200 [09:44<49:16,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|████████████████████████▉                                                                                                                               | 197/1200 [09:45<49:16,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-197
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-197/config.json
{'eval_loss': 1.138283610343933, 'eval_f1': 0.47023786249592703, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.739, 'eval_steps_per_second': 5.887, 'epoch': 16.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-197/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-197/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-197/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-196] due to args.save_total_limit
{'eval_loss': 1.1412022113800049, 'eval_f1': 0.4561205518770997, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.36, 'eval_steps_per_second': 5.868, 'epoch': 16.5}
 16%|█████████████████████████                                                                                                                               | 198/1200 [09:47<49:03,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 16%|█████████████████████████                                                                                                                               | 198/1200 [09:48<49:03,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-198
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-198/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-198/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-198/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-198/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-197] due to args.save_total_limit
 17%|█████████████████████████▏                                                                                                                              | 199/1200 [09:50<48:55,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 17%|█████████████████████████▏                                                                                                                              | 199/1200 [09:51<48:55,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-199
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-199/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-199/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-199/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-199/special_tokens_map.json
{'eval_loss': 1.1364059448242188, 'eval_f1': 0.49051679586563307, 'eval_runtime': 0.5128, 'eval_samples_per_second': 117.004, 'eval_steps_per_second': 5.85, 'epoch': 16.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-198] due to args.save_total_limit
 17%|█████████████████████████▎                                                                                                                              | 200/1200 [09:53<48:28,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-200/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-200/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-200/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-200/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-199] due to args.save_total_limit
 17%|█████████████████████████▍                                                                                                                              | 201/1200 [09:56<48:44,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 17%|█████████████████████████▍                                                                                                                              | 201/1200 [09:57<48:44,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-201
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-201/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-201/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-201/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-201/special_tokens_map.json
{'eval_loss': 1.1104861497879028, 'eval_f1': 0.5407407407407407, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.467, 'eval_steps_per_second': 5.873, 'epoch': 16.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-200] due to args.save_total_limit
 17%|█████████████████████████▌                                                                                                                              | 202/1200 [09:59<48:51,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 17%|█████████████████████████▌                                                                                                                              | 202/1200 [10:00<48:51,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-202
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-202/config.json
{'eval_loss': 1.1121023893356323, 'eval_f1': 0.5193120700437774, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.584, 'eval_steps_per_second': 5.879, 'epoch': 16.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-202/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-202/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-202/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-201] due to args.save_total_limit
{'eval_loss': 1.1239254474639893, 'eval_f1': 0.47848232848232847, 'eval_runtime': 0.5247, 'eval_samples_per_second': 114.343, 'eval_steps_per_second': 5.717, 'epoch': 16.92}
 17%|█████████████████████████▋                                                                                                                              | 203/1200 [10:02<48:33,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 17%|█████████████████████████▋                                                                                                                              | 203/1200 [10:03<48:33,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-203
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-203/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-203/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-203/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-203/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-202] due to args.save_total_limit
 17%|█████████████████████████▊                                                                                                                              | 204/1200 [10:05<48:25,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 17%|█████████████████████████▊                                                                                                                              | 204/1200 [10:05<48:25,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-204
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-204/config.json
{'eval_loss': 1.1338578462600708, 'eval_f1': 0.4792592592592592, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.674, 'eval_steps_per_second': 5.884, 'epoch': 17.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-204/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-204/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-204/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-203] due to args.save_total_limit
 17%|█████████████████████████▉                                                                                                                              | 205/1200 [10:08<48:17,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 17%|█████████████████████████▉                                                                                                                              | 205/1200 [10:08<48:17,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-205
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-205/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-205/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-205/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-205/special_tokens_map.json
{'eval_loss': 1.1385951042175293, 'eval_f1': 0.47848232848232847, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.493, 'eval_steps_per_second': 5.875, 'epoch': 17.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-204] due to args.save_total_limit
 17%|██████████████████████████                                                                                                                              | 206/1200 [10:11<48:31,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 17%|██████████████████████████                                                                                                                              | 206/1200 [10:11<48:31,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-206
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-206/config.json
{'eval_loss': 1.1382461786270142, 'eval_f1': 0.5169875909285409, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.808, 'eval_steps_per_second': 5.89, 'epoch': 17.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-206/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-206/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-206/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-205] due to args.save_total_limit
 17%|██████████████████████████▏                                                                                                                             | 207/1200 [10:14<48:31,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
{'eval_loss': 1.1465812921524048, 'eval_f1': 0.5188419845736919, 'eval_runtime': 0.5147, 'eval_samples_per_second': 116.576, 'eval_steps_per_second': 5.829, 'epoch': 17.25}
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 17%|██████████████████████████▏                                                                                                                             | 207/1200 [10:14<48:31,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-207
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-207/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-207/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-207/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-207/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-206] due to args.save_total_limit
 17%|██████████████████████████▎                                                                                                                             | 208/1200 [10:17<48:22,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 17%|██████████████████████████▎                                                                                                                             | 208/1200 [10:17<48:22,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-208
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-208/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-208/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-208/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-208/special_tokens_map.json
{'eval_loss': 1.169100046157837, 'eval_f1': 0.5436837534398509, 'eval_runtime': 0.5187, 'eval_samples_per_second': 115.672, 'eval_steps_per_second': 5.784, 'epoch': 17.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-207] due to args.save_total_limit
 17%|██████████████████████████▍                                                                                                                             | 209/1200 [10:20<48:31,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-209/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-209/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-209/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-209/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-208] due to args.save_total_limit
 18%|██████████████████████████▌                                                                                                                             | 210/1200 [10:22<48:10,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|██████████████████████████▌                                                                                                                             | 210/1200 [10:23<48:10,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-210
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-210/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-210/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-210/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-210/special_tokens_map.json
{'eval_loss': 1.2191487550735474, 'eval_f1': 0.49714285714285716, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.166, 'eval_steps_per_second': 5.858, 'epoch': 17.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-209] due to args.save_total_limit
 18%|██████████████████████████▋                                                                                                                             | 211/1200 [10:25<48:17,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.48it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-211/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-211/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-211/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-211/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-210] due to args.save_total_limit
 18%|██████████████████████████▊                                                                                                                             | 212/1200 [10:28<48:07,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|██████████████████████████▊                                                                                                                             | 212/1200 [10:29<48:07,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-212
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-212/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-212/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-212/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-212/special_tokens_map.json
{'eval_loss': 1.3166561126708984, 'eval_f1': 0.4351708499491751, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.54, 'eval_steps_per_second': 5.877, 'epoch': 17.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-211] due to args.save_total_limit
 18%|██████████████████████████▉                                                                                                                             | 213/1200 [10:31<48:06,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|██████████████████████████▉                                                                                                                             | 213/1200 [10:32<48:06,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-213
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-213/config.json
{'eval_loss': 1.3112680912017822, 'eval_f1': 0.449560055243696, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.705, 'eval_steps_per_second': 5.885, 'epoch': 17.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-213/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-213/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-213/special_tokens_map.json
{'eval_loss': 1.274135947227478, 'eval_f1': 0.46519931523599906, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.46, 'eval_steps_per_second': 5.873, 'epoch': 17.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-212] due to args.save_total_limit
 18%|███████████████████████████                                                                                                                             | 214/1200 [10:34<48:09,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|███████████████████████████                                                                                                                             | 214/1200 [10:35<48:09,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-214
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-214/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-214/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-214/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-214/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-213] due to args.save_total_limit
 18%|███████████████████████████▏                                                                                                                            | 215/1200 [10:38<50:05,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-215/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-215/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-215/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-215/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-214] due to args.save_total_limit
 18%|███████████████████████████▎                                                                                                                            | 216/1200 [10:40<49:32,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|███████████████████████████▎                                                                                                                            | 216/1200 [10:41<49:32,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-216
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-216/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-216/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-216/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-216/special_tokens_map.json
{'eval_loss': 1.1999146938323975, 'eval_f1': 0.4914529914529915, 'eval_runtime': 0.514, 'eval_samples_per_second': 116.724, 'eval_steps_per_second': 5.836, 'epoch': 18.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-215] due to args.save_total_limit
 18%|███████████████████████████▍                                                                                                                            | 217/1200 [10:43<48:48,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|███████████████████████████▍                                                                                                                            | 217/1200 [10:44<48:48,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-217
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-217/config.json
{'eval_loss': 1.1744225025177002, 'eval_f1': 0.4540435729847495, 'eval_runtime': 0.5137, 'eval_samples_per_second': 116.802, 'eval_steps_per_second': 5.84, 'epoch': 18.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-217/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-217/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-217/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-216] due to args.save_total_limit
 18%|███████████████████████████▌                                                                                                                            | 218/1200 [10:46<48:42,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|███████████████████████████▌                                                                                                                            | 218/1200 [10:47<48:42,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-218
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-218/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-218/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-218/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-218/special_tokens_map.json
{'eval_loss': 1.161503553390503, 'eval_f1': 0.48211592811816767, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.443, 'eval_steps_per_second': 5.872, 'epoch': 18.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-217] due to args.save_total_limit
 18%|███████████████████████████▋                                                                                                                            | 219/1200 [10:49<48:32,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|███████████████████████████▋                                                                                                                            | 219/1200 [10:50<48:32,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-219
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-219/config.json
{'eval_loss': 1.1623286008834839, 'eval_f1': 0.5005243764172336, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.608, 'eval_steps_per_second': 5.88, 'epoch': 18.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-219/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-219/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-219/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-218] due to args.save_total_limit
 18%|███████████████████████████▊                                                                                                                            | 220/1200 [10:52<48:06,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.164448618888855, 'eval_f1': 0.47445358788676756, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.452, 'eval_steps_per_second': 5.873, 'epoch': 18.33}
 18%|███████████████████████████▊                                                                                                                            | 220/1200 [10:53<48:06,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-220
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-220/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-220/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-220/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-220/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-219] due to args.save_total_limit
 18%|███████████████████████████▉                                                                                                                            | 221/1200 [10:55<48:08,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|███████████████████████████▉                                                                                                                            | 221/1200 [10:56<48:08,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-221
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-221/config.json
{'eval_loss': 1.1600996255874634, 'eval_f1': 0.484828947368421, 'eval_runtime': 0.5169, 'eval_samples_per_second': 116.083, 'eval_steps_per_second': 5.804, 'epoch': 18.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-221/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-221/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-221/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-220] due to args.save_total_limit
{'eval_loss': 1.15798819065094, 'eval_f1': 0.48888888888888893, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.616, 'eval_steps_per_second': 5.881, 'epoch': 18.5}
 18%|████████████████████████████                                                                                                                            | 222/1200 [10:58<48:02,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 18%|████████████████████████████                                                                                                                            | 222/1200 [10:59<48:02,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-222
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-222/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-222/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-222/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-222/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-221] due to args.save_total_limit
 19%|████████████████████████████▏                                                                                                                           | 223/1200 [11:01<48:09,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 19%|████████████████████████████▏                                                                                                                           | 223/1200 [11:02<48:09,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-223
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-223/config.json
{'eval_loss': 1.1779874563217163, 'eval_f1': 0.49229446164430685, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.045, 'eval_steps_per_second': 5.852, 'epoch': 18.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-223/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-223/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-223/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-222] due to args.save_total_limit
 19%|████████████████████████████▎                                                                                                                           | 224/1200 [11:04<48:03,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.2200514078140259, 'eval_f1': 0.5130665816462086, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.532, 'eval_steps_per_second': 5.877, 'epoch': 18.67}
 19%|████████████████████████████▎                                                                                                                           | 224/1200 [11:05<48:03,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-224
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-224/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-224/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-224/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-224/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-223] due to args.save_total_limit
 19%|████████████████████████████▌                                                                                                                           | 225/1200 [11:07<47:35,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 19%|████████████████████████████▌                                                                                                                           | 225/1200 [11:07<47:35,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-225
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-225/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-225/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-225/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-225/special_tokens_map.json
{'eval_loss': 1.2766368389129639, 'eval_f1': 0.4870531400966184, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.796, 'eval_steps_per_second': 5.89, 'epoch': 18.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-224] due to args.save_total_limit
 19%|████████████████████████████▋                                                                                                                           | 226/1200 [11:10<47:20,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 19%|████████████████████████████▋                                                                                                                           | 226/1200 [11:10<47:20,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-226
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-226/config.json
{'eval_loss': 1.3168413639068604, 'eval_f1': 0.4286040751998199, 'eval_runtime': 0.5129, 'eval_samples_per_second': 116.982, 'eval_steps_per_second': 5.849, 'epoch': 18.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-226/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-226/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-226/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-225] due to args.save_total_limit
{'eval_loss': 1.3493672609329224, 'eval_f1': 0.42043958508550605, 'eval_runtime': 0.5172, 'eval_samples_per_second': 116.019, 'eval_steps_per_second': 5.801, 'epoch': 18.92}
 19%|████████████████████████████▊                                                                                                                           | 227/1200 [11:13<47:02,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 19%|████████████████████████████▊                                                                                                                           | 227/1200 [11:13<47:02,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-227
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-227/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-227/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-227/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-227/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-226] due to args.save_total_limit
 19%|████████████████████████████▉                                                                                                                           | 228/1200 [11:16<48:52,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.3558541536331177, 'eval_f1': 0.41710875331564984, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.77, 'eval_steps_per_second': 5.888, 'epoch': 19.0}
                                                                                                                                                                                                Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-228
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-228/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-228/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-228/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-228/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-227] due to args.save_total_limit
 19%|█████████████████████████████                                                                                                                           | 229/1200 [11:19<48:31,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 19%|█████████████████████████████                                                                                                                           | 229/1200 [11:19<48:31,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-229
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-229/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-229/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-229/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-229/special_tokens_map.json
{'eval_loss': 1.331210970878601, 'eval_f1': 0.41710875331564984, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.451, 'eval_steps_per_second': 5.873, 'epoch': 19.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-228] due to args.save_total_limit
 19%|█████████████████████████████▏                                                                                                                          | 230/1200 [11:22<47:53,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-230/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-230/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-230/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-230/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-229] due to args.save_total_limit
 19%|█████████████████████████████▎                                                                                                                          | 231/1200 [11:25<47:30,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 19%|█████████████████████████████▎                                                                                                                          | 231/1200 [11:25<47:30,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-231
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-231/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-231/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-231/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-231/special_tokens_map.json
{'eval_loss': 1.2146047353744507, 'eval_f1': 0.52231128489193, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.521, 'eval_steps_per_second': 5.876, 'epoch': 19.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-230] due to args.save_total_limit
 19%|█████████████████████████████▍                                                                                                                          | 232/1200 [11:28<47:20,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 19%|█████████████████████████████▍                                                                                                                          | 232/1200 [11:28<47:20,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-232
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-232/config.json
{'eval_loss': 1.1749054193496704, 'eval_f1': 0.5581006244845058, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.825, 'eval_steps_per_second': 5.841, 'epoch': 19.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-232/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-232/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-232/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-231] due to args.save_total_limit
{'eval_loss': 1.1400386095046997, 'eval_f1': 0.49229446164430685, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.662, 'eval_steps_per_second': 5.883, 'epoch': 19.42}
 19%|█████████████████████████████▌                                                                                                                          | 233/1200 [11:31<47:58,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 19%|█████████████████████████████▌                                                                                                                          | 233/1200 [11:31<47:58,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-233
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-233/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-233/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-233/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-233/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-232] due to args.save_total_limit
 20%|█████████████████████████████▋                                                                                                                          | 234/1200 [11:33<47:24,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 20%|█████████████████████████████▋                                                                                                                          | 234/1200 [11:34<47:24,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-234
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-234/config.json
{'eval_loss': 1.123823642730713, 'eval_f1': 0.4939727242248251, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.565, 'eval_steps_per_second': 5.878, 'epoch': 19.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-234/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-234/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-234/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-233] due to args.save_total_limit
 20%|█████████████████████████████▊                                                                                                                          | 235/1200 [11:36<47:13,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-235/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-235/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-235/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-235/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-234] due to args.save_total_limit
 20%|█████████████████████████████▉                                                                                                                          | 236/1200 [11:39<46:59,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 20%|█████████████████████████████▉                                                                                                                          | 236/1200 [11:40<46:59,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-236
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-236/config.json
{'eval_loss': 1.1043167114257812, 'eval_f1': 0.5529705907280279, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.461, 'eval_steps_per_second': 5.873, 'epoch': 19.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-236/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-236/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-236/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-235] due to args.save_total_limit
 20%|██████████████████████████████                                                                                                                          | 237/1200 [11:42<46:52,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.0992037057876587, 'eval_f1': 0.5529705907280279, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.677, 'eval_steps_per_second': 5.884, 'epoch': 19.75}
 20%|██████████████████████████████                                                                                                                          | 237/1200 [11:43<46:52,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-237
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-237/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-237/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-237/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-237/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-236] due to args.save_total_limit
 20%|██████████████████████████████▏                                                                                                                         | 238/1200 [11:45<46:38,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 20%|██████████████████████████████▏                                                                                                                         | 238/1200 [11:46<46:38,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-238
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-238/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-238/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-238/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-238/special_tokens_map.json
{'eval_loss': 1.0998046398162842, 'eval_f1': 0.5589930355887802, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.584, 'eval_steps_per_second': 5.879, 'epoch': 19.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-237] due to args.save_total_limit
 20%|██████████████████████████████▎                                                                                                                         | 239/1200 [11:48<46:43,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.47it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-239/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-239/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-239/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-239/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-238] due to args.save_total_limit
 20%|██████████████████████████████▍                                                                                                                         | 240/1200 [11:51<48:14,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 20%|██████████████████████████████▍                                                                                                                         | 240/1200 [11:52<48:14,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-240
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-240/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-240/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-240/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-240/special_tokens_map.json
{'eval_loss': 1.0977286100387573, 'eval_f1': 0.5258465608465609, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.55, 'eval_steps_per_second': 5.877, 'epoch': 20.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-239] due to args.save_total_limit
 20%|██████████████████████████████▌                                                                                                                         | 241/1200 [11:54<47:59,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.30it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-241/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-241/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-241/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-241/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-240] due to args.save_total_limit
 20%|██████████████████████████████▋                                                                                                                         | 242/1200 [11:57<47:23,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 20%|██████████████████████████████▋                                                                                                                         | 242/1200 [11:58<47:23,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-242
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-242/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-242/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-242/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-242/special_tokens_map.json
{'eval_loss': 1.0979478359222412, 'eval_f1': 0.54267131242741, 'eval_runtime': 0.5125, 'eval_samples_per_second': 117.073, 'eval_steps_per_second': 5.854, 'epoch': 20.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-241] due to args.save_total_limit
 20%|██████████████████████████████▊                                                                                                                         | 243/1200 [12:00<46:57,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 20%|██████████████████████████████▊                                                                                                                         | 243/1200 [12:01<46:57,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-243
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-243/config.json
{'eval_loss': 1.1103017330169678, 'eval_f1': 0.5249184334980604, 'eval_runtime': 0.5195, 'eval_samples_per_second': 115.492, 'eval_steps_per_second': 5.775, 'epoch': 20.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-243/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-243/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-243/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-242] due to args.save_total_limit
 20%|██████████████████████████████▉                                                                                                                         | 244/1200 [12:03<46:42,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.1239567995071411, 'eval_f1': 0.5720354808590103, 'eval_runtime': 0.5174, 'eval_samples_per_second': 115.957, 'eval_steps_per_second': 5.798, 'epoch': 20.33}
 20%|██████████████████████████████▉                                                                                                                         | 244/1200 [12:03<46:42,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-244
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-244/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-244/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-244/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-244/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-243] due to args.save_total_limit
 20%|███████████████████████████████                                                                                                                         | 245/1200 [12:06<46:49,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 20%|███████████████████████████████                                                                                                                         | 245/1200 [12:06<46:49,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-245
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-245/config.json
{'eval_loss': 1.158216118812561, 'eval_f1': 0.5856209150326798, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.785, 'eval_steps_per_second': 5.889, 'epoch': 20.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-245/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-245/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-245/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-244] due to args.save_total_limit
 20%|███████████████████████████████▏                                                                                                                        | 246/1200 [12:09<48:19,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 20%|███████████████████████████████▏                                                                                                                        | 246/1200 [12:10<48:19,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-246
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-246/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-246/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-246/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-246/special_tokens_map.json
{'eval_loss': 1.2066665887832642, 'eval_f1': 0.5534097915895918, 'eval_runtime': 0.5079, 'eval_samples_per_second': 118.131, 'eval_steps_per_second': 5.907, 'epoch': 20.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-245] due to args.save_total_limit
 21%|███████████████████████████████▎                                                                                                                        | 247/1200 [12:12<47:56,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 21%|███████████████████████████████▎                                                                                                                        | 247/1200 [12:13<47:56,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-247
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-247/config.json
{'eval_loss': 1.2550684213638306, 'eval_f1': 0.5460479797979798, 'eval_runtime': 0.5185, 'eval_samples_per_second': 115.723, 'eval_steps_per_second': 5.786, 'epoch': 20.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-247/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-247/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-247/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-246] due to args.save_total_limit
{'eval_loss': 1.2749857902526855, 'eval_f1': 0.5246274287870213, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.535, 'eval_steps_per_second': 5.877, 'epoch': 20.67}
 21%|███████████████████████████████▍                                                                                                                        | 248/1200 [12:15<47:35,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 21%|███████████████████████████████▍                                                                                                                        | 248/1200 [12:16<47:35,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-248
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-248/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-248/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-248/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-248/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-247] due to args.save_total_limit
 21%|███████████████████████████████▌                                                                                                                        | 249/1200 [12:18<47:21,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 21%|███████████████████████████████▌                                                                                                                        | 249/1200 [12:19<47:21,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-249
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-249/config.json
{'eval_loss': 1.281484603881836, 'eval_f1': 0.5035340802987862, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.718, 'eval_steps_per_second': 5.886, 'epoch': 20.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-249/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-249/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-249/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-248] due to args.save_total_limit
 21%|███████████████████████████████▋                                                                                                                        | 250/1200 [12:21<46:43,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.2660220861434937, 'eval_f1': 0.5069135802469137, 'eval_runtime': 0.5203, 'eval_samples_per_second': 115.312, 'eval_steps_per_second': 5.766, 'epoch': 20.83}
 21%|███████████████████████████████▋                                                                                                                        | 250/1200 [12:21<46:43,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-250
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-250/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-250/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-250/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-250/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-249] due to args.save_total_limit
 21%|███████████████████████████████▊                                                                                                                        | 251/1200 [12:24<46:21,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 21%|███████████████████████████████▊                                                                                                                        | 251/1200 [12:24<46:21,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-251
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-251/config.json
{'eval_loss': 1.238736629486084, 'eval_f1': 0.5668055555555556, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.394, 'eval_steps_per_second': 5.87, 'epoch': 20.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-251/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-251/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-251/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-250] due to args.save_total_limit
 21%|███████████████████████████████▉                                                                                                                        | 252/1200 [12:27<46:23,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.2225085496902466, 'eval_f1': 0.5725580299281253, 'eval_runtime': 0.5237, 'eval_samples_per_second': 114.57, 'eval_steps_per_second': 5.729, 'epoch': 21.0}
 21%|███████████████████████████████▉                                                                                                                        | 252/1200 [12:27<46:23,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-252
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-252/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-252/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-252/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-252/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-251] due to args.save_total_limit
 21%|████████████████████████████████                                                                                                                        | 253/1200 [12:30<46:08,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 21%|████████████████████████████████                                                                                                                        | 253/1200 [12:30<46:08,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-253
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-253/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-253/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-253/tokenizer_config.json
{'eval_loss': 1.2024413347244263, 'eval_f1': 0.5726787034104107, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.7, 'eval_steps_per_second': 5.885, 'epoch': 21.08}
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-253/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-252] due to args.save_total_limit
 21%|████████████████████████████████▏                                                                                                                       | 254/1200 [12:33<46:02,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-254/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-254/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-254/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-254/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-253] due to args.save_total_limit
 21%|████████████████████████████████▎                                                                                                                       | 255/1200 [12:35<46:02,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 21%|████████████████████████████████▎                                                                                                                       | 255/1200 [12:36<46:02,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-255
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-255/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-255/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-255/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-255/special_tokens_map.json
{'eval_loss': 1.1783432960510254, 'eval_f1': 0.5326077097505668, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.123, 'eval_steps_per_second': 5.856, 'epoch': 21.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-254] due to args.save_total_limit
 21%|████████████████████████████████▍                                                                                                                       | 256/1200 [12:39<47:52,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-256/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-256/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-256/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-256/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-255] due to args.save_total_limit
 21%|████████████████████████████████▌                                                                                                                       | 257/1200 [12:42<47:08,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 21%|████████████████████████████████▌                                                                                                                       | 257/1200 [12:42<47:08,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-257
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-257/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-257/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-257/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-257/special_tokens_map.json
{'eval_loss': 1.2392058372497559, 'eval_f1': 0.46735775391237566, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.88, 'eval_steps_per_second': 5.844, 'epoch': 21.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-256] due to args.save_total_limit
 22%|████████████████████████████████▋                                                                                                                       | 258/1200 [12:45<46:47,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.51it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-258/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-258/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-258/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-258/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-257] due to args.save_total_limit
 22%|████████████████████████████████▊                                                                                                                       | 259/1200 [12:48<46:34,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|████████████████████████████████▊                                                                                                                       | 259/1200 [12:48<46:34,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-259
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-259/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-259/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-259/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-259/special_tokens_map.json
{'eval_loss': 1.2861536741256714, 'eval_f1': 0.5145653817082388, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.764, 'eval_steps_per_second': 5.888, 'epoch': 21.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-258] due to args.save_total_limit
 22%|████████████████████████████████▉                                                                                                                       | 260/1200 [12:50<46:03,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|████████████████████████████████▉                                                                                                                       | 260/1200 [12:51<46:03,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-260
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-260/config.json
{'eval_loss': 1.3137890100479126, 'eval_f1': 0.5334791934791935, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.766, 'eval_steps_per_second': 5.888, 'epoch': 21.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-260/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-260/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-260/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-259] due to args.save_total_limit
 22%|█████████████████████████████████                                                                                                                       | 261/1200 [12:53<45:53,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.356637954711914, 'eval_f1': 0.5198167092924126, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.515, 'eval_steps_per_second': 5.876, 'epoch': 21.75}
 22%|█████████████████████████████████                                                                                                                       | 261/1200 [12:54<45:53,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-261
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-261/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-261/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-261/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-261/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-260] due to args.save_total_limit
 22%|█████████████████████████████████▏                                                                                                                      | 262/1200 [12:56<45:46,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|█████████████████████████████████▏                                                                                                                      | 262/1200 [12:57<45:46,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-262
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-262/config.json
{'eval_loss': 1.4121203422546387, 'eval_f1': 0.5153229974160206, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.607, 'eval_steps_per_second': 5.88, 'epoch': 21.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-262/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-262/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-262/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-261] due to args.save_total_limit
{'eval_loss': 1.4447498321533203, 'eval_f1': 0.5438888888888889, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.54, 'eval_steps_per_second': 5.877, 'epoch': 21.92}
 22%|█████████████████████████████████▎                                                                                                                      | 263/1200 [12:59<45:53,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|█████████████████████████████████▎                                                                                                                      | 263/1200 [13:00<45:53,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-263
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-263/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-263/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-263/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-263/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-262] due to args.save_total_limit
 22%|█████████████████████████████████▍                                                                                                                      | 264/1200 [13:02<45:39,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|█████████████████████████████████▍                                                                                                                      | 264/1200 [13:03<45:39,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-264
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-264/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-264/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-264/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-264/special_tokens_map.json
{'eval_loss': 1.4801772832870483, 'eval_f1': 0.5217818740399385, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.589, 'eval_steps_per_second': 5.879, 'epoch': 22.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-263] due to args.save_total_limit
 22%|█████████████████████████████████▌                                                                                                                      | 265/1200 [13:05<45:59,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-265/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-265/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-265/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-265/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-264] due to args.save_total_limit
 22%|█████████████████████████████████▋                                                                                                                      | 266/1200 [13:08<45:40,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|█████████████████████████████████▋                                                                                                                      | 266/1200 [13:09<45:40,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-266
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-266/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-266/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-266/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-266/special_tokens_map.json
{'eval_loss': 1.6355808973312378, 'eval_f1': 0.5133333333333333, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.651, 'eval_steps_per_second': 5.883, 'epoch': 22.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-265] due to args.save_total_limit
 22%|█████████████████████████████████▊                                                                                                                      | 267/1200 [13:11<45:19,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|█████████████████████████████████▊                                                                                                                      | 267/1200 [13:11<45:19,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-267
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-267/config.json
{'eval_loss': 1.763332724571228, 'eval_f1': 0.5270186335403727, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.447, 'eval_steps_per_second': 5.872, 'epoch': 22.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-267/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-267/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-267/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-266] due to args.save_total_limit
 22%|█████████████████████████████████▉                                                                                                                      | 268/1200 [13:14<45:11,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|█████████████████████████████████▉                                                                                                                      | 268/1200 [13:14<45:11,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-268
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-268/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-268/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-268/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-268/special_tokens_map.json
{'eval_loss': 1.8923771381378174, 'eval_f1': 0.49832752613240416, 'eval_runtime': 0.5195, 'eval_samples_per_second': 115.502, 'eval_steps_per_second': 5.775, 'epoch': 22.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-267] due to args.save_total_limit
 22%|██████████████████████████████████                                                                                                                      | 269/1200 [13:17<47:08,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|██████████████████████████████████                                                                                                                      | 269/1200 [13:18<47:08,  3.04s/it]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-269/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-269/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-269/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-269/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-268] due to args.save_total_limit
 22%|██████████████████████████████████▏                                                                                                                     | 270/1200 [13:20<46:25,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 22%|██████████████████████████████████▏                                                                                                                     | 270/1200 [13:21<46:25,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-270
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-270/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-270/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-270/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-270/special_tokens_map.json
{'eval_loss': 1.4285894632339478, 'eval_f1': 0.5081915780696269, 'eval_runtime': 0.5144, 'eval_samples_per_second': 116.638, 'eval_steps_per_second': 5.832, 'epoch': 22.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-269] due to args.save_total_limit
 23%|██████████████████████████████████▎                                                                                                                     | 271/1200 [13:23<46:02,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 23%|██████████████████████████████████▎                                                                                                                     | 271/1200 [13:23<46:02,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-271
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-271/config.json
{'eval_loss': 1.183844804763794, 'eval_f1': 0.5170086639306886, 'eval_runtime': 0.5127, 'eval_samples_per_second': 117.018, 'eval_steps_per_second': 5.851, 'epoch': 22.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-271/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-271/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-271/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-270] due to args.save_total_limit
{'eval_loss': 1.1747711896896362, 'eval_f1': 0.5425277161862527, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.375, 'eval_steps_per_second': 5.869, 'epoch': 22.67}
 23%|██████████████████████████████████▍                                                                                                                     | 272/1200 [13:26<45:42,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 23%|██████████████████████████████████▍                                                                                                                     | 272/1200 [13:26<45:42,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-272
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-272/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-272/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-272/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-272/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-271] due to args.save_total_limit
 23%|██████████████████████████████████▌                                                                                                                     | 273/1200 [13:29<45:32,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 23%|██████████████████████████████████▌                                                                                                                     | 273/1200 [13:29<45:32,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-273
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-273/config.json
{'eval_loss': 1.1780140399932861, 'eval_f1': 0.5376984126984127, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.364, 'eval_steps_per_second': 5.868, 'epoch': 22.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-273/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-273/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-273/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-272] due to args.save_total_limit
 23%|██████████████████████████████████▋                                                                                                                     | 274/1200 [13:32<45:26,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.2045916318893433, 'eval_f1': 0.5566160009426182, 'eval_runtime': 0.5135, 'eval_samples_per_second': 116.851, 'eval_steps_per_second': 5.843, 'epoch': 22.83}
 23%|██████████████████████████████████▋                                                                                                                     | 274/1200 [13:32<45:26,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-274
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-274/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-274/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-274/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-274/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-273] due to args.save_total_limit
 23%|██████████████████████████████████▊                                                                                                                     | 275/1200 [13:35<45:27,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 23%|██████████████████████████████████▊                                                                                                                     | 275/1200 [13:35<45:27,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-275
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-275/config.json
{'eval_loss': 1.2639919519424438, 'eval_f1': 0.5865384615384616, 'eval_runtime': 0.515, 'eval_samples_per_second': 116.5, 'eval_steps_per_second': 5.825, 'epoch': 22.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-275/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-275/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-275/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-274] due to args.save_total_limit
{'eval_loss': 1.3739171028137207, 'eval_f1': 0.5736986362173618, 'eval_runtime': 0.5163, 'eval_samples_per_second': 116.209, 'eval_steps_per_second': 5.81, 'epoch': 23.0}
 23%|██████████████████████████████████▉                                                                                                                     | 276/1200 [13:38<45:17,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 23%|██████████████████████████████████▉                                                                                                                     | 276/1200 [13:38<45:17,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-276
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-276/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-276/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-276/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-276/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-275] due to args.save_total_limit
 23%|███████████████████████████████████                                                                                                                     | 277/1200 [13:40<44:51,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 23%|███████████████████████████████████                                                                                                                     | 277/1200 [13:41<44:51,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-277
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-277/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-277/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-277/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-277/special_tokens_map.json
{'eval_loss': 1.4694674015045166, 'eval_f1': 0.5240251745998872, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.811, 'eval_steps_per_second': 5.891, 'epoch': 23.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-276] due to args.save_total_limit
 23%|███████████████████████████████████▏                                                                                                                    | 278/1200 [13:43<44:51,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-278/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-278/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-278/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-278/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-277] due to args.save_total_limit
 23%|███████████████████████████████████▎                                                                                                                    | 279/1200 [13:47<46:39,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 23%|███████████████████████████████████▎                                                                                                                    | 279/1200 [13:47<46:39,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-279
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-279/config.json
{'eval_loss': 1.5586936473846436, 'eval_f1': 0.4725921002424824, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.482, 'eval_steps_per_second': 5.874, 'epoch': 23.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-279/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-279/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-279/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-278] due to args.save_total_limit
 23%|███████████████████████████████████▍                                                                                                                    | 280/1200 [13:50<45:51,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-280/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-280/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-280/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-280/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-279] due to args.save_total_limit
 23%|███████████████████████████████████▌                                                                                                                    | 281/1200 [13:53<45:29,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 23%|███████████████████████████████████▌                                                                                                                    | 281/1200 [13:53<45:29,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-281
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-281/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-281/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-281/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-281/special_tokens_map.json
{'eval_loss': 1.484844446182251, 'eval_f1': 0.5038527836012112, 'eval_runtime': 0.5151, 'eval_samples_per_second': 116.472, 'eval_steps_per_second': 5.824, 'epoch': 23.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-280] due to args.save_total_limit
 24%|███████████████████████████████████▋                                                                                                                    | 282/1200 [13:55<45:11,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|███████████████████████████████████▋                                                                                                                    | 282/1200 [13:56<45:11,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-282
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-282/config.json
{'eval_loss': 1.4051145315170288, 'eval_f1': 0.5433057775955912, 'eval_runtime': 0.5161, 'eval_samples_per_second': 116.257, 'eval_steps_per_second': 5.813, 'epoch': 23.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-282/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-282/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-282/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-281] due to args.save_total_limit
 24%|███████████████████████████████████▊                                                                                                                    | 283/1200 [13:58<44:59,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|███████████████████████████████████▊                                                                                                                    | 283/1200 [13:59<44:59,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-283
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-283/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-283/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-283/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-283/special_tokens_map.json
{'eval_loss': 1.3109781742095947, 'eval_f1': 0.5316268074110726, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.74, 'eval_steps_per_second': 5.887, 'epoch': 23.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-282] due to args.save_total_limit
 24%|███████████████████████████████████▉                                                                                                                    | 284/1200 [14:01<44:32,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|███████████████████████████████████▉                                                                                                                    | 284/1200 [14:02<44:32,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-284
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-284/config.json
{'eval_loss': 1.2314783334732056, 'eval_f1': 0.5341704991465259, 'eval_runtime': 0.5117, 'eval_samples_per_second': 117.265, 'eval_steps_per_second': 5.863, 'epoch': 23.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-284/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-284/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-284/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-283] due to args.save_total_limit
{'eval_loss': 1.1873410940170288, 'eval_f1': 0.5497222222222222, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.686, 'eval_steps_per_second': 5.884, 'epoch': 23.75}
 24%|████████████████████████████████████                                                                                                                    | 285/1200 [14:04<44:26,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|████████████████████████████████████                                                                                                                    | 285/1200 [14:05<44:26,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-285
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-285/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-285/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-285/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-285/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-284] due to args.save_total_limit
 24%|████████████████████████████████████▏                                                                                                                   | 286/1200 [14:07<44:36,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|████████████████████████████████████▏                                                                                                                   | 286/1200 [14:08<44:36,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-286
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-286/config.json
{'eval_loss': 1.1683990955352783, 'eval_f1': 0.5303267973856209, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.176, 'eval_steps_per_second': 5.859, 'epoch': 23.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-286/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-286/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-286/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-285] due to args.save_total_limit
 24%|████████████████████████████████████▎                                                                                                                   | 287/1200 [14:10<44:34,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.1637661457061768, 'eval_f1': 0.5125228758169934, 'eval_runtime': 0.5157, 'eval_samples_per_second': 116.355, 'eval_steps_per_second': 5.818, 'epoch': 23.92}
 24%|████████████████████████████████████▎                                                                                                                   | 287/1200 [14:11<44:34,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-287
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-287/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-287/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-287/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-287/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-286] due to args.save_total_limit
 24%|████████████████████████████████████▍                                                                                                                   | 288/1200 [14:13<44:21,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|████████████████████████████████████▍                                                                                                                   | 288/1200 [14:13<44:21,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-288
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-288/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-288/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-288/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-288/special_tokens_map.json
{'eval_loss': 1.1620136499404907, 'eval_f1': 0.5326077097505668, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.722, 'eval_steps_per_second': 5.886, 'epoch': 24.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-287] due to args.save_total_limit
 24%|████████████████████████████████████▌                                                                                                                   | 289/1200 [14:16<44:02,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|████████████████████████████████████▌                                                                                                                   | 289/1200 [14:16<44:02,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-289
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-289/config.json
{'eval_loss': 1.166775107383728, 'eval_f1': 0.5703405533192767, 'eval_runtime': 0.5209, 'eval_samples_per_second': 115.184, 'eval_steps_per_second': 5.759, 'epoch': 24.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-289/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-289/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-289/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-288] due to args.save_total_limit
 24%|████████████████████████████████████▋                                                                                                                   | 290/1200 [14:19<44:27,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|████████████████████████████████████▋                                                                                                                   | 290/1200 [14:19<44:27,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-290
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-290/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-290/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-290/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-290/special_tokens_map.json
{'eval_loss': 1.179146409034729, 'eval_f1': 0.576984126984127, 'eval_runtime': 0.513, 'eval_samples_per_second': 116.968, 'eval_steps_per_second': 5.848, 'epoch': 24.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-289] due to args.save_total_limit
 24%|████████████████████████████████████▊                                                                                                                   | 291/1200 [14:22<44:08,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|████████████████████████████████████▊                                                                                                                   | 291/1200 [14:22<44:08,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-291
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-291/config.json
{'eval_loss': 1.2165929079055786, 'eval_f1': 0.5451914098972922, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.779, 'eval_steps_per_second': 5.889, 'epoch': 24.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-291/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-291/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-291/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-290] due to args.save_total_limit
 24%|████████████████████████████████████▉                                                                                                                   | 292/1200 [14:25<44:09,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|████████████████████████████████████▉                                                                                                                   | 292/1200 [14:25<44:09,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-292
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-292/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-292/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-292/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-292/special_tokens_map.json
{'eval_loss': 1.2875289916992188, 'eval_f1': 0.5566160009426182, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.371, 'eval_steps_per_second': 5.869, 'epoch': 24.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-291] due to args.save_total_limit
 24%|█████████████████████████████████████                                                                                                                   | 293/1200 [14:28<44:06,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|█████████████████████████████████████                                                                                                                   | 293/1200 [14:28<44:06,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-293
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-293/config.json
{'eval_loss': 1.370561122894287, 'eval_f1': 0.5372368875086266, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.466, 'eval_steps_per_second': 5.873, 'epoch': 24.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-293/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-293/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-293/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-292] due to args.save_total_limit
{'eval_loss': 1.450138807296753, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5226, 'eval_samples_per_second': 114.806, 'eval_steps_per_second': 5.74, 'epoch': 24.5}
 24%|█████████████████████████████████████▏                                                                                                                  | 294/1200 [14:30<44:21,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 24%|█████████████████████████████████████▏                                                                                                                  | 294/1200 [14:31<44:21,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-294
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-294/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-294/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-294/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-294/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-293] due to args.save_total_limit
 25%|█████████████████████████████████████▎                                                                                                                  | 295/1200 [14:33<44:11,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 25%|█████████████████████████████████████▎                                                                                                                  | 295/1200 [14:34<44:11,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-295
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-295/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-295/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-295/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-295/special_tokens_map.json
{'eval_loss': 1.4903379678726196, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.572, 'eval_steps_per_second': 5.879, 'epoch': 24.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-294] due to args.save_total_limit
 25%|█████████████████████████████████████▍                                                                                                                  | 296/1200 [14:36<44:25,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-296/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-296/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-296/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-296/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-295] due to args.save_total_limit
 25%|█████████████████████████████████████▌                                                                                                                  | 297/1200 [14:39<43:57,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 25%|█████████████████████████████████████▌                                                                                                                  | 297/1200 [14:40<43:57,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-297
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-297/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-297/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-297/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-297/special_tokens_map.json
{'eval_loss': 1.4840044975280762, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5143, 'eval_samples_per_second': 116.668, 'eval_steps_per_second': 5.833, 'epoch': 24.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-296] due to args.save_total_limit
 25%|█████████████████████████████████████▋                                                                                                                  | 298/1200 [14:42<43:37,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 25%|█████████████████████████████████████▋                                                                                                                  | 298/1200 [14:43<43:37,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-298
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-298/config.json
{'eval_loss': 1.4795989990234375, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5193, 'eval_samples_per_second': 115.538, 'eval_steps_per_second': 5.777, 'epoch': 24.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-298/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-298/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-298/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-297] due to args.save_total_limit
 25%|█████████████████████████████████████▊                                                                                                                  | 299/1200 [14:45<45:20,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 25%|█████████████████████████████████████▊                                                                                                                  | 299/1200 [14:46<45:20,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-299
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-299/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-299/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-299/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-299/special_tokens_map.json
{'eval_loss': 1.4569263458251953, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.742, 'eval_steps_per_second': 5.887, 'epoch': 24.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-298] due to args.save_total_limit
 25%|██████████████████████████████████████                                                                                                                  | 300/1200 [14:48<44:41,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 25%|██████████████████████████████████████                                                                                                                  | 300/1200 [14:49<44:41,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-300
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-300/config.json
{'eval_loss': 1.4135158061981201, 'eval_f1': 0.5071630060292851, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.781, 'eval_steps_per_second': 5.889, 'epoch': 25.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-300/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-300/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-300/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-299] due to args.save_total_limit
{'eval_loss': 1.3556983470916748, 'eval_f1': 0.5038759689922481, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.058, 'eval_steps_per_second': 5.853, 'epoch': 25.08}
 25%|██████████████████████████████████████▏                                                                                                                 | 301/1200 [14:51<44:13,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 25%|██████████████████████████████████████▏                                                                                                                 | 301/1200 [14:52<44:13,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-301
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-301/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-301/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-301/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-301/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-300] due to args.save_total_limit
 25%|██████████████████████████████████████▎                                                                                                                 | 302/1200 [14:54<45:46,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.3225154876708984, 'eval_f1': 0.5210872565065306, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.528, 'eval_steps_per_second': 5.876, 'epoch': 25.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-302/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-302/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-302/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-301] due to args.save_total_limit
 25%|██████████████████████████████████████▍                                                                                                                 | 303/1200 [14:57<44:51,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 25%|██████████████████████████████████████▍                                                                                                                 | 303/1200 [14:58<44:51,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-303
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-303/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-303/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-303/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-303/special_tokens_map.json
{'eval_loss': 1.302978515625, 'eval_f1': 0.5314814814814814, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.172, 'eval_steps_per_second': 5.859, 'epoch': 25.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-302] due to args.save_total_limit
 25%|██████████████████████████████████████▌                                                                                                                 | 304/1200 [15:00<44:49,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-304/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-304/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-304/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-304/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-303] due to args.save_total_limit
 25%|██████████████████████████████████████▋                                                                                                                 | 305/1200 [15:03<44:34,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 25%|██████████████████████████████████████▋                                                                                                                 | 305/1200 [15:04<44:34,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-305
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-305/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-305/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-305/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-305/special_tokens_map.json
{'eval_loss': 1.3290603160858154, 'eval_f1': 0.5193533959491405, 'eval_runtime': 0.5155, 'eval_samples_per_second': 116.402, 'eval_steps_per_second': 5.82, 'epoch': 25.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-304] due to args.save_total_limit
 26%|██████████████████████████████████████▊                                                                                                                 | 306/1200 [15:06<44:08,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|██████████████████████████████████████▊                                                                                                                 | 306/1200 [15:07<44:08,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-306
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-306/config.json
{'eval_loss': 1.3478360176086426, 'eval_f1': 0.49093631997261533, 'eval_runtime': 0.5117, 'eval_samples_per_second': 117.257, 'eval_steps_per_second': 5.863, 'epoch': 25.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-306/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-306/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-306/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-305] due to args.save_total_limit
{'eval_loss': 1.3680500984191895, 'eval_f1': 0.49093631997261533, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.671, 'eval_steps_per_second': 5.884, 'epoch': 25.58}
 26%|██████████████████████████████████████▉                                                                                                                 | 307/1200 [15:09<43:52,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|██████████████████████████████████████▉                                                                                                                 | 307/1200 [15:10<43:52,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-307
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-307/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-307/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-307/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-307/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-306] due to args.save_total_limit
 26%|███████████████████████████████████████                                                                                                                 | 308/1200 [15:12<43:41,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|███████████████████████████████████████                                                                                                                 | 308/1200 [15:13<43:41,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-308
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-308/config.json
{'eval_loss': 1.371508240699768, 'eval_f1': 0.5070322546362719, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.524, 'eval_steps_per_second': 5.876, 'epoch': 25.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-308/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-308/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-308/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-307] due to args.save_total_limit
 26%|███████████████████████████████████████▏                                                                                                                | 309/1200 [15:15<43:48,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-309/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-309/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-309/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-309/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-308] due to args.save_total_limit
 26%|███████████████████████████████████████▎                                                                                                                | 310/1200 [15:18<43:27,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|███████████████████████████████████████▎                                                                                                                | 310/1200 [15:18<43:27,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-310
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-310/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-310/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-310/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-310/special_tokens_map.json
{'eval_loss': 1.426878571510315, 'eval_f1': 0.5339007092198582, 'eval_runtime': 0.5251, 'eval_samples_per_second': 114.272, 'eval_steps_per_second': 5.714, 'epoch': 25.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-309] due to args.save_total_limit
{'eval_loss': 1.4540085792541504, 'eval_f1': 0.5339007092198582, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.475, 'eval_steps_per_second': 5.874, 'epoch': 25.92}
 26%|███████████████████████████████████████▍                                                                                                                | 311/1200 [15:21<43:29,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|███████████████████████████████████████▍                                                                                                                | 311/1200 [15:21<43:29,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-311
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-311/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-311/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-311/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-311/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-310] due to args.save_total_limit
 26%|███████████████████████████████████████▌                                                                                                                | 312/1200 [15:24<43:15,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|███████████████████████████████████████▌                                                                                                                | 312/1200 [15:24<43:15,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-312
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-312/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-312/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-312/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-312/special_tokens_map.json
{'eval_loss': 1.4777839183807373, 'eval_f1': 0.5515277777777778, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.594, 'eval_steps_per_second': 5.88, 'epoch': 26.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-311] due to args.save_total_limit
 26%|███████████████████████████████████████▋                                                                                                                | 313/1200 [15:27<43:06,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-313/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-313/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-313/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-313/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-312] due to args.save_total_limit
 26%|███████████████████████████████████████▊                                                                                                                | 314/1200 [15:30<44:34,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|███████████████████████████████████████▊                                                                                                                | 314/1200 [15:30<44:34,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-314
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-314/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-314/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-314/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-314/special_tokens_map.json
{'eval_loss': 1.5729820728302002, 'eval_f1': 0.5354438997821351, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.824, 'eval_steps_per_second': 5.891, 'epoch': 26.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-313] due to args.save_total_limit
 26%|███████████████████████████████████████▉                                                                                                                | 315/1200 [15:33<43:53,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-315/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-315/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-315/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-315/special_tokens_map.json
{'eval_loss': 1.5487831830978394, 'eval_f1': 0.5509400269541779, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.502, 'eval_steps_per_second': 5.875, 'epoch': 26.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-314] due to args.save_total_limit
 26%|████████████████████████████████████████                                                                                                                | 316/1200 [15:36<43:38,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|████████████████████████████████████████                                                                                                                | 316/1200 [15:36<43:38,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-316
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-316/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-316/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-316/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-316/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-315] due to args.save_total_limit
 26%|████████████████████████████████████████▏                                                                                                               | 317/1200 [15:39<43:28,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|████████████████████████████████████████▏                                                                                                               | 317/1200 [15:39<43:28,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-317
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-317/config.json
{'eval_loss': 1.4830806255340576, 'eval_f1': 0.5575854700854701, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.126, 'eval_steps_per_second': 5.856, 'epoch': 26.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-317/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-317/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-317/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-316] due to args.save_total_limit
{'eval_loss': 1.4238994121551514, 'eval_f1': 0.590519131820759, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.722, 'eval_steps_per_second': 5.886, 'epoch': 26.5}
 26%|████████████████████████████████████████▎                                                                                                               | 318/1200 [15:42<43:13,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 26%|████████████████████████████████████████▎                                                                                                               | 318/1200 [15:42<43:13,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-318
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-318/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-318/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-318/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-318/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-317] due to args.save_total_limit
 27%|████████████████████████████████████████▍                                                                                                               | 319/1200 [15:44<42:56,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 27%|████████████████████████████████████████▍                                                                                                               | 319/1200 [15:45<42:56,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-319
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-319/config.json
{'eval_loss': 1.3970810174942017, 'eval_f1': 0.5537606837606838, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.802, 'eval_steps_per_second': 5.89, 'epoch': 26.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-319/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-319/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-319/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-318] due to args.save_total_limit
{'eval_loss': 1.3765921592712402, 'eval_f1': 0.5715985215985216, 'eval_runtime': 0.5156, 'eval_samples_per_second': 116.377, 'eval_steps_per_second': 5.819, 'epoch': 26.67}
 27%|████████████████████████████████████████▌                                                                                                               | 320/1200 [15:47<43:06,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 27%|████████████████████████████████████████▌                                                                                                               | 320/1200 [15:48<43:06,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-320
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-320/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-320/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-320/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-320/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-319] due to args.save_total_limit
 27%|████████████████████████████████████████▋                                                                                                               | 321/1200 [15:50<43:13,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 27%|████████████████████████████████████████▋                                                                                                               | 321/1200 [15:51<43:13,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-321
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-321/config.json
{'eval_loss': 1.3427146673202515, 'eval_f1': 0.517757809157039, 'eval_runtime': 0.5176, 'eval_samples_per_second': 115.927, 'eval_steps_per_second': 5.796, 'epoch': 26.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-321/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-321/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-321/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-320] due to args.save_total_limit
 27%|████████████████████████████████████████▊                                                                                                               | 322/1200 [15:53<43:00,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.3439487218856812, 'eval_f1': 0.517757809157039, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.507, 'eval_steps_per_second': 5.875, 'epoch': 26.83}
 27%|████████████████████████████████████████▊                                                                                                               | 322/1200 [15:54<43:00,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-322
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-322/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-322/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-322/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-322/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-321] due to args.save_total_limit
 27%|████████████████████████████████████████▉                                                                                                               | 323/1200 [15:56<42:40,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 27%|████████████████████████████████████████▉                                                                                                               | 323/1200 [15:57<42:40,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-323
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-323/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-323/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-323/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-323/special_tokens_map.json
{'eval_loss': 1.3534371852874756, 'eval_f1': 0.5209386130316361, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.689, 'eval_steps_per_second': 5.884, 'epoch': 26.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-322] due to args.save_total_limit
 27%|█████████████████████████████████████████                                                                                                               | 324/1200 [15:59<42:32,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 27%|█████████████████████████████████████████                                                                                                               | 324/1200 [16:00<42:32,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-324
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-324/config.json
{'eval_loss': 1.3581854104995728, 'eval_f1': 0.5209386130316361, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.524, 'eval_steps_per_second': 5.876, 'epoch': 27.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-324/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-324/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-324/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-323] due to args.save_total_limit
 27%|█████████████████████████████████████████▏                                                                                                              | 325/1200 [16:02<42:17,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 27%|█████████████████████████████████████████▏                                                                                                              | 325/1200 [16:02<42:17,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-325
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-325/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-325/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-325/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-325/special_tokens_map.json
{'eval_loss': 1.3735930919647217, 'eval_f1': 0.5209386130316361, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.456, 'eval_steps_per_second': 5.873, 'epoch': 27.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-324] due to args.save_total_limit
 27%|█████████████████████████████████████████▎                                                                                                              | 326/1200 [16:05<42:16,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 27%|█████████████████████████████████████████▎                                                                                                              | 326/1200 [16:05<42:16,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-326
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-326/config.json
{'eval_loss': 1.405325174331665, 'eval_f1': 0.5027951027951028, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.6, 'eval_steps_per_second': 5.88, 'epoch': 27.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-326/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-326/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-326/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-325] due to args.save_total_limit
 27%|█████████████████████████████████████████▍                                                                                                              | 327/1200 [16:08<42:15,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-327/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-327/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-327/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-327/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-326] due to args.save_total_limit
 27%|█████████████████████████████████████████▌                                                                                                              | 328/1200 [16:11<42:08,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 27%|█████████████████████████████████████████▌                                                                                                              | 328/1200 [16:11<42:08,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-328
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-328/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-328/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-328/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-328/special_tokens_map.json
{'eval_loss': 1.4956308603286743, 'eval_f1': 0.4928478850005892, 'eval_runtime': 0.5079, 'eval_samples_per_second': 118.134, 'eval_steps_per_second': 5.907, 'epoch': 27.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-327] due to args.save_total_limit
 27%|█████████████████████████████████████████▋                                                                                                              | 329/1200 [16:14<42:06,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 27%|█████████████████████████████████████████▋                                                                                                              | 329/1200 [16:14<42:06,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-329
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-329/config.json
{'eval_loss': 1.5753371715545654, 'eval_f1': 0.5071630060292851, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.661, 'eval_steps_per_second': 5.883, 'epoch': 27.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-329/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-329/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-329/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-328] due to args.save_total_limit
 28%|█████████████████████████████████████████▊                                                                                                              | 330/1200 [16:17<43:41,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 28%|█████████████████████████████████████████▊                                                                                                              | 330/1200 [16:17<43:41,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-330
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-330/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-330/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-330/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-330/special_tokens_map.json
{'eval_loss': 1.6960972547531128, 'eval_f1': 0.5156700760555992, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.79, 'eval_steps_per_second': 5.889, 'epoch': 27.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-329] due to args.save_total_limit
 28%|█████████████████████████████████████████▉                                                                                                              | 331/1200 [16:20<43:10,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 28%|█████████████████████████████████████████▉                                                                                                              | 331/1200 [16:20<43:10,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-331
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-331/config.json
{'eval_loss': 1.7909793853759766, 'eval_f1': 0.48076023391812867, 'eval_runtime': 0.5181, 'eval_samples_per_second': 115.807, 'eval_steps_per_second': 5.79, 'epoch': 27.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-331/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-331/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-331/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-330] due to args.save_total_limit
 28%|██████████████████████████████████████████                                                                                                              | 332/1200 [16:23<43:08,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 28%|██████████████████████████████████████████                                                                                                              | 332/1200 [16:23<43:08,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-332
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-332/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-332/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-332/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-332/special_tokens_map.json
{'eval_loss': 1.8303020000457764, 'eval_f1': 0.48076023391812867, 'eval_runtime': 0.5113, 'eval_samples_per_second': 117.353, 'eval_steps_per_second': 5.868, 'epoch': 27.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-331] due to args.save_total_limit
 28%|██████████████████████████████████████████▏                                                                                                             | 333/1200 [16:26<43:00,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.42it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-333/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-333/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-333/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-333/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-332] due to args.save_total_limit
 28%|██████████████████████████████████████████▎                                                                                                             | 334/1200 [16:29<42:35,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 28%|██████████████████████████████████████████▎                                                                                                             | 334/1200 [16:29<42:35,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-334
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-334/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-334/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-334/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-334/special_tokens_map.json
{'eval_loss': 1.7653323411941528, 'eval_f1': 0.4947913524384112, 'eval_runtime': 0.5128, 'eval_samples_per_second': 117.014, 'eval_steps_per_second': 5.851, 'epoch': 27.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-333] due to args.save_total_limit
 28%|██████████████████████████████████████████▍                                                                                                             | 335/1200 [16:31<42:21,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 28%|██████████████████████████████████████████▍                                                                                                             | 335/1200 [16:32<42:21,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-335
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-335/config.json
{'eval_loss': 1.6890729665756226, 'eval_f1': 0.5156700760555992, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.545, 'eval_steps_per_second': 5.877, 'epoch': 27.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-335/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-335/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-335/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-334] due to args.save_total_limit
 28%|██████████████████████████████████████████▌                                                                                                             | 336/1200 [16:34<42:25,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 28%|██████████████████████████████████████████▌                                                                                                             | 336/1200 [16:35<42:25,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-336
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-336/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-336/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-336/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-336/special_tokens_map.json
{'eval_loss': 1.5840849876403809, 'eval_f1': 0.521943367786391, 'eval_runtime': 0.5119, 'eval_samples_per_second': 117.204, 'eval_steps_per_second': 5.86, 'epoch': 28.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-335] due to args.save_total_limit
 28%|██████████████████████████████████████████▋                                                                                                             | 337/1200 [16:37<42:40,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 28%|██████████████████████████████████████████▋                                                                                                             | 337/1200 [16:38<42:40,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-337
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-337/config.json
{'eval_loss': 1.5300920009613037, 'eval_f1': 0.5419896640826872, 'eval_runtime': 0.5125, 'eval_samples_per_second': 117.081, 'eval_steps_per_second': 5.854, 'epoch': 28.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-337/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-337/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-337/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-336] due to args.save_total_limit
 28%|██████████████████████████████████████████▊                                                                                                             | 338/1200 [16:40<42:19,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.4829531908035278, 'eval_f1': 0.5407013658176448, 'eval_runtime': 0.5134, 'eval_samples_per_second': 116.866, 'eval_steps_per_second': 5.843, 'epoch': 28.17}
 28%|██████████████████████████████████████████▊                                                                                                             | 338/1200 [16:41<42:19,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-338
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-338/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-338/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-338/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-338/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-337] due to args.save_total_limit
 28%|██████████████████████████████████████████▉                                                                                                             | 339/1200 [16:43<42:33,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 28%|██████████████████████████████████████████▉                                                                                                             | 339/1200 [16:44<42:33,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-339
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-339/config.json
{'eval_loss': 1.4423879384994507, 'eval_f1': 0.5240531561461794, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.712, 'eval_steps_per_second': 5.886, 'epoch': 28.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-339/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-339/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-339/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-338] due to args.save_total_limit
 28%|███████████████████████████████████████████                                                                                                             | 340/1200 [16:46<42:11,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.53it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-340/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-340/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-340/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-340/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-339] due to args.save_total_limit
 28%|███████████████████████████████████████████▏                                                                                                            | 341/1200 [16:50<43:40,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 28%|███████████████████████████████████████████▏                                                                                                            | 341/1200 [16:50<43:40,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-341
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-341/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-341/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-341/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-341/special_tokens_map.json
{'eval_loss': 1.3975319862365723, 'eval_f1': 0.5240531561461794, 'eval_runtime': 0.5091, 'eval_samples_per_second': 117.845, 'eval_steps_per_second': 5.892, 'epoch': 28.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-340] due to args.save_total_limit
 28%|███████████████████████████████████████████▎                                                                                                            | 342/1200 [16:52<43:01,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-342/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-342/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-342/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-342/special_tokens_map.json
{'eval_loss': 1.3828909397125244, 'eval_f1': 0.5240531561461794, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.788, 'eval_steps_per_second': 5.889, 'epoch': 28.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-341] due to args.save_total_limit
 29%|███████████████████████████████████████████▍                                                                                                            | 343/1200 [16:55<42:52,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|███████████████████████████████████████████▍                                                                                                            | 343/1200 [16:56<42:52,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-343
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-343/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-343/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-343/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-343/special_tokens_map.json
{'eval_loss': 1.3859145641326904, 'eval_f1': 0.5407407407407407, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.6, 'eval_steps_per_second': 5.88, 'epoch': 28.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-342] due to args.save_total_limit
 29%|███████████████████████████████████████████▌                                                                                                            | 344/1200 [16:58<42:23,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|███████████████████████████████████████████▌                                                                                                            | 344/1200 [16:59<42:23,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-344
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-344/config.json
{'eval_loss': 1.396691918373108, 'eval_f1': 0.5563817663817664, 'eval_runtime': 0.5154, 'eval_samples_per_second': 116.417, 'eval_steps_per_second': 5.821, 'epoch': 28.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-344/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-344/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-344/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-343] due to args.save_total_limit
 29%|███████████████████████████████████████████▋                                                                                                            | 345/1200 [17:01<42:15,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|███████████████████████████████████████████▋                                                                                                            | 345/1200 [17:02<42:15,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-345
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-345/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-345/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-345/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-345/special_tokens_map.json
{'eval_loss': 1.4247416257858276, 'eval_f1': 0.586657934530275, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.554, 'eval_steps_per_second': 5.878, 'epoch': 28.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-344] due to args.save_total_limit
 29%|███████████████████████████████████████████▊                                                                                                            | 346/1200 [17:04<41:50,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|███████████████████████████████████████████▊                                                                                                            | 346/1200 [17:05<41:50,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-346
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-346/config.json
{'eval_loss': 1.475010633468628, 'eval_f1': 0.601388888888889, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.637, 'eval_steps_per_second': 5.882, 'epoch': 28.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-346/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-346/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-346/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-345] due to args.save_total_limit
 29%|███████████████████████████████████████████▉                                                                                                            | 347/1200 [17:07<41:36,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|███████████████████████████████████████████▉                                                                                                            | 347/1200 [17:08<41:36,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-347
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-347/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-347/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-347/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-347/special_tokens_map.json
{'eval_loss': 1.56443452835083, 'eval_f1': 0.5847857661583152, 'eval_runtime': 0.5166, 'eval_samples_per_second': 116.137, 'eval_steps_per_second': 5.807, 'epoch': 28.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-346] due to args.save_total_limit
 29%|████████████████████████████████████████████                                                                                                            | 348/1200 [17:10<41:54,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|████████████████████████████████████████████                                                                                                            | 348/1200 [17:11<41:54,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-348
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-348/config.json
{'eval_loss': 1.7066854238510132, 'eval_f1': 0.48897911259424043, 'eval_runtime': 0.515, 'eval_samples_per_second': 116.497, 'eval_steps_per_second': 5.825, 'epoch': 29.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-348/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-348/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-348/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-347] due to args.save_total_limit
 29%|████████████████████████████████████████████▏                                                                                                           | 349/1200 [17:13<41:40,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|████████████████████████████████████████████▏                                                                                                           | 349/1200 [17:14<41:40,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-349
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-349/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-349/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-349/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-349/special_tokens_map.json
{'eval_loss': 1.8197473287582397, 'eval_f1': 0.46777777777777785, 'eval_runtime': 0.5115, 'eval_samples_per_second': 117.311, 'eval_steps_per_second': 5.866, 'epoch': 29.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-348] due to args.save_total_limit
 29%|████████████████████████████████████████████▎                                                                                                           | 350/1200 [17:16<41:41,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|████████████████████████████████████████████▎                                                                                                           | 350/1200 [17:16<41:41,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-350
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-350/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-350/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-350/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-350/special_tokens_map.json
{'eval_loss': 1.8804174661636353, 'eval_f1': 0.46777777777777785, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.583, 'eval_steps_per_second': 5.879, 'epoch': 29.17}
{'eval_loss': 1.8921812772750854, 'eval_f1': 0.46777777777777785, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.573, 'eval_steps_per_second': 5.879, 'epoch': 29.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-349] due to args.save_total_limit
 29%|████████████████████████████████████████████▍                                                                                                           | 351/1200 [17:19<41:25,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-351/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-351/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-351/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-351/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-350] due to args.save_total_limit
{'eval_loss': 1.857353687286377, 'eval_f1': 0.46777777777777785, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.776, 'eval_steps_per_second': 5.889, 'epoch': 29.33}
 29%|████████████████████████████████████████████▌                                                                                                           | 352/1200 [17:22<41:07,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|████████████████████████████████████████████▌                                                                                                           | 352/1200 [17:22<41:07,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-352
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-352/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-352/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-352/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-352/special_tokens_map.json
{'eval_loss': 1.792048692703247, 'eval_f1': 0.5246274287870213, 'eval_runtime': 0.5124, 'eval_samples_per_second': 117.102, 'eval_steps_per_second': 5.855, 'epoch': 29.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-351] due to args.save_total_limit
 29%|████████████████████████████████████████████▋                                                                                                           | 353/1200 [17:25<41:11,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 29%|████████████████████████████████████████████▋                                                                                                           | 353/1200 [17:25<41:11,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-353
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-353/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-353/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-353/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-353/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-352] due to args.save_total_limit
 30%|████████████████████████████████████████████▊                                                                                                           | 354/1200 [17:28<41:03,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.7577136754989624, 'eval_f1': 0.5284360243500027, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.798, 'eval_steps_per_second': 5.89, 'epoch': 29.5}
 30%|████████████████████████████████████████████▊                                                                                                           | 354/1200 [17:28<41:03,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-354
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-354/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-354/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-354/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-354/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-353] due to args.save_total_limit
 30%|████████████████████████████████████████████▉                                                                                                           | 355/1200 [17:31<42:33,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-355/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-355/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-355/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-355/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-354] due to args.save_total_limit
{'eval_loss': 1.6847203969955444, 'eval_f1': 0.5317667309431208, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.705, 'eval_steps_per_second': 5.885, 'epoch': 29.67}
 30%|█████████████████████████████████████████████                                                                                                           | 356/1200 [17:34<41:50,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|█████████████████████████████████████████████                                                                                                           | 356/1200 [17:34<41:50,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-356
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-356/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-356/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-356/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-356/special_tokens_map.json
{'eval_loss': 1.6733909845352173, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.744, 'eval_steps_per_second': 5.887, 'epoch': 29.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-355] due to args.save_total_limit
 30%|█████████████████████████████████████████████▏                                                                                                          | 357/1200 [17:37<41:56,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|█████████████████████████████████████████████▏                                                                                                          | 357/1200 [17:37<41:56,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-357
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-357/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-357/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-357/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-357/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-356] due to args.save_total_limit
{'eval_loss': 1.6399188041687012, 'eval_f1': 0.4712128640062751, 'eval_runtime': 0.5127, 'eval_samples_per_second': 117.033, 'eval_steps_per_second': 5.852, 'epoch': 29.83}
 30%|█████████████████████████████████████████████▎                                                                                                          | 358/1200 [17:40<41:28,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|█████████████████████████████████████████████▎                                                                                                          | 358/1200 [17:40<41:28,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-358
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-358/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-358/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-358/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-358/special_tokens_map.json
{'eval_loss': 1.5992467403411865, 'eval_f1': 0.4545589649444881, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.56, 'eval_steps_per_second': 5.878, 'epoch': 29.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-357] due to args.save_total_limit
 30%|█████████████████████████████████████████████▍                                                                                                          | 359/1200 [17:43<41:27,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|█████████████████████████████████████████████▍                                                                                                          | 359/1200 [17:43<41:27,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-359
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-359/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-359/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-359/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-359/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-358] due to args.save_total_limit
 30%|█████████████████████████████████████████████▌                                                                                                          | 360/1200 [17:45<41:20,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.5679404735565186, 'eval_f1': 0.4753782505910165, 'eval_runtime': 0.5258, 'eval_samples_per_second': 114.116, 'eval_steps_per_second': 5.706, 'epoch': 30.0}
 30%|█████████████████████████████████████████████▌                                                                                                          | 360/1200 [17:46<41:20,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-360
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-360/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-360/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-360/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-360/special_tokens_map.json
{'eval_loss': 1.5425156354904175, 'eval_f1': 0.49312446717817565, 'eval_runtime': 0.5191, 'eval_samples_per_second': 115.579, 'eval_steps_per_second': 5.779, 'epoch': 30.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-359] due to args.save_total_limit
 30%|█████████████████████████████████████████████▋                                                                                                          | 361/1200 [17:48<40:58,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|█████████████████████████████████████████████▋                                                                                                          | 361/1200 [17:49<40:58,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-361
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-361/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-361/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-361/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-361/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-360] due to args.save_total_limit
 30%|█████████████████████████████████████████████▊                                                                                                          | 362/1200 [17:51<40:53,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|█████████████████████████████████████████████▊                                                                                                          | 362/1200 [17:52<40:53,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-362
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-362/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-362/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-362/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-362/special_tokens_map.json
{'eval_loss': 1.5342152118682861, 'eval_f1': 0.49312446717817565, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.705, 'eval_steps_per_second': 5.885, 'epoch': 30.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-361] due to args.save_total_limit
 30%|█████████████████████████████████████████████▉                                                                                                          | 363/1200 [17:54<40:38,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|█████████████████████████████████████████████▉                                                                                                          | 363/1200 [17:55<40:38,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-363
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-363/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-363/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-363/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-363/special_tokens_map.json
{'eval_loss': 1.5250542163848877, 'eval_f1': 0.49312446717817565, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.659, 'eval_steps_per_second': 5.883, 'epoch': 30.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-362] due to args.save_total_limit
 30%|██████████████████████████████████████████████                                                                                                          | 364/1200 [17:57<40:28,  2.90s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|██████████████████████████████████████████████                                                                                                          | 364/1200 [17:58<40:28,  2.90s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-364
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-364/config.json
{'eval_loss': 1.5115675926208496, 'eval_f1': 0.49312446717817565, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.896, 'eval_steps_per_second': 5.845, 'epoch': 30.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-364/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-364/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-364/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-363] due to args.save_total_limit
 30%|██████████████████████████████████████████████▏                                                                                                         | 365/1200 [18:00<40:42,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|██████████████████████████████████████████████▏                                                                                                         | 365/1200 [18:01<40:42,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-365
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-365/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-365/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-365/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-365/special_tokens_map.json
{'eval_loss': 1.5090283155441284, 'eval_f1': 0.5602707749766573, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.642, 'eval_steps_per_second': 5.882, 'epoch': 30.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-364] due to args.save_total_limit
 30%|██████████████████████████████████████████████▎                                                                                                         | 366/1200 [18:03<40:24,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 30%|██████████████████████████████████████████████▎                                                                                                         | 366/1200 [18:03<40:24,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-366
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-366/config.json
{'eval_loss': 1.508832335472107, 'eval_f1': 0.5758998884106487, 'eval_runtime': 0.5116, 'eval_samples_per_second': 117.277, 'eval_steps_per_second': 5.864, 'epoch': 30.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-366/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-366/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-366/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-365] due to args.save_total_limit
 31%|██████████████████████████████████████████████▍                                                                                                         | 367/1200 [18:06<40:41,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 31%|██████████████████████████████████████████████▍                                                                                                         | 367/1200 [18:06<40:41,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-367
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-367/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-367/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-367/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-367/special_tokens_map.json
{'eval_loss': 1.50905179977417, 'eval_f1': 0.5758998884106487, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.65, 'eval_steps_per_second': 5.883, 'epoch': 30.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-366] due to args.save_total_limit
 31%|██████████████████████████████████████████████▌                                                                                                         | 368/1200 [18:09<42:22,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-368/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-368/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-368/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-368/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-367] due to args.save_total_limit
{'eval_loss': 1.53619384765625, 'eval_f1': 0.5911679454390452, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.494, 'eval_steps_per_second': 5.875, 'epoch': 30.67}
 31%|██████████████████████████████████████████████▋                                                                                                         | 369/1200 [18:12<41:30,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 31%|██████████████████████████████████████████████▋                                                                                                         | 369/1200 [18:13<41:30,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-369
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-369/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-369/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-369/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-369/special_tokens_map.json
{'eval_loss': 1.573797583580017, 'eval_f1': 0.5911679454390452, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.045, 'eval_steps_per_second': 5.852, 'epoch': 30.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-368] due to args.save_total_limit
 31%|██████████████████████████████████████████████▊                                                                                                         | 370/1200 [18:15<41:04,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 31%|██████████████████████████████████████████████▊                                                                                                         | 370/1200 [18:16<41:04,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-370
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-370/config.json
{'eval_loss': 1.6094926595687866, 'eval_f1': 0.5717257683215131, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.744, 'eval_steps_per_second': 5.887, 'epoch': 30.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-370/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-370/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-370/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-369] due to args.save_total_limit
 31%|██████████████████████████████████████████████▉                                                                                                         | 371/1200 [18:18<41:04,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 31%|██████████████████████████████████████████████▉                                                                                                         | 371/1200 [18:19<41:04,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-371
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-371/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-371/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-371/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-371/special_tokens_map.json
{'eval_loss': 1.6133344173431396, 'eval_f1': 0.5717257683215131, 'eval_runtime': 0.5143, 'eval_samples_per_second': 116.674, 'eval_steps_per_second': 5.834, 'epoch': 30.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-370] due to args.save_total_limit
 31%|███████████████████████████████████████████████                                                                                                         | 372/1200 [18:21<40:39,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 31%|███████████████████████████████████████████████                                                                                                         | 372/1200 [18:21<40:39,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-372
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-372/config.json
{'eval_loss': 1.6165529489517212, 'eval_f1': 0.5911679454390452, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.532, 'eval_steps_per_second': 5.877, 'epoch': 31.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-372/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-372/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-372/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-371] due to args.save_total_limit
{'eval_loss': 1.6143834590911865, 'eval_f1': 0.5911679454390452, 'eval_runtime': 0.5116, 'eval_samples_per_second': 117.271, 'eval_steps_per_second': 5.864, 'epoch': 31.08}
 31%|███████████████████████████████████████████████▏                                                                                                        | 373/1200 [18:24<40:43,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 31%|███████████████████████████████████████████████▏                                                                                                        | 373/1200 [18:24<40:43,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-373
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-373/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-373/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-373/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-373/special_tokens_map.json
{'eval_loss': 1.5836632251739502, 'eval_f1': 0.5758998884106487, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.753, 'eval_steps_per_second': 5.888, 'epoch': 31.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-372] due to args.save_total_limit
 31%|███████████████████████████████████████████████▎                                                                                                        | 374/1200 [18:27<40:40,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 31%|███████████████████████████████████████████████▎                                                                                                        | 374/1200 [18:27<40:40,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-374
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-374/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-374/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-374/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-374/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-373] due to args.save_total_limit
 31%|███████████████████████████████████████████████▌                                                                                                        | 375/1200 [18:30<40:28,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.5869028568267822, 'eval_f1': 0.5758998884106487, 'eval_runtime': 0.5144, 'eval_samples_per_second': 116.649, 'eval_steps_per_second': 5.832, 'epoch': 31.25}
 31%|███████████████████████████████████████████████▌                                                                                                        | 375/1200 [18:30<40:28,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-375
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-375/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-375/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-375/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-375/special_tokens_map.json
{'eval_loss': 1.5804829597473145, 'eval_f1': 0.5568989547038328, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.646, 'eval_steps_per_second': 5.882, 'epoch': 31.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-374] due to args.save_total_limit
 31%|███████████████████████████████████████████████▋                                                                                                        | 376/1200 [18:33<40:13,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 31%|███████████████████████████████████████████████▋                                                                                                        | 376/1200 [18:33<40:13,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-376
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-376/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-376/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-376/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-376/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-375] due to args.save_total_limit
 31%|███████████████████████████████████████████████▊                                                                                                        | 377/1200 [18:36<40:13,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-377/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-377/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-377/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-377/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-376] due to args.save_total_limit
{'eval_loss': 1.578946828842163, 'eval_f1': 0.5579233079233078, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.52, 'eval_steps_per_second': 5.876, 'epoch': 31.5}
 32%|███████████████████████████████████████████████▉                                                                                                        | 378/1200 [18:38<39:56,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 32%|███████████████████████████████████████████████▉                                                                                                        | 378/1200 [18:39<39:56,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-378
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-378/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-378/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-378/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-378/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-377] due to args.save_total_limit
 32%|████████████████████████████████████████████████                                                                                                        | 379/1200 [18:41<40:17,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 32%|████████████████████████████████████████████████                                                                                                        | 379/1200 [18:42<40:17,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-379
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-379/config.json
{'eval_loss': 1.5719772577285767, 'eval_f1': 0.5579233079233078, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.641, 'eval_steps_per_second': 5.882, 'epoch': 31.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-379/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-379/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-379/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-378] due to args.save_total_limit
{'eval_loss': 1.5705382823944092, 'eval_f1': 0.5384959872764751, 'eval_runtime': 0.5156, 'eval_samples_per_second': 116.364, 'eval_steps_per_second': 5.818, 'epoch': 31.67}
 32%|████████████████████████████████████████████████▏                                                                                                       | 380/1200 [18:44<40:21,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 32%|████████████████████████████████████████████████▏                                                                                                       | 380/1200 [18:45<40:21,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-380
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-380/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-380/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-380/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-380/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-379] due to args.save_total_limit
 32%|████████████████████████████████████████████████▎                                                                                                       | 381/1200 [18:47<40:27,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 32%|████████████████████████████████████████████████▎                                                                                                       | 381/1200 [18:48<40:27,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-381
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-381/config.json
{'eval_loss': 1.5889874696731567, 'eval_f1': 0.5337197337197336, 'eval_runtime': 0.512, 'eval_samples_per_second': 117.185, 'eval_steps_per_second': 5.859, 'epoch': 31.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-381/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-381/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-381/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-380] due to args.save_total_limit
 32%|████████████████████████████████████████████████▍                                                                                                       | 382/1200 [18:50<40:11,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.6302831172943115, 'eval_f1': 0.5151477793583056, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.704, 'eval_steps_per_second': 5.885, 'epoch': 31.83}
 32%|████████████████████████████████████████████████▍                                                                                                       | 382/1200 [18:51<40:11,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-382
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-382/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-382/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-382/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-382/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-381] due to args.save_total_limit
 32%|████████████████████████████████████████████████▌                                                                                                       | 383/1200 [18:54<41:36,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-383/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-383/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-383/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-383/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-382] due to args.save_total_limit
{'eval_loss': 1.7124876976013184, 'eval_f1': 0.495218438252494, 'eval_runtime': 0.5163, 'eval_samples_per_second': 116.213, 'eval_steps_per_second': 5.811, 'epoch': 32.0}
 32%|████████████████████████████████████████████████▋                                                                                                       | 384/1200 [18:57<40:53,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 32%|████████████████████████████████████████████████▋                                                                                                       | 384/1200 [18:57<40:53,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-384
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-384/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-384/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-384/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-384/special_tokens_map.json
{'eval_loss': 1.720069408416748, 'eval_f1': 0.495218438252494, 'eval_runtime': 0.5167, 'eval_samples_per_second': 116.118, 'eval_steps_per_second': 5.806, 'epoch': 32.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-383] due to args.save_total_limit
 32%|████████████████████████████████████████████████▊                                                                                                       | 385/1200 [18:59<40:32,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 32%|████████████████████████████████████████████████▊                                                                                                       | 385/1200 [19:00<40:32,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-385
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-385/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-385/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-385/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-385/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-384] due to args.save_total_limit
 32%|████████████████████████████████████████████████▉                                                                                                       | 386/1200 [19:02<40:03,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.7214397192001343, 'eval_f1': 0.495218438252494, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.72, 'eval_steps_per_second': 5.886, 'epoch': 32.17}
 32%|████████████████████████████████████████████████▉                                                                                                       | 386/1200 [19:03<40:03,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-386
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-386/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-386/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-386/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-386/special_tokens_map.json
{'eval_loss': 1.7190431356430054, 'eval_f1': 0.495218438252494, 'eval_runtime': 0.5153, 'eval_samples_per_second': 116.444, 'eval_steps_per_second': 5.822, 'epoch': 32.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-385] due to args.save_total_limit
 32%|█████████████████████████████████████████████████                                                                                                       | 387/1200 [19:05<39:44,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 32%|█████████████████████████████████████████████████                                                                                                       | 387/1200 [19:06<39:44,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-387
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-387/config.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-386] due to args.save_total_limit
 32%|█████████████████████████████████████████████████▏                                                                                                      | 388/1200 [19:08<39:39,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.51it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-388/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-388/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-388/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-388/special_tokens_map.json
{'eval_loss': 1.6641188859939575, 'eval_f1': 0.530843507098097, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.68, 'eval_steps_per_second': 5.884, 'epoch': 32.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-387] due to args.save_total_limit
 32%|█████████████████████████████████████████████████▎                                                                                                      | 389/1200 [19:11<39:46,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 32%|█████████████████████████████████████████████████▎                                                                                                      | 389/1200 [19:12<39:46,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-389
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-389/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-389/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-389/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-389/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-388] due to args.save_total_limit
 32%|█████████████████████████████████████████████████▍                                                                                                      | 390/1200 [19:14<39:36,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-390/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-390/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-390/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-390/special_tokens_map.json
{'eval_loss': 1.6402125358581543, 'eval_f1': 0.5552631578947368, 'eval_runtime': 0.5134, 'eval_samples_per_second': 116.877, 'eval_steps_per_second': 5.844, 'epoch': 32.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-389] due to args.save_total_limit
 33%|█████████████████████████████████████████████████▌                                                                                                      | 391/1200 [19:17<39:33,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|█████████████████████████████████████████████████▌                                                                                                      | 391/1200 [19:17<39:33,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-391
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-391/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-391/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-391/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-391/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-390] due to args.save_total_limit
 33%|█████████████████████████████████████████████████▋                                                                                                      | 392/1200 [19:20<39:20,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|█████████████████████████████████████████████████▋                                                                                                      | 392/1200 [19:20<39:20,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-392
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-392/config.json
{'eval_loss': 1.653022289276123, 'eval_f1': 0.5693447293447292, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.724, 'eval_steps_per_second': 5.886, 'epoch': 32.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-392/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-392/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-392/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-391] due to args.save_total_limit
{'eval_loss': 1.6763229370117188, 'eval_f1': 0.6009434870511217, 'eval_runtime': 0.5115, 'eval_samples_per_second': 117.313, 'eval_steps_per_second': 5.866, 'epoch': 32.75}
 33%|█████████████████████████████████████████████████▊                                                                                                      | 393/1200 [19:23<39:41,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|█████████████████████████████████████████████████▊                                                                                                      | 393/1200 [19:23<39:41,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-393
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-393/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-393/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-393/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-393/special_tokens_map.json
{'eval_loss': 1.6858607530593872, 'eval_f1': 0.6009434870511217, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.701, 'eval_steps_per_second': 5.885, 'epoch': 32.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-392] due to args.save_total_limit
 33%|█████████████████████████████████████████████████▉                                                                                                      | 394/1200 [19:26<39:26,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|█████████████████████████████████████████████████▉                                                                                                      | 394/1200 [19:26<39:26,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-394
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-394/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-394/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-394/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-394/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-393] due to args.save_total_limit
 33%|██████████████████████████████████████████████████                                                                                                      | 395/1200 [19:29<39:16,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.6952232122421265, 'eval_f1': 0.5869734723281633, 'eval_runtime': 0.5149, 'eval_samples_per_second': 116.528, 'eval_steps_per_second': 5.826, 'epoch': 32.92}
 33%|██████████████████████████████████████████████████                                                                                                      | 395/1200 [19:29<39:16,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-395
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-395/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-395/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-395/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-395/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-394] due to args.save_total_limit
 33%|██████████████████████████████████████████████████▏                                                                                                     | 396/1200 [19:32<40:47,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|██████████████████████████████████████████████████▏                                                                                                     | 396/1200 [19:32<40:47,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-396
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-396/config.json
{'eval_loss': 1.685144066810608, 'eval_f1': 0.5696031970205777, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.636, 'eval_steps_per_second': 5.882, 'epoch': 33.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-396/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-396/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-396/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-395] due to args.save_total_limit
{'eval_loss': 1.6807384490966797, 'eval_f1': 0.5696031970205777, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.725, 'eval_steps_per_second': 5.886, 'epoch': 33.08}
 33%|██████████████████████████████████████████████████▎                                                                                                     | 397/1200 [19:35<39:58,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|██████████████████████████████████████████████████▎                                                                                                     | 397/1200 [19:35<39:58,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-397
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-397/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-397/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-397/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-397/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-396] due to args.save_total_limit
 33%|██████████████████████████████████████████████████▍                                                                                                     | 398/1200 [19:38<41:02,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|██████████████████████████████████████████████████▍                                                                                                     | 398/1200 [19:39<41:02,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-398
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-398/config.json
{'eval_loss': 1.688090205192566, 'eval_f1': 0.5836424394319131, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.755, 'eval_steps_per_second': 5.888, 'epoch': 33.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-398/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-398/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-398/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-397] due to args.save_total_limit
{'eval_loss': 1.7191904783248901, 'eval_f1': 0.5990070209582404, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.573, 'eval_steps_per_second': 5.879, 'epoch': 33.25}
 33%|██████████████████████████████████████████████████▌                                                                                                     | 399/1200 [19:41<40:16,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|██████████████████████████████████████████████████▌                                                                                                     | 399/1200 [19:42<40:16,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-399
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-399/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-399/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-399/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-399/special_tokens_map.json
{'eval_loss': 1.7748264074325562, 'eval_f1': 0.5612403100775194, 'eval_runtime': 0.5141, 'eval_samples_per_second': 116.711, 'eval_steps_per_second': 5.836, 'epoch': 33.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-398] due to args.save_total_limit
 33%|██████████████████████████████████████████████████▋                                                                                                     | 400/1200 [19:44<39:49,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|██████████████████████████████████████████████████▋                                                                                                     | 400/1200 [19:44<39:49,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-400
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-400/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-400/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-400/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-400/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-399] due to args.save_total_limit
{'eval_loss': 1.8470046520233154, 'eval_f1': 0.5658773291925466, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.598, 'eval_steps_per_second': 5.88, 'epoch': 33.42}
 33%|██████████████████████████████████████████████████▊                                                                                                     | 401/1200 [19:47<39:42,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 33%|██████████████████████████████████████████████████▊                                                                                                     | 401/1200 [19:47<39:42,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-401
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-401/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-401/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-401/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-401/special_tokens_map.json
{'eval_loss': 1.9206910133361816, 'eval_f1': 0.5658773291925466, 'eval_runtime': 0.5142, 'eval_samples_per_second': 116.691, 'eval_steps_per_second': 5.835, 'epoch': 33.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-400] due to args.save_total_limit
 34%|██████████████████████████████████████████████████▉                                                                                                     | 402/1200 [19:50<39:45,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|██████████████████████████████████████████████████▉                                                                                                     | 402/1200 [19:50<39:45,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-402
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-402/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-402/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-402/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-402/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-401] due to args.save_total_limit
{'eval_loss': 1.9693562984466553, 'eval_f1': 0.5444651436415334, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.636, 'eval_steps_per_second': 5.882, 'epoch': 33.58}
 34%|███████████████████████████████████████████████████                                                                                                     | 403/1200 [19:53<39:25,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|███████████████████████████████████████████████████                                                                                                     | 403/1200 [19:53<39:25,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-403
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-403/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-403/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-403/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-403/special_tokens_map.json
{'eval_loss': 1.9605658054351807, 'eval_f1': 0.5444651436415334, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.425, 'eval_steps_per_second': 5.871, 'epoch': 33.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-402] due to args.save_total_limit
 34%|███████████████████████████████████████████████████▏                                                                                                    | 404/1200 [19:56<39:26,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|███████████████████████████████████████████████████▏                                                                                                    | 404/1200 [19:56<39:26,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-404
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-404/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-404/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-404/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-404/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-403] due to args.save_total_limit
 34%|███████████████████████████████████████████████████▎                                                                                                    | 405/1200 [19:59<39:14,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.9005032777786255, 'eval_f1': 0.5444651436415334, 'eval_runtime': 0.5166, 'eval_samples_per_second': 116.139, 'eval_steps_per_second': 5.807, 'epoch': 33.75}
 34%|███████████████████████████████████████████████████▎                                                                                                    | 405/1200 [19:59<39:14,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-405
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-405/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-405/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-405/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-405/special_tokens_map.json
{'eval_loss': 1.8617198467254639, 'eval_f1': 0.5669390611541775, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.758, 'eval_steps_per_second': 5.888, 'epoch': 33.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-404] due to args.save_total_limit
 34%|███████████████████████████████████████████████████▍                                                                                                    | 406/1200 [20:02<39:17,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|███████████████████████████████████████████████████▍                                                                                                    | 406/1200 [20:02<39:17,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-406
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-406/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-406/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-406/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-406/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-405] due to args.save_total_limit
 34%|███████████████████████████████████████████████████▌                                                                                                    | 407/1200 [20:05<38:59,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-407/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-407/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-407/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-407/special_tokens_map.json
{'eval_loss': 1.8158107995986938, 'eval_f1': 0.5326295191143401, 'eval_runtime': 0.5138, 'eval_samples_per_second': 116.784, 'eval_steps_per_second': 5.839, 'epoch': 34.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-406] due to args.save_total_limit
 34%|███████████████████████████████████████████████████▋                                                                                                    | 408/1200 [20:08<39:00,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|███████████████████████████████████████████████████▋                                                                                                    | 408/1200 [20:08<39:00,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-408
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-408/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-408/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-408/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-408/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-407] due to args.save_total_limit
 34%|███████████████████████████████████████████████████▊                                                                                                    | 409/1200 [20:11<38:55,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|███████████████████████████████████████████████████▊                                                                                                    | 409/1200 [20:11<38:55,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-409
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-409/config.json
{'eval_loss': 1.7834057807922363, 'eval_f1': 0.5156944444444445, 'eval_runtime': 0.5163, 'eval_samples_per_second': 116.202, 'eval_steps_per_second': 5.81, 'epoch': 34.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-409/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-409/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-409/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-408] due to args.save_total_limit
{'eval_loss': 1.761352777481079, 'eval_f1': 0.5156944444444445, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.589, 'eval_steps_per_second': 5.879, 'epoch': 34.17}
 34%|███████████████████████████████████████████████████▉                                                                                                    | 410/1200 [20:13<38:49,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|███████████████████████████████████████████████████▉                                                                                                    | 410/1200 [20:14<38:49,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-410
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-410/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-410/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-410/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-410/special_tokens_map.json
{'eval_loss': 1.7848509550094604, 'eval_f1': 0.4800043859649123, 'eval_runtime': 0.519, 'eval_samples_per_second': 115.601, 'eval_steps_per_second': 5.78, 'epoch': 34.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-409] due to args.save_total_limit
 34%|████████████████████████████████████████████████████                                                                                                    | 411/1200 [20:17<39:13,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-411/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-411/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-411/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-411/special_tokens_map.json
{'eval_loss': 1.777944803237915, 'eval_f1': 0.4800043859649123, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.548, 'eval_steps_per_second': 5.877, 'epoch': 34.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-410] due to args.save_total_limit
 34%|████████████████████████████████████████████████████▏                                                                                                   | 412/1200 [20:19<38:53,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|████████████████████████████████████████████████████▏                                                                                                   | 412/1200 [20:20<38:53,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-412
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-412/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-412/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-412/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-412/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-411] due to args.save_total_limit
 34%|████████████████████████████████████████████████████▎                                                                                                   | 413/1200 [20:22<38:35,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|████████████████████████████████████████████████████▎                                                                                                   | 413/1200 [20:23<38:35,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-413
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-413/config.json
{'eval_loss': 1.762402057647705, 'eval_f1': 0.46848617652189084, 'eval_runtime': 0.5165, 'eval_samples_per_second': 116.158, 'eval_steps_per_second': 5.808, 'epoch': 34.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-413/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-413/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-413/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-412] due to args.save_total_limit
{'eval_loss': 1.7628055810928345, 'eval_f1': 0.46848617652189084, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.566, 'eval_steps_per_second': 5.878, 'epoch': 34.5}
 34%|████████████████████████████████████████████████████▍                                                                                                   | 414/1200 [20:26<39:58,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 34%|████████████████████████████████████████████████████▍                                                                                                   | 414/1200 [20:26<39:58,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-414
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-414/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-414/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-414/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-414/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-413] due to args.save_total_limit
 35%|████████████████████████████████████████████████████▌                                                                                                   | 415/1200 [20:29<39:49,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 35%|████████████████████████████████████████████████████▌                                                                                                   | 415/1200 [20:29<39:49,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-415
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-415/config.json
{'eval_loss': 1.765174150466919, 'eval_f1': 0.46848617652189084, 'eval_runtime': 0.5268, 'eval_samples_per_second': 113.891, 'eval_steps_per_second': 5.695, 'epoch': 34.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-415/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-415/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-415/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-414] due to args.save_total_limit
{'eval_loss': 1.743219256401062, 'eval_f1': 0.46848617652189084, 'eval_runtime': 0.519, 'eval_samples_per_second': 115.6, 'eval_steps_per_second': 5.78, 'epoch': 34.67}
 35%|████████████████████████████████████████████████████▋                                                                                                   | 416/1200 [20:32<39:10,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 35%|████████████████████████████████████████████████████▋                                                                                                   | 416/1200 [20:32<39:10,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-416
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-416/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-416/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-416/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-416/special_tokens_map.json
{'eval_loss': 1.7263820171356201, 'eval_f1': 0.48624999999999996, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.477, 'eval_steps_per_second': 5.874, 'epoch': 34.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-415] due to args.save_total_limit
 35%|████████████████████████████████████████████████████▊                                                                                                   | 417/1200 [20:34<38:33,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 35%|████████████████████████████████████████████████████▊                                                                                                   | 417/1200 [20:35<38:33,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-417
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-417/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-417/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-417/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-417/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-416] due to args.save_total_limit
{'eval_loss': 1.7553826570510864, 'eval_f1': 0.46567007605559924, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.679, 'eval_steps_per_second': 5.884, 'epoch': 34.83}
 35%|████████████████████████████████████████████████████▉                                                                                                   | 418/1200 [20:37<38:32,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 35%|████████████████████████████████████████████████████▉                                                                                                   | 418/1200 [20:38<38:32,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-418
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-418/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-418/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-418/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-418/special_tokens_map.json
{'eval_loss': 1.7968930006027222, 'eval_f1': 0.4935748792270532, 'eval_runtime': 0.5163, 'eval_samples_per_second': 116.22, 'eval_steps_per_second': 5.811, 'epoch': 34.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-417] due to args.save_total_limit
 35%|█████████████████████████████████████████████████████                                                                                                   | 419/1200 [20:40<38:13,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 35%|█████████████████████████████████████████████████████                                                                                                   | 419/1200 [20:41<38:13,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-419
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-419/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-419/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-419/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-419/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-418] due to args.save_total_limit
 35%|█████████████████████████████████████████████████████▏                                                                                                  | 420/1200 [20:43<38:10,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.831883192062378, 'eval_f1': 0.4807407407407407, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.667, 'eval_steps_per_second': 5.883, 'epoch': 35.0}
 35%|█████████████████████████████████████████████████████▏                                                                                                  | 420/1200 [20:44<38:10,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-420
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-420/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-420/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-420/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-420/special_tokens_map.json
{'eval_loss': 1.8795032501220703, 'eval_f1': 0.49575023505337096, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.642, 'eval_steps_per_second': 5.882, 'epoch': 35.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-419] due to args.save_total_limit
 35%|█████████████████████████████████████████████████████▎                                                                                                  | 421/1200 [20:46<38:09,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 35%|█████████████████████████████████████████████████████▎                                                                                                  | 421/1200 [20:47<38:09,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-421
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-421/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-421/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-421/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-421/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-420] due to args.save_total_limit
 35%|█████████████████████████████████████████████████████▍                                                                                                  | 422/1200 [20:49<38:11,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.19it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-422/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-422/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-422/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-422/special_tokens_map.json
{'eval_loss': 1.8609143495559692, 'eval_f1': 0.5179397237520762, 'eval_runtime': 0.5151, 'eval_samples_per_second': 116.484, 'eval_steps_per_second': 5.824, 'epoch': 35.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-421] due to args.save_total_limit
 35%|█████████████████████████████████████████████████████▌                                                                                                  | 423/1200 [20:52<37:52,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 35%|█████████████████████████████████████████████████████▌                                                                                                  | 423/1200 [20:53<37:52,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-423
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-423/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-423/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-423/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-423/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-422] due to args.save_total_limit
{'eval_loss': 1.7860804796218872, 'eval_f1': 0.5583924349881798, 'eval_runtime': 0.5178, 'eval_samples_per_second': 115.873, 'eval_steps_per_second': 5.794, 'epoch': 35.33}
 35%|█████████████████████████████████████████████████████▋                                                                                                  | 424/1200 [20:55<39:10,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 35%|█████████████████████████████████████████████████████▋                                                                                                  | 424/1200 [20:56<39:10,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-424
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-424/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-424/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-424/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-424/special_tokens_map.json
{'eval_loss': 1.7100334167480469, 'eval_f1': 0.5400854700854701, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.544, 'eval_steps_per_second': 5.877, 'epoch': 35.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-423] due to args.save_total_limit
 35%|█████████████████████████████████████████████████████▊                                                                                                  | 425/1200 [20:58<38:53,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 35%|█████████████████████████████████████████████████████▊                                                                                                  | 425/1200 [20:59<38:53,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-425
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-425/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-425/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-425/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-425/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-424] due to args.save_total_limit
 36%|█████████████████████████████████████████████████████▉                                                                                                  | 426/1200 [21:01<38:32,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|█████████████████████████████████████████████████████▉                                                                                                  | 426/1200 [21:02<38:32,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-426
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-426/config.json
{'eval_loss': 1.6421527862548828, 'eval_f1': 0.5382836937304503, 'eval_runtime': 0.5164, 'eval_samples_per_second': 116.198, 'eval_steps_per_second': 5.81, 'epoch': 35.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-426/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-426/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-426/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-425] due to args.save_total_limit
{'eval_loss': 1.6104682683944702, 'eval_f1': 0.5241442568271837, 'eval_runtime': 0.514, 'eval_samples_per_second': 116.722, 'eval_steps_per_second': 5.836, 'epoch': 35.58}
 36%|██████████████████████████████████████████████████████                                                                                                  | 427/1200 [21:04<38:04,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|██████████████████████████████████████████████████████                                                                                                  | 427/1200 [21:05<38:04,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-427
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-427/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-427/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-427/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-427/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-426] due to args.save_total_limit
 36%|██████████████████████████████████████████████████████▏                                                                                                 | 428/1200 [21:07<37:47,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|██████████████████████████████████████████████████████▏                                                                                                 | 428/1200 [21:07<37:47,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-428
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-428/config.json
{'eval_loss': 1.622869610786438, 'eval_f1': 0.5242747596480767, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.721, 'eval_steps_per_second': 5.886, 'epoch': 35.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-428/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-428/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-428/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-427] due to args.save_total_limit
{'eval_loss': 1.6363129615783691, 'eval_f1': 0.5391660891660892, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.437, 'eval_steps_per_second': 5.872, 'epoch': 35.75}
 36%|██████████████████████████████████████████████████████▎                                                                                                 | 429/1200 [21:10<38:08,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|██████████████████████████████████████████████████████▎                                                                                                 | 429/1200 [21:10<38:08,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-429
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-429/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-429/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-429/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-429/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-428] due to args.save_total_limit
 36%|██████████████████████████████████████████████████████▍                                                                                                 | 430/1200 [21:13<37:55,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|██████████████████████████████████████████████████████▍                                                                                                 | 430/1200 [21:13<37:55,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-430
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-430/config.json
{'eval_loss': 1.645074725151062, 'eval_f1': 0.5391660891660892, 'eval_runtime': 0.5156, 'eval_samples_per_second': 116.359, 'eval_steps_per_second': 5.818, 'epoch': 35.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-430/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-430/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-430/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-429] due to args.save_total_limit
 36%|██████████████████████████████████████████████████████▌                                                                                                 | 431/1200 [21:16<37:35,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.6523668766021729, 'eval_f1': 0.5391660891660892, 'eval_runtime': 0.5134, 'eval_samples_per_second': 116.864, 'eval_steps_per_second': 5.843, 'epoch': 35.92}
 36%|██████████████████████████████████████████████████████▌                                                                                                 | 431/1200 [21:16<37:35,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-431
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-431/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-431/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-431/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-431/special_tokens_map.json
{'eval_loss': 1.6601635217666626, 'eval_f1': 0.5391660891660892, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.467, 'eval_steps_per_second': 5.873, 'epoch': 36.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-430] due to args.save_total_limit
 36%|██████████████████████████████████████████████████████▋                                                                                                 | 432/1200 [21:19<37:26,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|██████████████████████████████████████████████████████▋                                                                                                 | 432/1200 [21:19<37:26,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-432
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-432/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-432/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-432/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-432/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-431] due to args.save_total_limit
 36%|██████████████████████████████████████████████████████▊                                                                                                 | 433/1200 [21:22<37:13,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-433/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-433/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-433/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-433/special_tokens_map.json
{'eval_loss': 1.6637091636657715, 'eval_f1': 0.5112810089639359, 'eval_runtime': 0.5168, 'eval_samples_per_second': 116.097, 'eval_steps_per_second': 5.805, 'epoch': 36.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-432] due to args.save_total_limit
 36%|██████████████████████████████████████████████████████▉                                                                                                 | 434/1200 [21:25<38:41,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|██████████████████████████████████████████████████████▉                                                                                                 | 434/1200 [21:25<38:41,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-434
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-434/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-434/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-434/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-434/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-433] due to args.save_total_limit
 36%|███████████████████████████████████████████████████████                                                                                                 | 435/1200 [21:28<38:08,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-435/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-435/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-435/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-435/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-434] due to args.save_total_limit
 36%|███████████████████████████████████████████████████████▏                                                                                                | 436/1200 [21:31<37:55,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|███████████████████████████████████████████████████████▏                                                                                                | 436/1200 [21:31<37:55,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-436
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-436/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-436/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-436/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-436/special_tokens_map.json
{'eval_loss': 1.7926398515701294, 'eval_f1': 0.5240531561461794, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.575, 'eval_steps_per_second': 5.879, 'epoch': 36.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-435] due to args.save_total_limit
 36%|███████████████████████████████████████████████████████▎                                                                                                | 437/1200 [21:34<37:50,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|███████████████████████████████████████████████████████▎                                                                                                | 437/1200 [21:34<37:50,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-437
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-437/config.json
{'eval_loss': 1.8515416383743286, 'eval_f1': 0.4868217054263566, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.565, 'eval_steps_per_second': 5.878, 'epoch': 36.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-437/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-437/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-437/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-436] due to args.save_total_limit
{'eval_loss': 1.9193003177642822, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.818, 'eval_steps_per_second': 5.891, 'epoch': 36.5}
 36%|███████████████████████████████████████████████████████▍                                                                                                | 438/1200 [21:37<37:30,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 36%|███████████████████████████████████████████████████████▍                                                                                                | 438/1200 [21:37<37:30,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-438
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-438/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-438/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-438/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-438/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-437] due to args.save_total_limit
 37%|███████████████████████████████████████████████████████▌                                                                                                | 439/1200 [21:39<37:05,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 37%|███████████████████████████████████████████████████████▌                                                                                                | 439/1200 [21:40<37:05,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-439
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-439/config.json
{'eval_loss': 1.9547619819641113, 'eval_f1': 0.5018399044205495, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.395, 'eval_steps_per_second': 5.87, 'epoch': 36.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-439/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-439/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-439/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-438] due to args.save_total_limit
{'eval_loss': 2.020320415496826, 'eval_f1': 0.4807407407407407, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.792, 'eval_steps_per_second': 5.89, 'epoch': 36.67}
 37%|███████████████████████████████████████████████████████▋                                                                                                | 440/1200 [21:42<36:58,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 37%|███████████████████████████████████████████████████████▋                                                                                                | 440/1200 [21:43<36:58,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-440
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-440/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-440/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-440/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-440/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-439] due to args.save_total_limit
 37%|███████████████████████████████████████████████████████▊                                                                                                | 441/1200 [21:45<37:06,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 37%|███████████████████████████████████████████████████████▊                                                                                                | 441/1200 [21:46<37:06,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-441
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-441/config.json
{'eval_loss': 2.051901340484619, 'eval_f1': 0.47980676328502414, 'eval_runtime': 0.514, 'eval_samples_per_second': 116.73, 'eval_steps_per_second': 5.837, 'epoch': 36.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-441/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-441/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-441/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-440] due to args.save_total_limit
 37%|███████████████████████████████████████████████████████▉                                                                                                | 442/1200 [21:48<36:49,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-442/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-442/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-442/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-442/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-441] due to args.save_total_limit
 37%|████████████████████████████████████████████████████████                                                                                                | 443/1200 [21:51<36:41,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 37%|████████████████████████████████████████████████████████                                                                                                | 443/1200 [21:52<36:41,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-443
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-443/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-443/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-443/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-443/special_tokens_map.json
{'eval_loss': 2.156203269958496, 'eval_f1': 0.4941269841269841, 'eval_runtime': 0.5132, 'eval_samples_per_second': 116.91, 'eval_steps_per_second': 5.845, 'epoch': 36.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-442] due to args.save_total_limit
 37%|████████████████████████████████████████████████████████▏                                                                                               | 444/1200 [21:54<36:51,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-444/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-444/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-444/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-444/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-443] due to args.save_total_limit
{'eval_loss': 2.0495645999908447, 'eval_f1': 0.46444444444444444, 'eval_runtime': 0.5082, 'eval_samples_per_second': 118.066, 'eval_steps_per_second': 5.903, 'epoch': 37.08}
 37%|████████████████████████████████████████████████████████▎                                                                                               | 445/1200 [21:57<36:45,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 37%|████████████████████████████████████████████████████████▎                                                                                               | 445/1200 [21:57<36:45,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-445
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-445/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-445/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-445/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-445/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-444] due to args.save_total_limit
 37%|████████████████████████████████████████████████████████▍                                                                                               | 446/1200 [22:00<38:30,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-446/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-446/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-446/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-446/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-445] due to args.save_total_limit
 37%|████████████████████████████████████████████████████████▌                                                                                               | 447/1200 [22:03<37:53,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 37%|████████████████████████████████████████████████████████▌                                                                                               | 447/1200 [22:04<37:53,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-447
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-447/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-447/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-447/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-447/special_tokens_map.json
{'eval_loss': 1.8469990491867065, 'eval_f1': 0.48917989417989427, 'eval_runtime': 0.5128, 'eval_samples_per_second': 116.999, 'eval_steps_per_second': 5.85, 'epoch': 37.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-446] due to args.save_total_limit
 37%|████████████████████████████████████████████████████████▋                                                                                               | 448/1200 [22:06<37:19,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 37%|████████████████████████████████████████████████████████▋                                                                                               | 448/1200 [22:07<37:19,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-448
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-448/config.json
{'eval_loss': 1.7832821607589722, 'eval_f1': 0.5017341225403935, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.416, 'eval_steps_per_second': 5.871, 'epoch': 37.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-448/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-448/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-448/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-447] due to args.save_total_limit
{'eval_loss': 1.7718883752822876, 'eval_f1': 0.4789939825408933, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.538, 'eval_steps_per_second': 5.877, 'epoch': 37.42}
 37%|████████████████████████████████████████████████████████▊                                                                                               | 449/1200 [22:09<37:08,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 37%|████████████████████████████████████████████████████████▊                                                                                               | 449/1200 [22:10<37:08,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-449
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-449/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-449/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-449/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-449/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-448] due to args.save_total_limit
 38%|█████████████████████████████████████████████████████████                                                                                               | 450/1200 [22:12<36:55,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 38%|█████████████████████████████████████████████████████████                                                                                               | 450/1200 [22:13<36:55,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-450
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-450/config.json
{'eval_loss': 1.768744707107544, 'eval_f1': 0.4760297139244507, 'eval_runtime': 0.5187, 'eval_samples_per_second': 115.683, 'eval_steps_per_second': 5.784, 'epoch': 37.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-450/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-450/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-450/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-449] due to args.save_total_limit
 38%|█████████████████████████████████████████████████████████▏                                                                                              | 451/1200 [22:15<37:07,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.770589828491211, 'eval_f1': 0.49282296650717694, 'eval_runtime': 0.5154, 'eval_samples_per_second': 116.415, 'eval_steps_per_second': 5.821, 'epoch': 37.58}
 38%|█████████████████████████████████████████████████████████▏                                                                                              | 451/1200 [22:16<37:07,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-451
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-451/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-451/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-451/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-451/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-450] due to args.save_total_limit
 38%|█████████████████████████████████████████████████████████▎                                                                                              | 452/1200 [22:18<36:44,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 38%|█████████████████████████████████████████████████████████▎                                                                                              | 452/1200 [22:18<36:44,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-452
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-452/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-452/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-452/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-452/special_tokens_map.json
{'eval_loss': 1.767459750175476, 'eval_f1': 0.49282296650717694, 'eval_runtime': 0.5186, 'eval_samples_per_second': 115.701, 'eval_steps_per_second': 5.785, 'epoch': 37.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-451] due to args.save_total_limit
 38%|█████████████████████████████████████████████████████████▍                                                                                              | 453/1200 [22:21<36:44,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-453/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-453/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-453/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-453/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-452] due to args.save_total_limit
 38%|█████████████████████████████████████████████████████████▌                                                                                              | 454/1200 [22:24<36:38,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 38%|█████████████████████████████████████████████████████████▌                                                                                              | 454/1200 [22:24<36:38,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-454
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-454/config.json
{'eval_loss': 1.7225327491760254, 'eval_f1': 0.5157509157509158, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.51, 'eval_steps_per_second': 5.875, 'epoch': 37.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-454/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-454/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-454/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-453] due to args.save_total_limit
 38%|█████████████████████████████████████████████████████████▋                                                                                              | 455/1200 [22:27<36:30,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.7453476190567017, 'eval_f1': 0.5209386130316361, 'eval_runtime': 0.5177, 'eval_samples_per_second': 115.895, 'eval_steps_per_second': 5.795, 'epoch': 37.92}
 38%|█████████████████████████████████████████████████████████▋                                                                                              | 455/1200 [22:27<36:30,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-455
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-455/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-455/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-455/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-455/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-454] due to args.save_total_limit
 38%|█████████████████████████████████████████████████████████▊                                                                                              | 456/1200 [22:30<36:40,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 38%|█████████████████████████████████████████████████████████▊                                                                                              | 456/1200 [22:30<36:40,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-456
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-456/config.json
{'eval_loss': 1.8018348217010498, 'eval_f1': 0.5577556293835363, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.65, 'eval_steps_per_second': 5.883, 'epoch': 38.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-456/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-456/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-456/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-455] due to args.save_total_limit
 38%|█████████████████████████████████████████████████████████▉                                                                                              | 457/1200 [22:33<36:38,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-457/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-457/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-457/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-457/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-456] due to args.save_total_limit
 38%|██████████████████████████████████████████████████████████                                                                                              | 458/1200 [22:36<36:33,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 38%|██████████████████████████████████████████████████████████                                                                                              | 458/1200 [22:36<36:33,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-458
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-458/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-458/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-458/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-458/special_tokens_map.json
{'eval_loss': 1.904465913772583, 'eval_f1': 0.5302622498274673, 'eval_runtime': 0.5146, 'eval_samples_per_second': 116.605, 'eval_steps_per_second': 5.83, 'epoch': 38.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-457] due to args.save_total_limit
 38%|██████████████████████████████████████████████████████████▏                                                                                             | 459/1200 [22:39<36:39,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.54it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-459/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-459/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-459/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-459/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-458] due to args.save_total_limit
 38%|██████████████████████████████████████████████████████████▎                                                                                             | 460/1200 [22:42<36:22,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 38%|██████████████████████████████████████████████████████████▎                                                                                             | 460/1200 [22:42<36:22,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-460
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-460/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-460/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-460/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-460/special_tokens_map.json
{'eval_loss': 1.933863878250122, 'eval_f1': 0.5153229974160206, 'eval_runtime': 0.5144, 'eval_samples_per_second': 116.639, 'eval_steps_per_second': 5.832, 'epoch': 38.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-459] due to args.save_total_limit
 38%|██████████████████████████████████████████████████████████▍                                                                                             | 461/1200 [22:45<36:31,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 38%|██████████████████████████████████████████████████████████▍                                                                                             | 461/1200 [22:45<36:31,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-461
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-461/config.json
{'eval_loss': 1.929003119468689, 'eval_f1': 0.5209302325581395, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.604, 'eval_steps_per_second': 5.88, 'epoch': 38.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-461/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-461/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-461/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-460] due to args.save_total_limit
{'eval_loss': 1.9158885478973389, 'eval_f1': 0.4885118416401556, 'eval_runtime': 0.5205, 'eval_samples_per_second': 115.274, 'eval_steps_per_second': 5.764, 'epoch': 38.5}
 38%|██████████████████████████████████████████████████████████▌                                                                                             | 462/1200 [22:47<36:07,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 38%|██████████████████████████████████████████████████████████▌                                                                                             | 462/1200 [22:48<36:07,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-462
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-462/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-462/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-462/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-462/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-461] due to args.save_total_limit
 39%|██████████████████████████████████████████████████████████▋                                                                                             | 463/1200 [22:50<36:11,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 39%|██████████████████████████████████████████████████████████▋                                                                                             | 463/1200 [22:51<36:11,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-463
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-463/config.json
{'eval_loss': 1.900659441947937, 'eval_f1': 0.47148936170212763, 'eval_runtime': 0.5198, 'eval_samples_per_second': 115.421, 'eval_steps_per_second': 5.771, 'epoch': 38.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-463/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-463/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-463/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-462] due to args.save_total_limit
 39%|██████████████████████████████████████████████████████████▊                                                                                             | 464/1200 [22:53<35:52,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-464/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-464/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-464/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-464/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-463] due to args.save_total_limit
 39%|██████████████████████████████████████████████████████████▉                                                                                             | 465/1200 [22:56<35:55,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 39%|██████████████████████████████████████████████████████████▉                                                                                             | 465/1200 [22:57<35:55,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-465
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-465/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-465/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-465/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-465/special_tokens_map.json
{'eval_loss': 1.9069058895111084, 'eval_f1': 0.47148936170212763, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.767, 'eval_steps_per_second': 5.888, 'epoch': 38.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-464] due to args.save_total_limit
 39%|███████████████████████████████████████████████████████████                                                                                             | 466/1200 [22:59<35:48,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
{'eval_loss': 1.8990529775619507, 'eval_f1': 0.5022838377031118, 'eval_runtime': 0.5213, 'eval_samples_per_second': 115.101, 'eval_steps_per_second': 5.755, 'epoch': 38.83}
  Num examples = 60
  Batch size = 5
 39%|███████████████████████████████████████████████████████████                                                                                             | 466/1200 [23:00<35:48,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-466
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-466/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-466/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-466/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-466/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-465] due to args.save_total_limit
 39%|███████████████████████████████████████████████████████████▏                                                                                            | 467/1200 [23:02<35:39,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 39%|███████████████████████████████████████████████████████████▏                                                                                            | 467/1200 [23:03<35:39,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-467
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-467/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-467/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-467/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-467/special_tokens_map.json
{'eval_loss': 1.8871185779571533, 'eval_f1': 0.4807817415880125, 'eval_runtime': 0.509, 'eval_samples_per_second': 117.867, 'eval_steps_per_second': 5.893, 'epoch': 38.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-466] due to args.save_total_limit
{'eval_loss': 1.8698265552520752, 'eval_f1': 0.4807817415880125, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.548, 'eval_steps_per_second': 5.877, 'epoch': 39.0}
 39%|███████████████████████████████████████████████████████████▎                                                                                            | 468/1200 [23:05<37:07,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 39%|███████████████████████████████████████████████████████████▎                                                                                            | 468/1200 [23:06<37:07,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-468
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-468/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-468/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-468/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-468/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-467] due to args.save_total_limit
 39%|███████████████████████████████████████████████████████████▍                                                                                            | 469/1200 [23:08<36:50,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 39%|███████████████████████████████████████████████████████████▍                                                                                            | 469/1200 [23:09<36:50,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-469
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-469/config.json
{'eval_loss': 1.8802531957626343, 'eval_f1': 0.4807817415880125, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.465, 'eval_steps_per_second': 5.873, 'epoch': 39.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-469/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-469/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-469/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-468] due to args.save_total_limit
 39%|███████████████████████████████████████████████████████████▌                                                                                            | 470/1200 [23:11<36:14,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 39%|███████████████████████████████████████████████████████████▌                                                                                            | 470/1200 [23:12<36:14,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-470
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-470/config.json
{'eval_loss': 1.8881072998046875, 'eval_f1': 0.4388888888888889, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.701, 'eval_steps_per_second': 5.885, 'epoch': 39.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-470/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-470/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-470/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-469] due to args.save_total_limit
 39%|███████████████████████████████████████████████████████████▋                                                                                            | 471/1200 [23:14<36:03,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 39%|███████████████████████████████████████████████████████████▋                                                                                            | 471/1200 [23:15<36:03,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-471
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-471/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-471/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-471/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-471/special_tokens_map.json
{'eval_loss': 1.9247536659240723, 'eval_f1': 0.4529523809523809, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.5, 'eval_steps_per_second': 5.875, 'epoch': 39.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-470] due to args.save_total_limit
 39%|███████████████████████████████████████████████████████████▊                                                                                            | 472/1200 [23:17<35:50,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-472/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-472/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-472/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-472/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-471] due to args.save_total_limit
{'eval_loss': 1.9736944437026978, 'eval_f1': 0.42396949891067537, 'eval_runtime': 0.5153, 'eval_samples_per_second': 116.434, 'eval_steps_per_second': 5.822, 'epoch': 39.42}
 39%|███████████████████████████████████████████████████████████▉                                                                                            | 473/1200 [23:20<35:32,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 39%|███████████████████████████████████████████████████████████▉                                                                                            | 473/1200 [23:21<35:32,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-473
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-473/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-473/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-473/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-473/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-472] due to args.save_total_limit
 40%|████████████████████████████████████████████████████████████                                                                                            | 474/1200 [23:23<35:28,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|████████████████████████████████████████████████████████████                                                                                            | 474/1200 [23:23<35:28,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-474
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-474/config.json
{'eval_loss': 1.973168969154358, 'eval_f1': 0.4625386996904025, 'eval_runtime': 0.5122, 'eval_samples_per_second': 117.148, 'eval_steps_per_second': 5.857, 'epoch': 39.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-474/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-474/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-474/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-473] due to args.save_total_limit
{'eval_loss': 1.9760345220565796, 'eval_f1': 0.4625386996904025, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.946, 'eval_steps_per_second': 5.847, 'epoch': 39.58}
 40%|████████████████████████████████████████████████████████████▏                                                                                           | 475/1200 [23:26<35:24,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|████████████████████████████████████████████████████████████▏                                                                                           | 475/1200 [23:26<35:24,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-475
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-475/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-475/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-475/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-475/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-474] due to args.save_total_limit
 40%|████████████████████████████████████████████████████████████▎                                                                                           | 476/1200 [23:29<35:18,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|████████████████████████████████████████████████████████████▎                                                                                           | 476/1200 [23:29<35:18,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-476
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-476/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-476/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-476/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-476/special_tokens_map.json
{'eval_loss': 1.9745427370071411, 'eval_f1': 0.4625386996904025, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.362, 'eval_steps_per_second': 5.868, 'epoch': 39.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-475] due to args.save_total_limit
 40%|████████████████████████████████████████████████████████████▍                                                                                           | 477/1200 [23:32<35:15,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-477/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-477/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-477/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-477/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-476] due to args.save_total_limit
 40%|████████████████████████████████████████████████████████████▌                                                                                           | 478/1200 [23:35<36:49,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|████████████████████████████████████████████████████████████▌                                                                                           | 478/1200 [23:36<36:49,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-478
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-478/config.json
{'eval_loss': 1.9743728637695312, 'eval_f1': 0.4606146572104019, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.803, 'eval_steps_per_second': 5.89, 'epoch': 39.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-478/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-478/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-478/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-477] due to args.save_total_limit
 40%|████████████████████████████████████████████████████████████▋                                                                                           | 479/1200 [23:38<36:19,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 1.9316784143447876, 'eval_f1': 0.4619117914487126, 'eval_runtime': 0.512, 'eval_samples_per_second': 117.184, 'eval_steps_per_second': 5.859, 'epoch': 39.92}
 40%|████████████████████████████████████████████████████████████▋                                                                                           | 479/1200 [23:39<36:19,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-479
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-479/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-479/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-479/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-479/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-478] due to args.save_total_limit
 40%|████████████████████████████████████████████████████████████▊                                                                                           | 480/1200 [23:41<35:53,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|████████████████████████████████████████████████████████████▊                                                                                           | 480/1200 [23:41<35:53,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-480
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-480/config.json
{'eval_loss': 1.8660494089126587, 'eval_f1': 0.4619117914487126, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.818, 'eval_steps_per_second': 5.841, 'epoch': 40.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-480/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-480/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-480/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-479] due to args.save_total_limit
{'eval_loss': 1.800172209739685, 'eval_f1': 0.4802781759303498, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.534, 'eval_steps_per_second': 5.877, 'epoch': 40.08}
 40%|████████████████████████████████████████████████████████████▉                                                                                           | 481/1200 [23:44<35:37,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|████████████████████████████████████████████████████████████▉                                                                                           | 481/1200 [23:44<35:37,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-481
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-481/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-481/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-481/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-481/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-480] due to args.save_total_limit
 40%|█████████████████████████████████████████████████████████████                                                                                           | 482/1200 [23:47<35:21,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|█████████████████████████████████████████████████████████████                                                                                           | 482/1200 [23:47<35:21,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-482
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-482/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-482/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-482/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-482/special_tokens_map.json
{'eval_loss': 1.7502140998840332, 'eval_f1': 0.4802781759303498, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.69, 'eval_steps_per_second': 5.884, 'epoch': 40.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-481] due to args.save_total_limit
 40%|█████████████████████████████████████████████████████████████▏                                                                                          | 483/1200 [23:50<35:05,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-483/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-483/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-483/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-483/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-482] due to args.save_total_limit
 40%|█████████████████████████████████████████████████████████████▎                                                                                          | 484/1200 [23:53<34:46,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|█████████████████████████████████████████████████████████████▎                                                                                          | 484/1200 [23:53<34:46,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-484
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-484/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-484/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-484/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-484/special_tokens_map.json
{'eval_loss': 1.7012038230895996, 'eval_f1': 0.49509649509649506, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.555, 'eval_steps_per_second': 5.878, 'epoch': 40.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-483] due to args.save_total_limit
 40%|█████████████████████████████████████████████████████████████▍                                                                                          | 485/1200 [23:55<34:51,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|█████████████████████████████████████████████████████████████▍                                                                                          | 485/1200 [23:56<34:51,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-485
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-485/config.json
{'eval_loss': 1.691306233406067, 'eval_f1': 0.5182503060551842, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.767, 'eval_steps_per_second': 5.888, 'epoch': 40.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-485/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-485/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-485/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-484] due to args.save_total_limit
 40%|█████████████████████████████████████████████████████████████▌                                                                                          | 486/1200 [23:58<35:01,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 40%|█████████████████████████████████████████████████████████████▌                                                                                          | 486/1200 [23:59<35:01,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-486
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-486/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-486/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-486/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-486/special_tokens_map.json
{'eval_loss': 1.6608810424804688, 'eval_f1': 0.552014652014652, 'eval_runtime': 0.5162, 'eval_samples_per_second': 116.235, 'eval_steps_per_second': 5.812, 'epoch': 40.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-485] due to args.save_total_limit
 41%|█████████████████████████████████████████████████████████████▋                                                                                          | 487/1200 [24:01<34:48,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|█████████████████████████████████████████████████████████████▋                                                                                          | 487/1200 [24:02<34:48,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-487
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-487/config.json
{'eval_loss': 1.6303237676620483, 'eval_f1': 0.552014652014652, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.466, 'eval_steps_per_second': 5.873, 'epoch': 40.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-487/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-487/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-487/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-486] due to args.save_total_limit
{'eval_loss': 1.62155282497406, 'eval_f1': 0.5881764638190586, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.646, 'eval_steps_per_second': 5.882, 'epoch': 40.67}
 41%|█████████████████████████████████████████████████████████████▊                                                                                          | 488/1200 [24:04<34:35,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|█████████████████████████████████████████████████████████████▊                                                                                          | 488/1200 [24:05<34:35,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-488
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-488/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-488/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-488/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-488/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-487] due to args.save_total_limit
 41%|█████████████████████████████████████████████████████████████▉                                                                                          | 489/1200 [24:08<36:19,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.21it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-489/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-489/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-489/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-489/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-488] due to args.save_total_limit
{'eval_loss': 1.658669352531433, 'eval_f1': 0.6010723489446893, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.806, 'eval_steps_per_second': 5.89, 'epoch': 40.83}
 41%|██████████████████████████████████████████████████████████████                                                                                          | 490/1200 [24:11<35:42,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|██████████████████████████████████████████████████████████████                                                                                          | 490/1200 [24:11<35:42,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-490
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-490/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-490/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-490/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-490/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-489] due to args.save_total_limit
 41%|██████████████████████████████████████████████████████████████▏                                                                                         | 491/1200 [24:13<35:12,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|██████████████████████████████████████████████████████████████▏                                                                                         | 491/1200 [24:14<35:12,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-491
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-491/config.json
{'eval_loss': 1.6764543056488037, 'eval_f1': 0.5540740740740742, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.602, 'eval_steps_per_second': 5.88, 'epoch': 40.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-491/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-491/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-491/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-490] due to args.save_total_limit
{'eval_loss': 1.690514087677002, 'eval_f1': 0.5240531561461794, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.79, 'eval_steps_per_second': 5.889, 'epoch': 41.0}
 41%|██████████████████████████████████████████████████████████████▎                                                                                         | 492/1200 [24:16<35:11,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|██████████████████████████████████████████████████████████████▎                                                                                         | 492/1200 [24:17<35:11,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-492
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-492/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-492/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-492/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-492/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-491] due to args.save_total_limit
 41%|██████████████████████████████████████████████████████████████▍                                                                                         | 493/1200 [24:19<35:04,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|██████████████████████████████████████████████████████████████▍                                                                                         | 493/1200 [24:20<35:04,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-493
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-493/config.json
{'eval_loss': 1.69810152053833, 'eval_f1': 0.48914607577448327, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.447, 'eval_steps_per_second': 5.872, 'epoch': 41.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-493/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-493/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-493/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-492] due to args.save_total_limit
{'eval_loss': 1.7034343481063843, 'eval_f1': 0.48914607577448327, 'eval_runtime': 0.5124, 'eval_samples_per_second': 117.104, 'eval_steps_per_second': 5.855, 'epoch': 41.17}
 41%|██████████████████████████████████████████████████████████████▌                                                                                         | 494/1200 [24:22<34:44,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|██████████████████████████████████████████████████████████████▌                                                                                         | 494/1200 [24:23<34:44,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-494
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-494/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-494/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-494/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-494/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-493] due to args.save_total_limit
 41%|██████████████████████████████████████████████████████████████▋                                                                                         | 495/1200 [24:25<34:29,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|██████████████████████████████████████████████████████████████▋                                                                                         | 495/1200 [24:26<34:29,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-495
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-495/config.json
{'eval_loss': 1.7260704040527344, 'eval_f1': 0.48348041889969295, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.125, 'eval_steps_per_second': 5.856, 'epoch': 41.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-495/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-495/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-495/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-494] due to args.save_total_limit
{'eval_loss': 1.7579551935195923, 'eval_f1': 0.4656999641962048, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.726, 'eval_steps_per_second': 5.886, 'epoch': 41.33}
 41%|██████████████████████████████████████████████████████████████▊                                                                                         | 496/1200 [24:28<35:38,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|██████████████████████████████████████████████████████████████▊                                                                                         | 496/1200 [24:29<35:38,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-496
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-496/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-496/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-496/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-496/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-495] due to args.save_total_limit
 41%|██████████████████████████████████████████████████████████████▉                                                                                         | 497/1200 [24:31<35:12,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 41%|██████████████████████████████████████████████████████████████▉                                                                                         | 497/1200 [24:32<35:12,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-497
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-497/config.json
{'eval_loss': 1.777233362197876, 'eval_f1': 0.4656999641962048, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.525, 'eval_steps_per_second': 5.876, 'epoch': 41.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-497/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-497/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-497/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-496] due to args.save_total_limit
{'eval_loss': 1.8017882108688354, 'eval_f1': 0.4656999641962048, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.617, 'eval_steps_per_second': 5.881, 'epoch': 41.5}
 42%|███████████████████████████████████████████████████████████████                                                                                         | 498/1200 [24:34<35:19,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|███████████████████████████████████████████████████████████████                                                                                         | 498/1200 [24:35<35:19,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-498
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-498/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-498/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-498/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-498/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-497] due to args.save_total_limit
 42%|███████████████████████████████████████████████████████████████▏                                                                                        | 499/1200 [24:37<34:46,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|███████████████████████████████████████████████████████████████▏                                                                                        | 499/1200 [24:38<34:46,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-499
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-499/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-499/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-499/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-499/special_tokens_map.json
{'eval_loss': 1.8028411865234375, 'eval_f1': 0.46495726495726497, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.626, 'eval_steps_per_second': 5.881, 'epoch': 41.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-498] due to args.save_total_limit
{'loss': 0.7586, 'learning_rate': 1.1666666666666668e-05, 'epoch': 41.67}
 42%|███████████████████████████████████████████████████████████████▎                                                                                        | 500/1200 [24:41<37:22,  3.20s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|███████████████████████████████████████████████████████████████▎                                                                                        | 500/1200 [24:42<37:22,  3.20s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-500
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-500/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-500/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-500/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-500/special_tokens_map.json
{'eval_loss': 1.8211443424224854, 'eval_f1': 0.4531560283687944, 'eval_runtime': 0.5036, 'eval_samples_per_second': 119.148, 'eval_steps_per_second': 5.957, 'epoch': 41.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-499] due to args.save_total_limit
 42%|███████████████████████████████████████████████████████████████▍                                                                                        | 501/1200 [24:44<36:11,  3.11s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|███████████████████████████████████████████████████████████████▍                                                                                        | 501/1200 [24:44<36:11,  3.11s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-501
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-501/config.json
{'eval_loss': 1.8305188417434692, 'eval_f1': 0.47416212592977, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.566, 'eval_steps_per_second': 5.878, 'epoch': 41.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-501/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-501/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-501/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-500] due to args.save_total_limit
 42%|███████████████████████████████████████████████████████████████▌                                                                                        | 502/1200 [24:47<35:43,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|███████████████████████████████████████████████████████████████▌                                                                                        | 502/1200 [24:47<35:43,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-502
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-502/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-502/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-502/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-502/special_tokens_map.json
{'eval_loss': 1.792290210723877, 'eval_f1': 0.5071630060292851, 'eval_runtime': 0.5127, 'eval_samples_per_second': 117.023, 'eval_steps_per_second': 5.851, 'epoch': 41.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-501] due to args.save_total_limit
 42%|███████████████████████████████████████████████████████████████▋                                                                                        | 503/1200 [24:50<35:09,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-503/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-503/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-503/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-503/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-502] due to args.save_total_limit
 42%|███████████████████████████████████████████████████████████████▊                                                                                        | 504/1200 [24:53<34:36,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|███████████████████████████████████████████████████████████████▊                                                                                        | 504/1200 [24:53<34:36,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-504
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-504/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-504/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-504/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-504/special_tokens_map.json
{'eval_loss': 1.738200306892395, 'eval_f1': 0.5568989547038328, 'eval_runtime': 0.5171, 'eval_samples_per_second': 116.03, 'eval_steps_per_second': 5.802, 'epoch': 42.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-503] due to args.save_total_limit
 42%|███████████████████████████████████████████████████████████████▉                                                                                        | 505/1200 [24:56<34:17,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|███████████████████████████████████████████████████████████████▉                                                                                        | 505/1200 [24:56<34:17,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-505
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-505/config.json
{'eval_loss': 1.7158066034317017, 'eval_f1': 0.5568989547038328, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.928, 'eval_steps_per_second': 5.846, 'epoch': 42.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-505/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-505/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-505/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-504] due to args.save_total_limit
{'eval_loss': 1.7125622034072876, 'eval_f1': 0.5568989547038328, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.514, 'eval_steps_per_second': 5.876, 'epoch': 42.17}
 42%|████████████████████████████████████████████████████████████████                                                                                        | 506/1200 [24:59<34:14,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|████████████████████████████████████████████████████████████████                                                                                        | 506/1200 [24:59<34:14,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-506
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-506/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-506/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-506/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-506/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-505] due to args.save_total_limit
 42%|████████████████████████████████████████████████████████████████▏                                                                                       | 507/1200 [25:01<34:00,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|████████████████████████████████████████████████████████████████▏                                                                                       | 507/1200 [25:02<34:00,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-507
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-507/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-507/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-507/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-507/special_tokens_map.json
{'eval_loss': 1.7262217998504639, 'eval_f1': 0.5377061406272978, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.599, 'eval_steps_per_second': 5.88, 'epoch': 42.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-506] due to args.save_total_limit
 42%|████████████████████████████████████████████████████████████████▎                                                                                       | 508/1200 [25:05<35:19,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|████████████████████████████████████████████████████████████████▎                                                                                       | 508/1200 [25:05<35:19,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-508
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-508/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-508/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-508/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-508/special_tokens_map.json
{'eval_loss': 1.7208008766174316, 'eval_f1': 0.5377061406272978, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.543, 'eval_steps_per_second': 5.877, 'epoch': 42.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-507] due to args.save_total_limit
 42%|████████████████████████████████████████████████████████████████▍                                                                                       | 509/1200 [25:08<34:56,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 42%|████████████████████████████████████████████████████████████████▍                                                                                       | 509/1200 [25:08<34:56,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-509
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-509/config.json
{'eval_loss': 1.7194466590881348, 'eval_f1': 0.5550471401634192, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.399, 'eval_steps_per_second': 5.87, 'epoch': 42.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-509/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-509/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-509/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-508] due to args.save_total_limit
 42%|████████████████████████████████████████████████████████████████▌                                                                                       | 510/1200 [25:11<34:26,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-510/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-510/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-510/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-510/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-509] due to args.save_total_limit
 43%|████████████████████████████████████████████████████████████████▋                                                                                       | 511/1200 [25:14<34:18,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 43%|████████████████████████████████████████████████████████████████▋                                                                                       | 511/1200 [25:14<34:18,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-511
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-511/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-511/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-511/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-511/special_tokens_map.json
{'eval_loss': 1.716481328010559, 'eval_f1': 0.5885964912280702, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.621, 'eval_steps_per_second': 5.881, 'epoch': 42.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-510] due to args.save_total_limit
 43%|████████████████████████████████████████████████████████████████▊                                                                                       | 512/1200 [25:17<34:13,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-512/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-512/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-512/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-512/special_tokens_map.json
{'eval_loss': 1.7442153692245483, 'eval_f1': 0.5540740740740742, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.514, 'eval_steps_per_second': 5.876, 'epoch': 42.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-511] due to args.save_total_limit
 43%|████████████████████████████████████████████████████████████████▉                                                                                       | 513/1200 [25:20<33:45,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 43%|████████████████████████████████████████████████████████████████▉                                                                                       | 513/1200 [25:20<33:45,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-513
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-513/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-513/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-513/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-513/special_tokens_map.json
{'eval_loss': 1.7499616146087646, 'eval_f1': 0.5540740740740742, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.762, 'eval_steps_per_second': 5.888, 'epoch': 42.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-512] due to args.save_total_limit
 43%|█████████████████████████████████████████████████████████████████                                                                                       | 514/1200 [25:22<33:29,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 43%|█████████████████████████████████████████████████████████████████                                                                                       | 514/1200 [25:23<33:29,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-514
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-514/config.json
{'eval_loss': 1.7628425359725952, 'eval_f1': 0.5377061406272978, 'eval_runtime': 0.5155, 'eval_samples_per_second': 116.4, 'eval_steps_per_second': 5.82, 'epoch': 42.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-514/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-514/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-514/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-513] due to args.save_total_limit
 43%|█████████████████████████████████████████████████████████████████▏                                                                                      | 515/1200 [25:25<33:23,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 43%|█████████████████████████████████████████████████████████████████▏                                                                                      | 515/1200 [25:26<33:23,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-515
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-515/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-515/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-515/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-515/special_tokens_map.json
{'eval_loss': 1.771612286567688, 'eval_f1': 0.5377061406272978, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.608, 'eval_steps_per_second': 5.88, 'epoch': 42.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-514] due to args.save_total_limit
 43%|█████████████████████████████████████████████████████████████████▎                                                                                      | 516/1200 [25:28<33:27,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-516/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-516/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-516/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-516/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-515] due to args.save_total_limit
 43%|█████████████████████████████████████████████████████████████████▍                                                                                      | 517/1200 [25:31<33:21,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 43%|█████████████████████████████████████████████████████████████████▍                                                                                      | 517/1200 [25:32<33:21,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-517
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-517/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-517/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-517/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-517/special_tokens_map.json
{'eval_loss': 1.8144447803497314, 'eval_f1': 0.5540740740740742, 'eval_runtime': 0.5117, 'eval_samples_per_second': 117.262, 'eval_steps_per_second': 5.863, 'epoch': 43.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-516] due to args.save_total_limit
 43%|█████████████████████████████████████████████████████████████████▌                                                                                      | 518/1200 [25:34<33:15,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 43%|█████████████████████████████████████████████████████████████████▌                                                                                      | 518/1200 [25:35<33:15,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-518
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-518/config.json
{'eval_loss': 1.8613948822021484, 'eval_f1': 0.5517460317460317, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.705, 'eval_steps_per_second': 5.885, 'epoch': 43.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-518/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-518/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-518/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-517] due to args.save_total_limit
{'eval_loss': 1.8955401182174683, 'eval_f1': 0.5517460317460317, 'eval_runtime': 0.5203, 'eval_samples_per_second': 115.311, 'eval_steps_per_second': 5.766, 'epoch': 43.25}
 43%|█████████████████████████████████████████████████████████████████▋                                                                                      | 519/1200 [25:37<33:13,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 43%|█████████████████████████████████████████████████████████████████▋                                                                                      | 519/1200 [25:38<33:13,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-519
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-519/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-519/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-519/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-519/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-518] due to args.save_total_limit
 43%|█████████████████████████████████████████████████████████████████▊                                                                                      | 520/1200 [25:40<33:09,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 43%|█████████████████████████████████████████████████████████████████▊                                                                                      | 520/1200 [25:40<33:09,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-520
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-520/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-520/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-520/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-520/special_tokens_map.json
{'eval_loss': 1.9428826570510864, 'eval_f1': 0.5352380952380952, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.049, 'eval_steps_per_second': 5.852, 'epoch': 43.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-519] due to args.save_total_limit
 43%|█████████████████████████████████████████████████████████████████▉                                                                                      | 521/1200 [25:43<33:10,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-521/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-521/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-521/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-521/special_tokens_map.json
{'eval_loss': 1.9650137424468994, 'eval_f1': 0.5352380952380952, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.371, 'eval_steps_per_second': 5.869, 'epoch': 43.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-520] due to args.save_total_limit
 44%|██████████████████████████████████████████████████████████████████                                                                                      | 522/1200 [25:46<33:06,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|██████████████████████████████████████████████████████████████████                                                                                      | 522/1200 [25:46<33:06,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-522
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-522/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-522/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-522/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-522/special_tokens_map.json
{'eval_loss': 1.956998586654663, 'eval_f1': 0.5352380952380952, 'eval_runtime': 0.5151, 'eval_samples_per_second': 116.48, 'eval_steps_per_second': 5.824, 'epoch': 43.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-521] due to args.save_total_limit
 44%|██████████████████████████████████████████████████████████████████▏                                                                                     | 523/1200 [25:49<34:26,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|██████████████████████████████████████████████████████████████████▏                                                                                     | 523/1200 [25:50<34:26,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-523
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-523/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-523/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-523/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-523/special_tokens_map.json
{'eval_loss': 1.9665319919586182, 'eval_f1': 0.5352380952380952, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.711, 'eval_steps_per_second': 5.886, 'epoch': 43.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-522] due to args.save_total_limit
 44%|██████████████████████████████████████████████████████████████████▎                                                                                     | 524/1200 [25:52<33:54,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|██████████████████████████████████████████████████████████████████▎                                                                                     | 524/1200 [25:53<33:54,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-524
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-524/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-524/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-524/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-524/special_tokens_map.json
{'eval_loss': 1.9477826356887817, 'eval_f1': 0.5197674418604651, 'eval_runtime': 0.5135, 'eval_samples_per_second': 116.846, 'eval_steps_per_second': 5.842, 'epoch': 43.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-523] due to args.save_total_limit
 44%|██████████████████████████████████████████████████████████████████▌                                                                                     | 525/1200 [25:55<33:30,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.47it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-525/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-525/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-525/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-525/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-524] due to args.save_total_limit
 44%|██████████████████████████████████████████████████████████████████▋                                                                                     | 526/1200 [25:58<33:07,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|██████████████████████████████████████████████████████████████████▋                                                                                     | 526/1200 [25:58<33:07,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-526
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-526/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-526/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-526/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-526/special_tokens_map.json
{'eval_loss': 1.8926424980163574, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5128, 'eval_samples_per_second': 117.004, 'eval_steps_per_second': 5.85, 'epoch': 43.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-525] due to args.save_total_limit
 44%|██████████████████████████████████████████████████████████████████▊                                                                                     | 527/1200 [26:01<33:20,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|██████████████████████████████████████████████████████████████████▊                                                                                     | 527/1200 [26:01<33:20,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-527
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-527/config.json
{'eval_loss': 1.8583438396453857, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.622, 'eval_steps_per_second': 5.881, 'epoch': 43.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-527/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-527/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-527/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-526] due to args.save_total_limit
 44%|██████████████████████████████████████████████████████████████████▉                                                                                     | 528/1200 [26:04<33:01,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|██████████████████████████████████████████████████████████████████▉                                                                                     | 528/1200 [26:04<33:01,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-528
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-528/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-528/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-528/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-528/special_tokens_map.json
{'eval_loss': 1.8514797687530518, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.714, 'eval_steps_per_second': 5.886, 'epoch': 44.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-527] due to args.save_total_limit
 44%|███████████████████████████████████████████████████████████████████                                                                                     | 529/1200 [26:07<32:59,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|███████████████████████████████████████████████████████████████████                                                                                     | 529/1200 [26:07<32:59,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-529
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-529/config.json
{'eval_loss': 1.8381707668304443, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5173, 'eval_samples_per_second': 115.978, 'eval_steps_per_second': 5.799, 'epoch': 44.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-529/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-529/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-529/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-528] due to args.save_total_limit
 44%|███████████████████████████████████████████████████████████████████▏                                                                                    | 530/1200 [26:10<32:50,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|███████████████████████████████████████████████████████████████████▏                                                                                    | 530/1200 [26:10<32:50,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-530
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-530/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-530/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-530/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-530/special_tokens_map.json
{'eval_loss': 1.8402633666992188, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.55, 'eval_steps_per_second': 5.878, 'epoch': 44.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-529] due to args.save_total_limit
 44%|███████████████████████████████████████████████████████████████████▎                                                                                    | 531/1200 [26:13<32:39,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|███████████████████████████████████████████████████████████████████▎                                                                                    | 531/1200 [26:13<32:39,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-531
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-531/config.json
{'eval_loss': 1.868725299835205, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5178, 'eval_samples_per_second': 115.879, 'eval_steps_per_second': 5.794, 'epoch': 44.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-531/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-531/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-531/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-530] due to args.save_total_limit
 44%|███████████████████████████████████████████████████████████████████▍                                                                                    | 532/1200 [26:16<32:54,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|███████████████████████████████████████████████████████████████████▍                                                                                    | 532/1200 [26:16<32:54,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-532
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-532/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-532/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-532/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-532/special_tokens_map.json
{'eval_loss': 1.875285029411316, 'eval_f1': 0.5377061406272978, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.427, 'eval_steps_per_second': 5.871, 'epoch': 44.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-531] due to args.save_total_limit
 44%|███████████████████████████████████████████████████████████████████▌                                                                                    | 533/1200 [26:19<32:52,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 44%|███████████████████████████████████████████████████████████████████▌                                                                                    | 533/1200 [26:19<32:52,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-533
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-533/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-533/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-533/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-533/special_tokens_map.json
{'eval_loss': 1.8948522806167603, 'eval_f1': 0.519748984865264, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.475, 'eval_steps_per_second': 5.874, 'epoch': 44.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-532] due to args.save_total_limit
 44%|███████████████████████████████████████████████████████████████████▋                                                                                    | 534/1200 [26:21<32:45,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-534/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-534/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-534/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-534/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-533] due to args.save_total_limit
 45%|███████████████████████████████████████████████████████████████████▊                                                                                    | 535/1200 [26:24<32:40,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 45%|███████████████████████████████████████████████████████████████████▊                                                                                    | 535/1200 [26:25<32:40,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-535
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-535/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-535/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-535/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-535/special_tokens_map.json
{'eval_loss': 2.0077409744262695, 'eval_f1': 0.5197674418604651, 'eval_runtime': 0.5122, 'eval_samples_per_second': 117.149, 'eval_steps_per_second': 5.857, 'epoch': 44.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-534] due to args.save_total_limit
 45%|███████████████████████████████████████████████████████████████████▉                                                                                    | 536/1200 [26:27<32:34,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 45%|███████████████████████████████████████████████████████████████████▉                                                                                    | 536/1200 [26:28<32:34,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-536
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-536/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-536/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-536/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-536/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-535] due to args.save_total_limit
{'eval_loss': 2.0560803413391113, 'eval_f1': 0.5352380952380952, 'eval_runtime': 0.516, 'eval_samples_per_second': 116.272, 'eval_steps_per_second': 5.814, 'epoch': 44.67}
 45%|████████████████████████████████████████████████████████████████████                                                                                    | 537/1200 [26:30<32:41,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 45%|████████████████████████████████████████████████████████████████████                                                                                    | 537/1200 [26:31<32:41,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-537
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-537/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-537/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-537/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-537/special_tokens_map.json
{'eval_loss': 2.1167385578155518, 'eval_f1': 0.5143202208419599, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.671, 'eval_steps_per_second': 5.884, 'epoch': 44.75}
{'eval_loss': 2.177518367767334, 'eval_f1': 0.5143202208419599, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.601, 'eval_steps_per_second': 5.88, 'epoch': 44.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-536] due to args.save_total_limit
 45%|████████████████████████████████████████████████████████████████████▏                                                                                   | 538/1200 [26:33<32:24,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 45%|████████████████████████████████████████████████████████████████████▏                                                                                   | 538/1200 [26:34<32:24,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-538
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-538/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-538/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-538/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-538/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-537] due to args.save_total_limit
 45%|████████████████████████████████████████████████████████████████████▎                                                                                   | 539/1200 [26:36<32:12,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.217250347137451, 'eval_f1': 0.5143202208419599, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.419, 'eval_steps_per_second': 5.871, 'epoch': 44.92}
 45%|████████████████████████████████████████████████████████████████████▎                                                                                   | 539/1200 [26:37<32:12,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-539
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-539/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-539/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-539/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-539/special_tokens_map.json
{'eval_loss': 2.2328989505767822, 'eval_f1': 0.5143202208419599, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.704, 'eval_steps_per_second': 5.885, 'epoch': 45.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-538] due to args.save_total_limit
 45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 540/1200 [26:39<33:27,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 45%|████████████████████████████████████████████████████████████████████▍                                                                                   | 540/1200 [26:40<33:27,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-540
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-540/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-540/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-540/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-540/special_tokens_map.json
{'eval_loss': 2.250457286834717, 'eval_f1': 0.5143202208419599, 'eval_runtime': 0.5125, 'eval_samples_per_second': 117.068, 'eval_steps_per_second': 5.853, 'epoch': 45.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-539] due to args.save_total_limit
 45%|████████████████████████████████████████████████████████████████████▌                                                                                   | 541/1200 [26:42<33:06,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 45%|████████████████████████████████████████████████████████████████████▌                                                                                   | 541/1200 [26:43<33:06,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-541
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-541/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-541/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-541/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-541/special_tokens_map.json
{'eval_loss': 2.2680459022521973, 'eval_f1': 0.5143202208419599, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.645, 'eval_steps_per_second': 5.882, 'epoch': 45.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-540] due to args.save_total_limit
 45%|████████████████████████████████████████████████████████████████████▋                                                                                   | 542/1200 [26:45<32:39,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 45%|████████████████████████████████████████████████████████████████████▋                                                                                   | 542/1200 [26:46<32:39,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-542
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-542/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-542/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-542/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-542/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-541] due to args.save_total_limit
{'eval_loss': 2.265883684158325, 'eval_f1': 0.5143202208419599, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.506, 'eval_steps_per_second': 5.875, 'epoch': 45.25}
 45%|████████████████████████████████████████████████████████████████████▊                                                                                   | 543/1200 [26:48<32:22,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 45%|████████████████████████████████████████████████████████████████████▊                                                                                   | 543/1200 [26:49<32:22,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-543
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-543/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-543/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-543/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-543/special_tokens_map.json
{'eval_loss': 2.228475332260132, 'eval_f1': 0.5292596436602665, 'eval_runtime': 0.5115, 'eval_samples_per_second': 117.309, 'eval_steps_per_second': 5.865, 'epoch': 45.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-542] due to args.save_total_limit
 45%|████████████████████████████████████████████████████████████████████▉                                                                                   | 544/1200 [26:51<32:04,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 45%|████████████████████████████████████████████████████████████████████▉                                                                                   | 544/1200 [26:52<32:04,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-544
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-544/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-544/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-544/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-544/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-543] due to args.save_total_limit
 45%|█████████████████████████████████████████████████████████████████████                                                                                   | 545/1200 [26:54<32:00,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-545/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-545/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-545/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-545/special_tokens_map.json
{'eval_loss': 2.1296703815460205, 'eval_f1': 0.5503358077059031, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.707, 'eval_steps_per_second': 5.885, 'epoch': 45.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-544] due to args.save_total_limit
 46%|█████████████████████████████████████████████████████████████████████▏                                                                                  | 546/1200 [26:57<31:50,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|█████████████████████████████████████████████████████████████████████▏                                                                                  | 546/1200 [26:57<31:50,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-546
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-546/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-546/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-546/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-546/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-545] due to args.save_total_limit
 46%|█████████████████████████████████████████████████████████████████████▎                                                                                  | 547/1200 [27:00<31:41,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|█████████████████████████████████████████████████████████████████████▎                                                                                  | 547/1200 [27:00<31:41,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-547
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-547/config.json
{'eval_loss': 2.0964860916137695, 'eval_f1': 0.5695993179880647, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.707, 'eval_steps_per_second': 5.885, 'epoch': 45.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-547/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-547/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-547/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-546] due to args.save_total_limit
{'eval_loss': 2.062730312347412, 'eval_f1': 0.5726984126984126, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.623, 'eval_steps_per_second': 5.881, 'epoch': 45.67}
 46%|█████████████████████████████████████████████████████████████████████▍                                                                                  | 548/1200 [27:03<31:37,  2.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|█████████████████████████████████████████████████████████████████████▍                                                                                  | 548/1200 [27:03<31:37,  2.91s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-548
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-548/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-548/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-548/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-548/special_tokens_map.json
{'eval_loss': 2.050431966781616, 'eval_f1': 0.585706415797949, 'eval_runtime': 0.5113, 'eval_samples_per_second': 117.357, 'eval_steps_per_second': 5.868, 'epoch': 45.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-547] due to args.save_total_limit
 46%|█████████████████████████████████████████████████████████████████████▌                                                                                  | 549/1200 [27:06<31:52,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|█████████████████████████████████████████████████████████████████████▌                                                                                  | 549/1200 [27:06<31:52,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-549
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-549/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-549/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-549/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-549/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-548] due to args.save_total_limit
{'eval_loss': 2.0647969245910645, 'eval_f1': 0.603301871700528, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.755, 'eval_steps_per_second': 5.888, 'epoch': 45.83}
 46%|█████████████████████████████████████████████████████████████████████▋                                                                                  | 550/1200 [27:09<31:51,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|█████████████████████████████████████████████████████████████████████▋                                                                                  | 550/1200 [27:09<31:51,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-550
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-550/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-550/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-550/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-550/special_tokens_map.json
{'eval_loss': 2.0688159465789795, 'eval_f1': 0.603301871700528, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.044, 'eval_steps_per_second': 5.852, 'epoch': 45.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-549] due to args.save_total_limit
 46%|█████████████████████████████████████████████████████████████████████▊                                                                                  | 551/1200 [27:12<31:50,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|█████████████████████████████████████████████████████████████████████▊                                                                                  | 551/1200 [27:12<31:50,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-551
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-551/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-551/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-551/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-551/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-550] due to args.save_total_limit
{'eval_loss': 2.0811402797698975, 'eval_f1': 0.603301871700528, 'eval_runtime': 0.5142, 'eval_samples_per_second': 116.691, 'eval_steps_per_second': 5.835, 'epoch': 46.0}
 46%|█████████████████████████████████████████████████████████████████████▉                                                                                  | 552/1200 [27:15<33:00,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|█████████████████████████████████████████████████████████████████████▉                                                                                  | 552/1200 [27:15<33:00,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-552
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-552/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-552/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-552/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-552/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-551] due to args.save_total_limit
 46%|██████████████████████████████████████████████████████████████████████                                                                                  | 553/1200 [27:18<32:23,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-553/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-553/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-553/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-553/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-552] due to args.save_total_limit
{'eval_loss': 2.107846260070801, 'eval_f1': 0.603301871700528, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.376, 'eval_steps_per_second': 5.869, 'epoch': 46.17}
 46%|██████████████████████████████████████████████████████████████████████▏                                                                                 | 554/1200 [27:21<32:04,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|██████████████████████████████████████████████████████████████████████▏                                                                                 | 554/1200 [27:21<32:04,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-554
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-554/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-554/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-554/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-554/special_tokens_map.json
{'eval_loss': 2.100886344909668, 'eval_f1': 0.603301871700528, 'eval_runtime': 0.5167, 'eval_samples_per_second': 116.128, 'eval_steps_per_second': 5.806, 'epoch': 46.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-553] due to args.save_total_limit
 46%|██████████████████████████████████████████████████████████████████████▎                                                                                 | 555/1200 [27:24<31:47,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|██████████████████████████████████████████████████████████████████████▎                                                                                 | 555/1200 [27:24<31:47,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-555
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-555/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-555/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-555/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-555/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-554] due to args.save_total_limit
{'eval_loss': 2.086655855178833, 'eval_f1': 0.5881499177151351, 'eval_runtime': 0.5146, 'eval_samples_per_second': 116.6, 'eval_steps_per_second': 5.83, 'epoch': 46.33}
 46%|██████████████████████████████████████████████████████████████████████▍                                                                                 | 556/1200 [27:27<31:47,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|██████████████████████████████████████████████████████████████████████▍                                                                                 | 556/1200 [27:27<31:47,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-556
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-556/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-556/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-556/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-556/special_tokens_map.json
{'eval_loss': 2.1024887561798096, 'eval_f1': 0.5543312609596683, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.826, 'eval_steps_per_second': 5.891, 'epoch': 46.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-555] due to args.save_total_limit
 46%|██████████████████████████████████████████████████████████████████████▌                                                                                 | 557/1200 [27:30<32:58,  3.08s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|██████████████████████████████████████████████████████████████████████▌                                                                                 | 557/1200 [27:30<32:58,  3.08s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-557
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-557/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-557/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-557/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-557/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-556] due to args.save_total_limit
{'eval_loss': 2.1178388595581055, 'eval_f1': 0.5352380952380952, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.729, 'eval_steps_per_second': 5.886, 'epoch': 46.5}
 46%|██████████████████████████████████████████████████████████████████████▋                                                                                 | 558/1200 [27:33<32:20,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 46%|██████████████████████████████████████████████████████████████████████▋                                                                                 | 558/1200 [27:33<32:20,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-558
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-558/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-558/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-558/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-558/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-557] due to args.save_total_limit
 47%|██████████████████████████████████████████████████████████████████████▊                                                                                 | 559/1200 [27:36<32:01,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-559/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-559/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-559/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-559/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-558] due to args.save_total_limit
{'eval_loss': 2.1405787467956543, 'eval_f1': 0.5141753671165435, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.487, 'eval_steps_per_second': 5.874, 'epoch': 46.67}
 47%|██████████████████████████████████████████████████████████████████████▉                                                                                 | 560/1200 [27:39<31:46,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 47%|██████████████████████████████████████████████████████████████████████▉                                                                                 | 560/1200 [27:39<31:46,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-560
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-560/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-560/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-560/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-560/special_tokens_map.json
{'eval_loss': 2.141664743423462, 'eval_f1': 0.4619117914487126, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.557, 'eval_steps_per_second': 5.878, 'epoch': 46.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-559] due to args.save_total_limit
 47%|███████████████████████████████████████████████████████████████████████                                                                                 | 561/1200 [27:42<31:40,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 47%|███████████████████████████████████████████████████████████████████████                                                                                 | 561/1200 [27:42<31:40,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-561
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-561/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-561/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-561/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-561/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-560] due to args.save_total_limit
{'eval_loss': 2.1846513748168945, 'eval_f1': 0.4656999641962048, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.363, 'eval_steps_per_second': 5.868, 'epoch': 46.83}
 47%|███████████████████████████████████████████████████████████████████████▏                                                                                | 562/1200 [27:45<31:40,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 47%|███████████████████████████████████████████████████████████████████████▏                                                                                | 562/1200 [27:45<31:40,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-562
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-562/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-562/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-562/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-562/special_tokens_map.json
{'eval_loss': 2.2194790840148926, 'eval_f1': 0.4667387387387387, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.698, 'eval_steps_per_second': 5.885, 'epoch': 46.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-561] due to args.save_total_limit
 47%|███████████████████████████████████████████████████████████████████████▎                                                                                | 563/1200 [27:48<31:32,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 47%|███████████████████████████████████████████████████████████████████████▎                                                                                | 563/1200 [27:48<31:32,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-563
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-563/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-563/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-563/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-563/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-562] due to args.save_total_limit
 47%|███████████████████████████████████████████████████████████████████████▍                                                                                | 564/1200 [27:51<31:17,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.2580888271331787, 'eval_f1': 0.4656999641962048, 'eval_runtime': 0.5132, 'eval_samples_per_second': 116.907, 'eval_steps_per_second': 5.845, 'epoch': 47.0}
 47%|███████████████████████████████████████████████████████████████████████▍                                                                                | 564/1200 [27:51<31:17,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-564
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-564/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-564/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-564/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-564/special_tokens_map.json
{'eval_loss': 2.2582333087921143, 'eval_f1': 0.4774054054054054, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.582, 'eval_steps_per_second': 5.879, 'epoch': 47.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-563] due to args.save_total_limit
 47%|███████████████████████████████████████████████████████████████████████▌                                                                                | 565/1200 [27:53<31:17,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 47%|███████████████████████████████████████████████████████████████████████▌                                                                                | 565/1200 [27:54<31:17,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-565
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-565/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-565/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-565/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-565/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-564] due to args.save_total_limit
 47%|███████████████████████████████████████████████████████████████████████▋                                                                                | 566/1200 [27:57<31:30,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-566/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-566/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-566/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-566/special_tokens_map.json
{'eval_loss': 2.218485116958618, 'eval_f1': 0.4625386996904025, 'eval_runtime': 0.5187, 'eval_samples_per_second': 115.675, 'eval_steps_per_second': 5.784, 'epoch': 47.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-565] due to args.save_total_limit
 47%|███████████████████████████████████████████████████████████████████████▊                                                                                | 567/1200 [27:59<31:15,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 47%|███████████████████████████████████████████████████████████████████████▊                                                                                | 567/1200 [28:00<31:15,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-567
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-567/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-567/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-567/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-567/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-566] due to args.save_total_limit
 47%|███████████████████████████████████████████████████████████████████████▉                                                                                | 568/1200 [28:02<31:02,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 47%|███████████████████████████████████████████████████████████████████████▉                                                                                | 568/1200 [28:03<31:02,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-568
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-568/config.json
{'eval_loss': 2.205104351043701, 'eval_f1': 0.4625386996904025, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.663, 'eval_steps_per_second': 5.883, 'epoch': 47.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-568/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-568/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-568/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-567] due to args.save_total_limit
{'eval_loss': 2.1917786598205566, 'eval_f1': 0.4619117914487126, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.56, 'eval_steps_per_second': 5.878, 'epoch': 47.42}
 47%|████████████████████████████████████████████████████████████████████████                                                                                | 569/1200 [28:05<30:57,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 47%|████████████████████████████████████████████████████████████████████████                                                                                | 569/1200 [28:06<30:57,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-569
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-569/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-569/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-569/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-569/special_tokens_map.json
{'eval_loss': 2.2262375354766846, 'eval_f1': 0.48751322751322756, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.365, 'eval_steps_per_second': 5.868, 'epoch': 47.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-568] due to args.save_total_limit
 48%|████████████████████████████████████████████████████████████████████████▏                                                                               | 570/1200 [28:08<30:42,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|████████████████████████████████████████████████████████████████████████▏                                                                               | 570/1200 [28:09<30:42,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-570
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-570/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-570/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-570/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-570/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-569] due to args.save_total_limit
{'eval_loss': 2.270085573196411, 'eval_f1': 0.5197674418604651, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.831, 'eval_steps_per_second': 5.842, 'epoch': 47.58}
 48%|████████████████████████████████████████████████████████████████████████▎                                                                               | 571/1200 [28:11<30:51,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|████████████████████████████████████████████████████████████████████████▎                                                                               | 571/1200 [28:12<30:51,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-571
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-571/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-571/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-571/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-571/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-570] due to args.save_total_limit
 48%|████████████████████████████████████████████████████████████████████████▍                                                                               | 572/1200 [28:14<30:48,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|████████████████████████████████████████████████████████████████████████▍                                                                               | 572/1200 [28:15<30:48,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-572
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-572/config.json
{'eval_loss': 2.2939412593841553, 'eval_f1': 0.5143202208419599, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.886, 'eval_steps_per_second': 5.844, 'epoch': 47.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-572/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-572/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-572/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-571] due to args.save_total_limit
{'eval_loss': 2.297654390335083, 'eval_f1': 0.5309478538333771, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.631, 'eval_steps_per_second': 5.882, 'epoch': 47.75}
 48%|████████████████████████████████████████████████████████████████████████▌                                                                               | 573/1200 [28:17<31:56,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|████████████████████████████████████████████████████████████████████████▌                                                                               | 573/1200 [28:18<31:56,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-573
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-573/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-573/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-573/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-573/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-572] due to args.save_total_limit
 48%|████████████████████████████████████████████████████████████████████████▋                                                                               | 574/1200 [28:20<31:24,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|████████████████████████████████████████████████████████████████████████▋                                                                               | 574/1200 [28:21<31:24,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-574
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-574/config.json
{'eval_loss': 2.274540424346924, 'eval_f1': 0.531332781913427, 'eval_runtime': 0.515, 'eval_samples_per_second': 116.494, 'eval_steps_per_second': 5.825, 'epoch': 47.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-574/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-574/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-574/special_tokens_map.json
{'eval_loss': 2.2283856868743896, 'eval_f1': 0.531332781913427, 'eval_runtime': 0.5114, 'eval_samples_per_second': 117.314, 'eval_steps_per_second': 5.866, 'epoch': 47.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-573] due to args.save_total_limit
 48%|████████████████████████████████████████████████████████████████████████▊                                                                               | 575/1200 [28:23<31:04,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|████████████████████████████████████████████████████████████████████████▊                                                                               | 575/1200 [28:24<31:04,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-575
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-575/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-575/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-575/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-575/special_tokens_map.json
{'eval_loss': 2.162632942199707, 'eval_f1': 0.5546482628138975, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.48, 'eval_steps_per_second': 5.874, 'epoch': 48.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-574] due to args.save_total_limit
 48%|████████████████████████████████████████████████████████████████████████▉                                                                               | 576/1200 [28:26<30:48,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|████████████████████████████████████████████████████████████████████████▉                                                                               | 576/1200 [28:27<30:48,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-576
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-576/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-576/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-576/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-576/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-575] due to args.save_total_limit
{'eval_loss': 2.087534189224243, 'eval_f1': 0.5557292990931436, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.49, 'eval_steps_per_second': 5.874, 'epoch': 48.08}
 48%|█████████████████████████████████████████████████████████████████████████                                                                               | 577/1200 [28:29<30:31,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|█████████████████████████████████████████████████████████████████████████                                                                               | 577/1200 [28:30<30:31,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-577
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-577/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-577/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-577/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-577/special_tokens_map.json
{'eval_loss': 2.04388165473938, 'eval_f1': 0.5400854700854701, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.461, 'eval_steps_per_second': 5.873, 'epoch': 48.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-576] due to args.save_total_limit
 48%|█████████████████████████████████████████████████████████████████████████▏                                                                              | 578/1200 [28:32<30:24,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|█████████████████████████████████████████████████████████████████████████▏                                                                              | 578/1200 [28:32<30:24,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-578
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-578/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-578/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-578/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-578/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-577] due to args.save_total_limit
 48%|█████████████████████████████████████████████████████████████████████████▎                                                                              | 579/1200 [28:35<30:12,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-579/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-579/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-579/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-579/special_tokens_map.json
{'eval_loss': 1.9667490720748901, 'eval_f1': 0.5376281544702597, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.621, 'eval_steps_per_second': 5.881, 'epoch': 48.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-578] due to args.save_total_limit
 48%|█████████████████████████████████████████████████████████████████████████▍                                                                              | 580/1200 [28:38<31:20,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|█████████████████████████████████████████████████████████████████████████▍                                                                              | 580/1200 [28:39<31:20,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-580
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-580/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-580/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-580/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-580/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-579] due to args.save_total_limit
 48%|█████████████████████████████████████████████████████████████████████████▌                                                                              | 581/1200 [28:41<31:00,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-581/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-581/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-581/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-581/special_tokens_map.json
{'eval_loss': 1.9495360851287842, 'eval_f1': 0.5376281544702597, 'eval_runtime': 0.5124, 'eval_samples_per_second': 117.101, 'eval_steps_per_second': 5.855, 'epoch': 48.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-580] due to args.save_total_limit
 48%|█████████████████████████████████████████████████████████████████████████▋                                                                              | 582/1200 [28:44<30:35,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 48%|█████████████████████████████████████████████████████████████████████████▋                                                                              | 582/1200 [28:44<30:35,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-582
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-582/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-582/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-582/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-582/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-581] due to args.save_total_limit
 49%|█████████████████████████████████████████████████████████████████████████▊                                                                              | 583/1200 [28:47<30:19,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 49%|█████████████████████████████████████████████████████████████████████████▊                                                                              | 583/1200 [28:47<30:19,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-583
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-583/config.json
{'eval_loss': 1.9596501588821411, 'eval_f1': 0.5400854700854701, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.644, 'eval_steps_per_second': 5.882, 'epoch': 48.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-583/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-583/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-583/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-582] due to args.save_total_limit
{'eval_loss': 1.9520680904388428, 'eval_f1': 0.5400854700854701, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.659, 'eval_steps_per_second': 5.883, 'epoch': 48.67}
 49%|█████████████████████████████████████████████████████████████████████████▉                                                                              | 584/1200 [28:50<30:13,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 49%|█████████████████████████████████████████████████████████████████████████▉                                                                              | 584/1200 [28:50<30:13,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-584
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-584/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-584/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-584/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-584/special_tokens_map.json
{'eval_loss': 1.9439228773117065, 'eval_f1': 0.5240740740740741, 'eval_runtime': 0.5142, 'eval_samples_per_second': 116.696, 'eval_steps_per_second': 5.835, 'epoch': 48.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-583] due to args.save_total_limit
 49%|██████████████████████████████████████████████████████████████████████████                                                                              | 585/1200 [28:53<29:57,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 49%|██████████████████████████████████████████████████████████████████████████                                                                              | 585/1200 [28:53<29:57,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-585
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-585/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-585/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-585/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-585/special_tokens_map.json
{'eval_loss': 1.9393064975738525, 'eval_f1': 0.5240740740740741, 'eval_runtime': 0.5232, 'eval_samples_per_second': 114.683, 'eval_steps_per_second': 5.734, 'epoch': 48.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-584] due to args.save_total_limit
 49%|██████████████████████████████████████████████████████████████████████████▏                                                                             | 586/1200 [28:56<30:09,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 49%|██████████████████████████████████████████████████████████████████████████▏                                                                             | 586/1200 [28:56<30:09,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-586
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-586/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-586/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-586/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-586/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-585] due to args.save_total_limit
 49%|██████████████████████████████████████████████████████████████████████████▎                                                                             | 587/1200 [28:59<30:10,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 49%|██████████████████████████████████████████████████████████████████████████▎                                                                             | 587/1200 [28:59<30:10,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-587
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-587/config.json
{'eval_loss': 1.9533129930496216, 'eval_f1': 0.5076437469801055, 'eval_runtime': 0.5155, 'eval_samples_per_second': 116.393, 'eval_steps_per_second': 5.82, 'epoch': 48.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-587/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-587/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-587/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-586] due to args.save_total_limit
{'eval_loss': 1.9887521266937256, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5189, 'eval_samples_per_second': 115.619, 'eval_steps_per_second': 5.781, 'epoch': 49.0}
 49%|██████████████████████████████████████████████████████████████████████████▍                                                                             | 588/1200 [29:02<30:19,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 49%|██████████████████████████████████████████████████████████████████████████▍                                                                             | 588/1200 [29:02<30:19,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-588
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-588/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-588/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-588/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-588/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-587] due to args.save_total_limit
 49%|██████████████████████████████████████████████████████████████████████████▌                                                                             | 589/1200 [29:05<30:06,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 49%|██████████████████████████████████████████████████████████████████████████▌                                                                             | 589/1200 [29:05<30:06,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-589
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-589/config.json
{'eval_loss': 2.0484538078308105, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.74, 'eval_steps_per_second': 5.887, 'epoch': 49.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-589/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-589/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-589/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-588] due to args.save_total_limit
 49%|██████████████████████████████████████████████████████████████████████████▋                                                                             | 590/1200 [29:07<29:55,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.099294424057007, 'eval_f1': 0.48459383753501406, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.726, 'eval_steps_per_second': 5.886, 'epoch': 49.17}
 49%|██████████████████████████████████████████████████████████████████████████▋                                                                             | 590/1200 [29:08<29:55,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-590
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-590/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-590/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-590/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-590/special_tokens_map.json
{'eval_loss': 2.1561059951782227, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.752, 'eval_steps_per_second': 5.888, 'epoch': 49.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-589] due to args.save_total_limit
 49%|██████████████████████████████████████████████████████████████████████████▊                                                                             | 591/1200 [29:10<29:48,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 49%|██████████████████████████████████████████████████████████████████████████▊                                                                             | 591/1200 [29:11<29:48,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-591
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-591/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-591/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-591/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-591/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-590] due to args.save_total_limit
 49%|██████████████████████████████████████████████████████████████████████████▉                                                                             | 592/1200 [29:13<29:43,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.208574056625366, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.774, 'eval_steps_per_second': 5.889, 'epoch': 49.33}
 49%|██████████████████████████████████████████████████████████████████████████▉                                                                             | 592/1200 [29:14<29:43,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-592
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-592/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-592/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-592/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-592/special_tokens_map.json
{'eval_loss': 2.212186574935913, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.516, 'eval_samples_per_second': 116.278, 'eval_steps_per_second': 5.814, 'epoch': 49.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-591] due to args.save_total_limit
 49%|███████████████████████████████████████████████████████████████████████████                                                                             | 593/1200 [29:16<29:37,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 49%|███████████████████████████████████████████████████████████████████████████                                                                             | 593/1200 [29:17<29:37,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-593
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-593/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-593/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-593/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-593/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-592] due to args.save_total_limit
 50%|███████████████████████████████████████████████████████████████████████████▏                                                                            | 594/1200 [29:20<30:36,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.224191188812256, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.643, 'eval_steps_per_second': 5.882, 'epoch': 49.5}
 50%|███████████████████████████████████████████████████████████████████████████▏                                                                            | 594/1200 [29:20<30:36,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-594
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-594/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-594/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-594/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-594/special_tokens_map.json
{'eval_loss': 2.209287405014038, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.462, 'eval_steps_per_second': 5.873, 'epoch': 49.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-593] due to args.save_total_limit
 50%|███████████████████████████████████████████████████████████████████████████▎                                                                            | 595/1200 [29:22<30:09,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|███████████████████████████████████████████████████████████████████████████▎                                                                            | 595/1200 [29:23<30:09,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-595
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-595/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-595/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-595/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-595/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-594] due to args.save_total_limit
 50%|███████████████████████████████████████████████████████████████████████████▍                                                                            | 596/1200 [29:25<29:57,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.59it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-596/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-596/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-596/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-596/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-595] due to args.save_total_limit
{'eval_loss': 2.2047619819641113, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.5144, 'eval_samples_per_second': 116.635, 'eval_steps_per_second': 5.832, 'epoch': 49.75}
 50%|███████████████████████████████████████████████████████████████████████████▌                                                                            | 597/1200 [29:28<29:51,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|███████████████████████████████████████████████████████████████████████████▌                                                                            | 597/1200 [29:29<29:51,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-597
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-597/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-597/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-597/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-597/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-596] due to args.save_total_limit
 50%|███████████████████████████████████████████████████████████████████████████▋                                                                            | 598/1200 [29:31<29:48,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|███████████████████████████████████████████████████████████████████████████▋                                                                            | 598/1200 [29:32<29:48,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-598
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-598/config.json
{'eval_loss': 2.1932358741760254, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.5, 'eval_steps_per_second': 5.875, 'epoch': 49.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-598/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-598/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-598/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-597] due to args.save_total_limit
{'eval_loss': 2.1638741493225098, 'eval_f1': 0.4680124223602485, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.55, 'eval_steps_per_second': 5.877, 'epoch': 49.92}
 50%|███████████████████████████████████████████████████████████████████████████▊                                                                            | 599/1200 [29:34<29:48,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|███████████████████████████████████████████████████████████████████████████▊                                                                            | 599/1200 [29:35<29:48,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-599
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-599/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-599/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-599/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-599/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-598] due to args.save_total_limit
 50%|████████████████████████████████████████████████████████████████████████████                                                                            | 600/1200 [29:37<29:33,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|████████████████████████████████████████████████████████████████████████████                                                                            | 600/1200 [29:38<29:33,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-600
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-600/config.json
{'eval_loss': 2.1374921798706055, 'eval_f1': 0.4652910052910053, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.495, 'eval_steps_per_second': 5.875, 'epoch': 50.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-600/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-600/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-600/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-599] due to args.save_total_limit
{'eval_loss': 2.113354444503784, 'eval_f1': 0.46459948320413436, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.711, 'eval_steps_per_second': 5.886, 'epoch': 50.08}
 50%|████████████████████████████████████████████████████████████████████████████▏                                                                           | 601/1200 [29:40<29:29,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|████████████████████████████████████████████████████████████████████████████▏                                                                           | 601/1200 [29:41<29:29,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-601
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-601/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-601/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-601/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-601/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-600] due to args.save_total_limit
 50%|████████████████████████████████████████████████████████████████████████████▎                                                                           | 602/1200 [29:43<29:29,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|████████████████████████████████████████████████████████████████████████████▎                                                                           | 602/1200 [29:44<29:29,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-602
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-602/config.json
{'eval_loss': 2.0948638916015625, 'eval_f1': 0.45180878552971576, 'eval_runtime': 0.5153, 'eval_samples_per_second': 116.428, 'eval_steps_per_second': 5.821, 'epoch': 50.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-602/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-602/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-602/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-601] due to args.save_total_limit
 50%|████████████████████████████████████████████████████████████████████████████▍                                                                           | 603/1200 [29:46<29:17,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.093167543411255, 'eval_f1': 0.5028132992327365, 'eval_runtime': 0.5147, 'eval_samples_per_second': 116.569, 'eval_steps_per_second': 5.828, 'epoch': 50.25}
 50%|████████████████████████████████████████████████████████████████████████████▍                                                                           | 603/1200 [29:47<29:17,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-603
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-603/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-603/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-603/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-603/special_tokens_map.json
{'eval_loss': 2.104930877685547, 'eval_f1': 0.5205673758865248, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.584, 'eval_steps_per_second': 5.879, 'epoch': 50.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-602] due to args.save_total_limit
 50%|████████████████████████████████████████████████████████████████████████████▌                                                                           | 604/1200 [29:49<29:05,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|████████████████████████████████████████████████████████████████████████████▌                                                                           | 604/1200 [29:49<29:05,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-604
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-604/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-604/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-604/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-604/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-603] due to args.save_total_limit
{'eval_loss': 2.089975118637085, 'eval_f1': 0.5216382651165259, 'eval_runtime': 0.5113, 'eval_samples_per_second': 117.338, 'eval_steps_per_second': 5.867, 'epoch': 50.42}
 50%|████████████████████████████████████████████████████████████████████████████▋                                                                           | 605/1200 [29:52<29:09,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|████████████████████████████████████████████████████████████████████████████▋                                                                           | 605/1200 [29:52<29:09,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-605
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-605/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-605/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-605/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-605/special_tokens_map.json
{'eval_loss': 2.0830490589141846, 'eval_f1': 0.5216382651165259, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.695, 'eval_steps_per_second': 5.885, 'epoch': 50.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-604] due to args.save_total_limit
 50%|████████████████████████████████████████████████████████████████████████████▊                                                                           | 606/1200 [29:55<29:04,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 50%|████████████████████████████████████████████████████████████████████████████▊                                                                           | 606/1200 [29:55<29:04,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-606
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-606/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-606/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-606/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-606/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-605] due to args.save_total_limit
{'eval_loss': 2.0898876190185547, 'eval_f1': 0.5216382651165259, 'eval_runtime': 0.5165, 'eval_samples_per_second': 116.163, 'eval_steps_per_second': 5.808, 'epoch': 50.58}
 51%|████████████████████████████████████████████████████████████████████████████▉                                                                           | 607/1200 [29:58<29:39,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 51%|████████████████████████████████████████████████████████████████████████████▉                                                                           | 607/1200 [29:58<29:39,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-607
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-607/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-607/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-607/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-607/special_tokens_map.json
{'eval_loss': 2.092902421951294, 'eval_f1': 0.5396724538151322, 'eval_runtime': 0.5073, 'eval_samples_per_second': 118.283, 'eval_steps_per_second': 5.914, 'epoch': 50.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-606] due to args.save_total_limit
 51%|█████████████████████████████████████████████████████████████████████████████                                                                           | 608/1200 [30:01<29:21,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 51%|█████████████████████████████████████████████████████████████████████████████                                                                           | 608/1200 [30:01<29:21,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-608
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-608/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-608/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-608/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-608/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-607] due to args.save_total_limit
 51%|█████████████████████████████████████████████████████████████████████████████▏                                                                          | 609/1200 [30:04<29:23,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-609/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-609/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-609/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-609/special_tokens_map.json
{'eval_loss': 2.0425686836242676, 'eval_f1': 0.5400854700854701, 'eval_runtime': 0.5118, 'eval_samples_per_second': 117.234, 'eval_steps_per_second': 5.862, 'epoch': 50.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-608] due to args.save_total_limit
 51%|█████████████████████████████████████████████████████████████████████████████▎                                                                          | 610/1200 [30:07<29:04,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 51%|█████████████████████████████████████████████████████████████████████████████▎                                                                          | 610/1200 [30:07<29:04,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-610
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-610/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-610/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-610/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-610/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-609] due to args.save_total_limit
 51%|█████████████████████████████████████████████████████████████████████████████▍                                                                          | 611/1200 [30:10<28:58,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-611/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-611/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-611/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-611/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-610] due to args.save_total_limit
{'eval_loss': 2.016908884048462, 'eval_f1': 0.5082010582010582, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.651, 'eval_steps_per_second': 5.883, 'epoch': 51.0}
 51%|█████████████████████████████████████████████████████████████████████████████▌                                                                          | 612/1200 [30:13<29:52,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 51%|█████████████████████████████████████████████████████████████████████████████▌                                                                          | 612/1200 [30:14<29:52,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-612
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-612/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-612/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-612/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-612/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-611] due to args.save_total_limit
 51%|█████████████████████████████████████████████████████████████████████████████▋                                                                          | 613/1200 [30:16<29:25,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.49it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-613/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-613/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-613/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-613/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-612] due to args.save_total_limit
{'eval_loss': 2.010390043258667, 'eval_f1': 0.525061995793703, 'eval_runtime': 0.515, 'eval_samples_per_second': 116.514, 'eval_steps_per_second': 5.826, 'epoch': 51.17}
 51%|█████████████████████████████████████████████████████████████████████████████▊                                                                          | 614/1200 [30:19<29:12,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 51%|█████████████████████████████████████████████████████████████████████████████▊                                                                          | 614/1200 [30:19<29:12,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-614
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-614/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-614/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-614/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-614/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-613] due to args.save_total_limit
 51%|█████████████████████████████████████████████████████████████████████████████▉                                                                          | 615/1200 [30:22<29:04,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 51%|█████████████████████████████████████████████████████████████████████████████▉                                                                          | 615/1200 [30:22<29:04,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-615
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-615/config.json
{'eval_loss': 2.0075020790100098, 'eval_f1': 0.525061995793703, 'eval_runtime': 0.5145, 'eval_samples_per_second': 116.623, 'eval_steps_per_second': 5.831, 'epoch': 51.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-615/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-615/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-615/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-614] due to args.save_total_limit
 51%|██████████████████████████████████████████████████████████████████████████████                                                                          | 616/1200 [30:25<30:08,  3.10s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 51%|██████████████████████████████████████████████████████████████████████████████                                                                          | 616/1200 [30:26<30:08,  3.10s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-616
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-616/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-616/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-616/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-616/special_tokens_map.json
{'eval_loss': 2.0224742889404297, 'eval_f1': 0.5082010582010582, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.81, 'eval_steps_per_second': 5.891, 'epoch': 51.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-615] due to args.save_total_limit
 51%|██████████████████████████████████████████████████████████████████████████████▏                                                                         | 617/1200 [30:28<29:37,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 51%|██████████████████████████████████████████████████████████████████████████████▏                                                                         | 617/1200 [30:29<29:37,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-617
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-617/config.json
{'eval_loss': 2.0297346115112305, 'eval_f1': 0.5082010582010582, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.895, 'eval_steps_per_second': 5.845, 'epoch': 51.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-617/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-617/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-617/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-616] due to args.save_total_limit
{'eval_loss': 2.056666851043701, 'eval_f1': 0.5076437469801055, 'eval_runtime': 0.5148, 'eval_samples_per_second': 116.541, 'eval_steps_per_second': 5.827, 'epoch': 51.5}
 52%|██████████████████████████████████████████████████████████████████████████████▎                                                                         | 618/1200 [30:31<29:12,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 52%|██████████████████████████████████████████████████████████████████████████████▎                                                                         | 618/1200 [30:32<29:12,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-618
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-618/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-618/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-618/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-618/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-617] due to args.save_total_limit
 52%|██████████████████████████████████████████████████████████████████████████████▍                                                                         | 619/1200 [30:34<28:58,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.25it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-619/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-619/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-619/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-619/special_tokens_map.json
{'eval_loss': 2.1852619647979736, 'eval_f1': 0.5403239556692242, 'eval_runtime': 0.5115, 'eval_samples_per_second': 117.296, 'eval_steps_per_second': 5.865, 'epoch': 51.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-618] due to args.save_total_limit
 52%|██████████████████████████████████████████████████████████████████████████████▌                                                                         | 620/1200 [30:37<28:46,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 52%|██████████████████████████████████████████████████████████████████████████████▌                                                                         | 620/1200 [30:37<28:46,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-620
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-620/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-620/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-620/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-620/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-619] due to args.save_total_limit
 52%|██████████████████████████████████████████████████████████████████████████████▋                                                                         | 621/1200 [30:40<28:50,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 52%|██████████████████████████████████████████████████████████████████████████████▋                                                                         | 621/1200 [30:40<28:50,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-621
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-621/config.json
{'eval_loss': 2.2706239223480225, 'eval_f1': 0.5498746867167921, 'eval_runtime': 0.5165, 'eval_samples_per_second': 116.174, 'eval_steps_per_second': 5.809, 'epoch': 51.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-621/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-621/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-621/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-620] due to args.save_total_limit
{'eval_loss': 2.3277132511138916, 'eval_f1': 0.5590324816131267, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.394, 'eval_steps_per_second': 5.87, 'epoch': 51.83}
 52%|██████████████████████████████████████████████████████████████████████████████▊                                                                         | 622/1200 [30:43<28:37,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 52%|██████████████████████████████████████████████████████████████████████████████▊                                                                         | 622/1200 [30:43<28:37,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-622
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-622/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-622/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-622/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-622/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-621] due to args.save_total_limit
 52%|██████████████████████████████████████████████████████████████████████████████▉                                                                         | 623/1200 [30:46<28:50,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 52%|██████████████████████████████████████████████████████████████████████████████▉                                                                         | 623/1200 [30:46<28:50,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-623
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-623/config.json
{'eval_loss': 2.43097186088562, 'eval_f1': 0.5590324816131267, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.789, 'eval_steps_per_second': 5.889, 'epoch': 51.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-623/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-623/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-623/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-622] due to args.save_total_limit
{'eval_loss': 2.471614122390747, 'eval_f1': 0.5590324816131267, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.633, 'eval_steps_per_second': 5.882, 'epoch': 52.0}
 52%|███████████████████████████████████████████████████████████████████████████████                                                                         | 624/1200 [30:49<28:31,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 52%|███████████████████████████████████████████████████████████████████████████████                                                                         | 624/1200 [30:49<28:31,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-624
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-624/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-624/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-624/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-624/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-623] due to args.save_total_limit
 52%|███████████████████████████████████████████████████████████████████████████████▏                                                                        | 625/1200 [30:52<28:22,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 52%|███████████████████████████████████████████████████████████████████████████████▏                                                                        | 625/1200 [30:52<28:22,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-625
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-625/config.json
{'eval_loss': 2.4838922023773193, 'eval_f1': 0.5590324816131267, 'eval_runtime': 0.5124, 'eval_samples_per_second': 117.098, 'eval_steps_per_second': 5.855, 'epoch': 52.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-625/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-625/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-625/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-624] due to args.save_total_limit
 52%|███████████████████████████████████████████████████████████████████████████████▎                                                                        | 626/1200 [30:55<28:29,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.468944787979126, 'eval_f1': 0.5590324816131267, 'eval_runtime': 0.5158, 'eval_samples_per_second': 116.323, 'eval_steps_per_second': 5.816, 'epoch': 52.17}
 52%|███████████████████████████████████████████████████████████████████████████████▎                                                                        | 626/1200 [30:55<28:29,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-626
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-626/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-626/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-626/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-626/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-625] due to args.save_total_limit
 52%|███████████████████████████████████████████████████████████████████████████████▍                                                                        | 627/1200 [30:58<28:14,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 52%|███████████████████████████████████████████████████████████████████████████████▍                                                                        | 627/1200 [30:58<28:14,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-627
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-627/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-627/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-627/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-627/special_tokens_map.json
{'eval_loss': 2.421502113342285, 'eval_f1': 0.5452844635307433, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.663, 'eval_steps_per_second': 5.883, 'epoch': 52.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-626] due to args.save_total_limit
 52%|███████████████████████████████████████████████████████████████████████████████▌                                                                        | 628/1200 [31:01<28:06,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-628/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-628/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-628/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-628/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-627] due to args.save_total_limit
 52%|███████████████████████████████████████████████████████████████████████████████▋                                                                        | 629/1200 [31:04<28:00,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 52%|███████████████████████████████████████████████████████████████████████████████▋                                                                        | 629/1200 [31:04<28:00,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-629
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-629/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-629/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-629/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-629/special_tokens_map.json
{'eval_loss': 2.2756729125976562, 'eval_f1': 0.5403239556692242, 'eval_runtime': 0.5124, 'eval_samples_per_second': 117.088, 'eval_steps_per_second': 5.854, 'epoch': 52.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-628] due to args.save_total_limit
 52%|███████████████████████████████████████████████████████████████████████████████▊                                                                        | 630/1200 [31:07<28:02,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-630/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-630/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-630/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-630/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-629] due to args.save_total_limit
{'eval_loss': 2.1736748218536377, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.121, 'eval_steps_per_second': 5.856, 'epoch': 52.58}
 53%|███████████████████████████████████████████████████████████████████████████████▉                                                                        | 631/1200 [31:09<27:46,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|███████████████████████████████████████████████████████████████████████████████▉                                                                        | 631/1200 [31:10<27:46,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-631
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-631/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-631/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-631/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-631/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-630] due to args.save_total_limit
 53%|████████████████████████████████████████████████████████████████████████████████                                                                        | 632/1200 [31:12<27:41,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|████████████████████████████████████████████████████████████████████████████████                                                                        | 632/1200 [31:13<27:41,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-632
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-632/config.json
{'eval_loss': 2.1561245918273926, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.884, 'eval_steps_per_second': 5.844, 'epoch': 52.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-632/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-632/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-632/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-631] due to args.save_total_limit
{'eval_loss': 2.158721923828125, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.522, 'eval_samples_per_second': 114.953, 'eval_steps_per_second': 5.748, 'epoch': 52.75}
 53%|████████████████████████████████████████████████████████████████████████████████▏                                                                       | 633/1200 [31:15<27:43,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|████████████████████████████████████████████████████████████████████████████████▏                                                                       | 633/1200 [31:16<27:43,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-633
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-633/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-633/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-633/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-633/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-632] due to args.save_total_limit
 53%|████████████████████████████████████████████████████████████████████████████████▎                                                                       | 634/1200 [31:18<27:50,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|████████████████████████████████████████████████████████████████████████████████▎                                                                       | 634/1200 [31:19<27:50,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-634
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-634/config.json
{'eval_loss': 2.1782209873199463, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5185, 'eval_samples_per_second': 115.724, 'eval_steps_per_second': 5.786, 'epoch': 52.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-634/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-634/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-634/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-633] due to args.save_total_limit
{'eval_loss': 2.208223819732666, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.5153, 'eval_samples_per_second': 116.445, 'eval_steps_per_second': 5.822, 'epoch': 52.92}
 53%|████████████████████████████████████████████████████████████████████████████████▍                                                                       | 635/1200 [31:22<28:44,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|████████████████████████████████████████████████████████████████████████████████▍                                                                       | 635/1200 [31:22<28:44,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-635
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-635/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-635/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-635/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-635/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-634] due to args.save_total_limit
 53%|████████████████████████████████████████████████████████████████████████████████▌                                                                       | 636/1200 [31:24<28:16,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|████████████████████████████████████████████████████████████████████████████████▌                                                                       | 636/1200 [31:25<28:16,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-636
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-636/config.json
{'eval_loss': 2.2224884033203125, 'eval_f1': 0.520899470899471, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.655, 'eval_steps_per_second': 5.883, 'epoch': 53.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-636/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-636/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-636/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-635] due to args.save_total_limit
{'eval_loss': 2.260716438293457, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.172, 'eval_steps_per_second': 5.859, 'epoch': 53.08}
 53%|████████████████████████████████████████████████████████████████████████████████▋                                                                       | 637/1200 [31:27<28:04,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|████████████████████████████████████████████████████████████████████████████████▋                                                                       | 637/1200 [31:28<28:04,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-637
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-637/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-637/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-637/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-637/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-636] due to args.save_total_limit
 53%|████████████████████████████████████████████████████████████████████████████████▊                                                                       | 638/1200 [31:30<27:45,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|████████████████████████████████████████████████████████████████████████████████▊                                                                       | 638/1200 [31:31<27:45,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-638
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-638/config.json
{'eval_loss': 2.300248861312866, 'eval_f1': 0.5062717770034844, 'eval_runtime': 0.5134, 'eval_samples_per_second': 116.872, 'eval_steps_per_second': 5.844, 'epoch': 53.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-638/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-638/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-638/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-637] due to args.save_total_limit
{'eval_loss': 2.337970495223999, 'eval_f1': 0.5028132992327365, 'eval_runtime': 0.5148, 'eval_samples_per_second': 116.546, 'eval_steps_per_second': 5.827, 'epoch': 53.25}
 53%|████████████████████████████████████████████████████████████████████████████████▉                                                                       | 639/1200 [31:33<27:27,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|████████████████████████████████████████████████████████████████████████████████▉                                                                       | 639/1200 [31:34<27:27,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-639
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-639/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-639/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-639/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-639/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-638] due to args.save_total_limit
 53%|█████████████████████████████████████████████████████████████████████████████████                                                                       | 640/1200 [31:36<27:16,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 53%|█████████████████████████████████████████████████████████████████████████████████                                                                       | 640/1200 [31:37<27:16,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-640
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-640/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-640/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-640/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-640/special_tokens_map.json
{'eval_loss': 2.3593204021453857, 'eval_f1': 0.5, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.42, 'eval_steps_per_second': 5.871, 'epoch': 53.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-639] due to args.save_total_limit
 53%|█████████████████████████████████████████████████████████████████████████████████▏                                                                      | 641/1200 [31:39<27:21,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-641/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-641/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-641/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-641/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-640] due to args.save_total_limit
 54%|█████████████████████████████████████████████████████████████████████████████████▎                                                                      | 642/1200 [31:42<28:14,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 54%|█████████████████████████████████████████████████████████████████████████████████▎                                                                      | 642/1200 [31:43<28:14,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-642
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-642/config.json
{'eval_loss': 2.3626902103424072, 'eval_f1': 0.5146432932147217, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.831, 'eval_steps_per_second': 5.892, 'epoch': 53.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-642/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-642/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-642/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-641] due to args.save_total_limit
{'eval_loss': 2.335911989212036, 'eval_f1': 0.5, 'eval_runtime': 0.5164, 'eval_samples_per_second': 116.185, 'eval_steps_per_second': 5.809, 'epoch': 53.58}
 54%|█████████████████████████████████████████████████████████████████████████████████▍                                                                      | 643/1200 [31:45<27:56,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 54%|█████████████████████████████████████████████████████████████████████████████████▍                                                                      | 643/1200 [31:46<27:56,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-643
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-643/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-643/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-643/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-643/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-642] due to args.save_total_limit
 54%|█████████████████████████████████████████████████████████████████████████████████▌                                                                      | 644/1200 [31:48<27:49,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 54%|█████████████████████████████████████████████████████████████████████████████████▌                                                                      | 644/1200 [31:49<27:49,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-644
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-644/config.json
{'eval_loss': 2.259726047515869, 'eval_f1': 0.5, 'eval_runtime': 0.5144, 'eval_samples_per_second': 116.639, 'eval_steps_per_second': 5.832, 'epoch': 53.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-644/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-644/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-644/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-643] due to args.save_total_limit
 54%|█████████████████████████████████████████████████████████████████████████████████▋                                                                      | 645/1200 [31:51<27:35,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.2297685146331787, 'eval_f1': 0.48274231678487, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.441, 'eval_steps_per_second': 5.872, 'epoch': 53.75}
 54%|█████████████████████████████████████████████████████████████████████████████████▋                                                                      | 645/1200 [31:52<27:35,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-645
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-645/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-645/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-645/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-645/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-644] due to args.save_total_limit
 54%|█████████████████████████████████████████████████████████████████████████████████▊                                                                      | 646/1200 [31:54<27:44,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 54%|█████████████████████████████████████████████████████████████████████████████████▊                                                                      | 646/1200 [31:55<27:44,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-646
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-646/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-646/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-646/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-646/special_tokens_map.json
{'eval_loss': 2.2420499324798584, 'eval_f1': 0.5, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.564, 'eval_steps_per_second': 5.878, 'epoch': 53.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-645] due to args.save_total_limit
 54%|█████████████████████████████████████████████████████████████████████████████████▉                                                                      | 647/1200 [31:57<27:19,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-647/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-647/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-647/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-647/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-646] due to args.save_total_limit
 54%|██████████████████████████████████████████████████████████████████████████████████                                                                      | 648/1200 [32:00<27:21,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 54%|██████████████████████████████████████████████████████████████████████████████████                                                                      | 648/1200 [32:01<27:21,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-648
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-648/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-648/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-648/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-648/special_tokens_map.json
{'eval_loss': 2.2888381481170654, 'eval_f1': 0.5, 'eval_runtime': 0.5125, 'eval_samples_per_second': 117.068, 'eval_steps_per_second': 5.853, 'epoch': 54.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-647] due to args.save_total_limit
 54%|██████████████████████████████████████████████████████████████████████████████████▏                                                                     | 649/1200 [32:03<27:20,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 54%|██████████████████████████████████████████████████████████████████████████████████▏                                                                     | 649/1200 [32:04<27:20,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-649
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-649/config.json
{'eval_loss': 2.3073766231536865, 'eval_f1': 0.5006486766995331, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.796, 'eval_steps_per_second': 5.89, 'epoch': 54.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-649/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-649/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-649/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-648] due to args.save_total_limit
 54%|██████████████████████████████████████████████████████████████████████████████████▎                                                                     | 650/1200 [32:06<27:07,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 54%|██████████████████████████████████████████████████████████████████████████████████▎                                                                     | 650/1200 [32:07<27:07,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-650
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-650/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-650/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-650/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-650/special_tokens_map.json
{'eval_loss': 2.3086929321289062, 'eval_f1': 0.5006486766995331, 'eval_runtime': 0.5148, 'eval_samples_per_second': 116.558, 'eval_steps_per_second': 5.828, 'epoch': 54.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-649] due to args.save_total_limit
 54%|██████████████████████████████████████████████████████████████████████████████████▍                                                                     | 651/1200 [32:09<26:57,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.54it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-651/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-651/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-651/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-651/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-650] due to args.save_total_limit
{'eval_loss': 2.337496519088745, 'eval_f1': 0.5006486766995331, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.822, 'eval_steps_per_second': 5.891, 'epoch': 54.33}
 54%|██████████████████████████████████████████████████████████████████████████████████▌                                                                     | 652/1200 [32:12<26:49,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 54%|██████████████████████████████████████████████████████████████████████████████████▌                                                                     | 652/1200 [32:12<26:49,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-652
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-652/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-652/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-652/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-652/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-651] due to args.save_total_limit
 54%|██████████████████████████████████████████████████████████████████████████████████▋                                                                     | 653/1200 [32:15<26:42,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 54%|██████████████████████████████████████████████████████████████████████████████████▋                                                                     | 653/1200 [32:15<26:42,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-653
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-653/config.json
{'eval_loss': 2.3663384914398193, 'eval_f1': 0.5006486766995331, 'eval_runtime': 0.512, 'eval_samples_per_second': 117.178, 'eval_steps_per_second': 5.859, 'epoch': 54.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-653/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-653/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-653/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-652] due to args.save_total_limit
 55%|██████████████████████████████████████████████████████████████████████████████████▊                                                                     | 654/1200 [32:18<26:43,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 55%|██████████████████████████████████████████████████████████████████████████████████▊                                                                     | 654/1200 [32:18<26:43,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-654
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-654/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-654/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-654/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-654/special_tokens_map.json
{'eval_loss': 2.4032938480377197, 'eval_f1': 0.5006486766995331, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.581, 'eval_steps_per_second': 5.879, 'epoch': 54.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-653] due to args.save_total_limit
 55%|██████████████████████████████████████████████████████████████████████████████████▉                                                                     | 655/1200 [32:21<26:34,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 55%|██████████████████████████████████████████████████████████████████████████████████▉                                                                     | 655/1200 [32:21<26:34,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-655
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-655/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-655/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-655/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-655/special_tokens_map.json
{'eval_loss': 2.431262731552124, 'eval_f1': 0.5006486766995331, 'eval_runtime': 0.5137, 'eval_samples_per_second': 116.81, 'eval_steps_per_second': 5.841, 'epoch': 54.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-654] due to args.save_total_limit
 55%|███████████████████████████████████████████████████████████████████████████████████                                                                     | 656/1200 [32:24<26:44,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-656/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-656/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-656/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-656/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-655] due to args.save_total_limit
 55%|███████████████████████████████████████████████████████████████████████████████████▏                                                                    | 657/1200 [32:27<26:46,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 55%|███████████████████████████████████████████████████████████████████████████████████▏                                                                    | 657/1200 [32:27<26:46,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-657
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-657/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-657/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-657/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-657/special_tokens_map.json
{'eval_loss': 2.4313392639160156, 'eval_f1': 0.48567977915804, 'eval_runtime': 0.5181, 'eval_samples_per_second': 115.805, 'eval_steps_per_second': 5.79, 'epoch': 54.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-656] due to args.save_total_limit
 55%|███████████████████████████████████████████████████████████████████████████████████▎                                                                    | 658/1200 [32:30<27:45,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.4217402935028076, 'eval_f1': 0.47032730404823425, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.718, 'eval_steps_per_second': 5.886, 'epoch': 54.83}
 55%|███████████████████████████████████████████████████████████████████████████████████▎                                                                    | 658/1200 [32:30<27:45,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-658
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-658/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-658/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-658/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-658/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-657] due to args.save_total_limit
 55%|███████████████████████████████████████████████████████████████████████████████████▍                                                                    | 659/1200 [32:33<27:12,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 55%|███████████████████████████████████████████████████████████████████████████████████▍                                                                    | 659/1200 [32:33<27:12,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-659
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-659/config.json
{'eval_loss': 2.4089951515197754, 'eval_f1': 0.45180878552971576, 'eval_runtime': 0.5117, 'eval_samples_per_second': 117.253, 'eval_steps_per_second': 5.863, 'epoch': 54.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-659/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-659/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-659/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-658] due to args.save_total_limit
 55%|███████████████████████████████████████████████████████████████████████████████████▌                                                                    | 660/1200 [32:36<26:56,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 55%|███████████████████████████████████████████████████████████████████████████████████▌                                                                    | 660/1200 [32:36<26:56,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-660
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-660/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-660/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-660/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-660/special_tokens_map.json
{'eval_loss': 2.4011998176574707, 'eval_f1': 0.45180878552971576, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.938, 'eval_steps_per_second': 5.847, 'epoch': 55.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-659] due to args.save_total_limit
 55%|███████████████████████████████████████████████████████████████████████████████████▋                                                                    | 661/1200 [32:39<26:45,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 55%|███████████████████████████████████████████████████████████████████████████████████▋                                                                    | 661/1200 [32:39<26:45,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-661
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-661/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-661/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-661/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-661/special_tokens_map.json
{'eval_loss': 2.4015209674835205, 'eval_f1': 0.45180878552971576, 'eval_runtime': 0.5085, 'eval_samples_per_second': 118.003, 'eval_steps_per_second': 5.9, 'epoch': 55.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-660] due to args.save_total_limit
 55%|███████████████████████████████████████████████████████████████████████████████████▊                                                                    | 662/1200 [32:42<26:29,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-662/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-662/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-662/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-662/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-661] due to args.save_total_limit
 55%|███████████████████████████████████████████████████████████████████████████████████▉                                                                    | 663/1200 [32:45<26:22,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 55%|███████████████████████████████████████████████████████████████████████████████████▉                                                                    | 663/1200 [32:45<26:22,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-663
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-663/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-663/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-663/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-663/special_tokens_map.json
{'eval_loss': 2.3852076530456543, 'eval_f1': 0.4716370269037848, 'eval_runtime': 0.5174, 'eval_samples_per_second': 115.967, 'eval_steps_per_second': 5.798, 'epoch': 55.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-662] due to args.save_total_limit
 55%|████████████████████████████████████████████████████████████████████████████████████                                                                    | 664/1200 [32:47<26:18,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 55%|████████████████████████████████████████████████████████████████████████████████████                                                                    | 664/1200 [32:48<26:18,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-664
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-664/config.json
{'eval_loss': 2.3686935901641846, 'eval_f1': 0.4899963086009598, 'eval_runtime': 0.5172, 'eval_samples_per_second': 116.018, 'eval_steps_per_second': 5.801, 'epoch': 55.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-664/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-664/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-664/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-663] due to args.save_total_limit
 55%|████████████████████████████████████████████████████████████████████████████████████▏                                                                   | 665/1200 [32:50<26:15,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 55%|████████████████████████████████████████████████████████████████████████████████████▏                                                                   | 665/1200 [32:51<26:15,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-665
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-665/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-665/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-665/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-665/special_tokens_map.json
{'eval_loss': 2.3562240600585938, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.173, 'eval_steps_per_second': 5.859, 'epoch': 55.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-664] due to args.save_total_limit
 56%|████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 666/1200 [32:53<26:11,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 666/1200 [32:54<26:11,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-666
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-666/config.json
{'eval_loss': 2.3841307163238525, 'eval_f1': 0.5285978835978836, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.48, 'eval_steps_per_second': 5.874, 'epoch': 55.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-666/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-666/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-666/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-665] due to args.save_total_limit
 56%|████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 667/1200 [32:56<26:14,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 667/1200 [32:57<26:14,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-667
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-667/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-667/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-667/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-667/special_tokens_map.json
{'eval_loss': 2.4101908206939697, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5168, 'eval_samples_per_second': 116.088, 'eval_steps_per_second': 5.804, 'epoch': 55.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-666] due to args.save_total_limit
 56%|████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 668/1200 [32:59<26:05,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 668/1200 [33:00<26:05,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-668
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-668/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-668/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-668/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-668/special_tokens_map.json
{'eval_loss': 2.4495832920074463, 'eval_f1': 0.48459383753501406, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.567, 'eval_steps_per_second': 5.878, 'epoch': 55.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-667] due to args.save_total_limit
 56%|████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 669/1200 [33:02<25:59,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-669/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-669/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-669/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-669/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-668] due to args.save_total_limit
 56%|████████████████████████████████████████████████████████████████████████████████████▊                                                                   | 670/1200 [33:05<25:49,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|████████████████████████████████████████████████████████████████████████████████████▊                                                                   | 670/1200 [33:06<25:49,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-670
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-670/config.json
{'eval_loss': 2.482438564300537, 'eval_f1': 0.4716370269037848, 'eval_runtime': 0.5118, 'eval_samples_per_second': 117.226, 'eval_steps_per_second': 5.861, 'epoch': 55.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-670/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-670/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-670/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-669] due to args.save_total_limit
 56%|████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 671/1200 [33:08<26:05,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 671/1200 [33:09<26:05,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-671
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-671/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-671/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-671/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-671/special_tokens_map.json
{'eval_loss': 2.496002197265625, 'eval_f1': 0.48776844070961717, 'eval_runtime': 0.5172, 'eval_samples_per_second': 116.005, 'eval_steps_per_second': 5.8, 'epoch': 55.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-670] due to args.save_total_limit
 56%|█████████████████████████████████████████████████████████████████████████████████████                                                                   | 672/1200 [33:11<27:02,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|█████████████████████████████████████████████████████████████████████████████████████                                                                   | 672/1200 [33:12<27:02,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-672
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-672/config.json
{'eval_loss': 2.5223214626312256, 'eval_f1': 0.4983451536643026, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.691, 'eval_steps_per_second': 5.885, 'epoch': 56.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-672/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-672/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-672/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-671] due to args.save_total_limit
 56%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 673/1200 [33:14<26:51,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 673/1200 [33:15<26:51,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-673
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-673/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-673/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-673/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-673/special_tokens_map.json
{'eval_loss': 2.5508649349212646, 'eval_f1': 0.4978632478632478, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.547, 'eval_steps_per_second': 5.877, 'epoch': 56.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-672] due to args.save_total_limit
 56%|█████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 674/1200 [33:17<26:35,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|█████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 674/1200 [33:18<26:35,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-674
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-674/config.json
{'eval_loss': 2.5595626831054688, 'eval_f1': 0.5126864781000119, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.786, 'eval_steps_per_second': 5.889, 'epoch': 56.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-674/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-674/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-674/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-673] due to args.save_total_limit
 56%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 675/1200 [33:20<26:13,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 675/1200 [33:21<26:13,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-675
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-675/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-675/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-675/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-675/special_tokens_map.json
{'eval_loss': 2.612783670425415, 'eval_f1': 0.5272552552552553, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.438, 'eval_steps_per_second': 5.872, 'epoch': 56.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-674] due to args.save_total_limit
 56%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                  | 676/1200 [33:23<25:57,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                  | 676/1200 [33:24<25:57,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-676
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-676/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-676/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-676/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-676/special_tokens_map.json
{'eval_loss': 2.706587076187134, 'eval_f1': 0.5431637519872814, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.537, 'eval_steps_per_second': 5.877, 'epoch': 56.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-675] due to args.save_total_limit
 56%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 677/1200 [33:26<25:51,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.54it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-677/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-677/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-677/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-677/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-676] due to args.save_total_limit
 56%|█████████████████████████████████████████████████████████████████████████████████████▉                                                                  | 678/1200 [33:29<25:35,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 56%|█████████████████████████████████████████████████████████████████████████████████████▉                                                                  | 678/1200 [33:30<25:35,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-678
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-678/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-678/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-678/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-678/special_tokens_map.json
{'eval_loss': 2.801952838897705, 'eval_f1': 0.5418598382749326, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.378, 'eval_steps_per_second': 5.869, 'epoch': 56.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-677] due to args.save_total_limit
 57%|██████████████████████████████████████████████████████████████████████████████████████                                                                  | 679/1200 [33:32<25:33,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 57%|██████████████████████████████████████████████████████████████████████████████████████                                                                  | 679/1200 [33:33<25:33,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-679
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-679/config.json
{'eval_loss': 2.791764259338379, 'eval_f1': 0.5418598382749326, 'eval_runtime': 0.5127, 'eval_samples_per_second': 117.035, 'eval_steps_per_second': 5.852, 'epoch': 56.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-679/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-679/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-679/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-678] due to args.save_total_limit
 57%|██████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 680/1200 [33:35<26:32,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 57%|██████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 680/1200 [33:36<26:32,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-680
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-680/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-680/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-680/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-680/special_tokens_map.json
{'eval_loss': 2.8025918006896973, 'eval_f1': 0.5418598382749326, 'eval_runtime': 0.5201, 'eval_samples_per_second': 115.368, 'eval_steps_per_second': 5.768, 'epoch': 56.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-679] due to args.save_total_limit
 57%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                 | 681/1200 [33:38<26:17,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 57%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                 | 681/1200 [33:39<26:17,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-681
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-681/config.json
{'eval_loss': 2.7563209533691406, 'eval_f1': 0.5418598382749326, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.725, 'eval_steps_per_second': 5.886, 'epoch': 56.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-681/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-681/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-681/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-680] due to args.save_total_limit
 57%|██████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 682/1200 [33:41<25:52,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 57%|██████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 682/1200 [33:42<25:52,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-682
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-682/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-682/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-682/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-682/special_tokens_map.json
{'eval_loss': 2.7078254222869873, 'eval_f1': 0.5282051282051282, 'eval_runtime': 0.5176, 'eval_samples_per_second': 115.917, 'eval_steps_per_second': 5.796, 'epoch': 56.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-681] due to args.save_total_limit
 57%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                 | 683/1200 [33:44<25:48,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-683/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-683/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-683/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-683/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-682] due to args.save_total_limit
 57%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 684/1200 [33:47<25:32,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 57%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 684/1200 [33:48<25:32,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-684
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-684/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-684/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-684/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-684/special_tokens_map.json
{'eval_loss': 2.6098132133483887, 'eval_f1': 0.5290175438596492, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.621, 'eval_steps_per_second': 5.881, 'epoch': 57.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-683] due to args.save_total_limit
 57%|██████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 685/1200 [33:50<25:26,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 57%|██████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 685/1200 [33:51<25:26,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-685
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-685/config.json
{'eval_loss': 2.6168909072875977, 'eval_f1': 0.5290175438596492, 'eval_runtime': 0.517, 'eval_samples_per_second': 116.058, 'eval_steps_per_second': 5.803, 'epoch': 57.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-685/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-685/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-685/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-684] due to args.save_total_limit
 57%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                 | 686/1200 [33:53<25:12,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 57%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                 | 686/1200 [33:54<25:12,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-686
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-686/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-686/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-686/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-686/special_tokens_map.json
{'eval_loss': 2.598464012145996, 'eval_f1': 0.5290175438596492, 'eval_runtime': 0.5158, 'eval_samples_per_second': 116.313, 'eval_steps_per_second': 5.816, 'epoch': 57.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-685] due to args.save_total_limit
 57%|███████████████████████████████████████████████████████████████████████████████████████                                                                 | 687/1200 [33:56<24:58,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 57%|███████████████████████████████████████████████████████████████████████████████████████                                                                 | 687/1200 [33:56<24:58,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-687
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-687/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-687/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-687/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-687/special_tokens_map.json
{'eval_loss': 2.5907247066497803, 'eval_f1': 0.5152777777777778, 'eval_runtime': 0.5152, 'eval_samples_per_second': 116.46, 'eval_steps_per_second': 5.823, 'epoch': 57.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-686] due to args.save_total_limit
 57%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                | 688/1200 [33:59<25:04,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-688/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-688/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-688/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-688/special_tokens_map.json
{'eval_loss': 2.565995454788208, 'eval_f1': 0.4960981912144703, 'eval_runtime': 0.5145, 'eval_samples_per_second': 116.609, 'eval_steps_per_second': 5.83, 'epoch': 57.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-687] due to args.save_total_limit
 57%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                | 689/1200 [34:02<24:57,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 57%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                | 689/1200 [34:02<24:57,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-689
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-689/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-689/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-689/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-689/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-688] due to args.save_total_limit
 57%|███████████████████████████████████████████████████████████████████████████████████████▍                                                                | 690/1200 [34:05<25:00,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.47it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-690/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-690/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-690/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-690/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-689] due to args.save_total_limit
{'eval_loss': 2.5470354557037354, 'eval_f1': 0.45999764345469546, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.64, 'eval_steps_per_second': 5.882, 'epoch': 57.58}
 58%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                | 691/1200 [34:08<25:04,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                | 691/1200 [34:08<25:04,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-691
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-691/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-691/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-691/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-691/special_tokens_map.json
{'eval_loss': 2.5463712215423584, 'eval_f1': 0.45999764345469546, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.474, 'eval_steps_per_second': 5.874, 'epoch': 57.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-690] due to args.save_total_limit
 58%|███████████████████████████████████████████████████████████████████████████████████████▋                                                                | 692/1200 [34:11<24:56,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|███████████████████████████████████████████████████████████████████████████████████████▋                                                                | 692/1200 [34:11<24:56,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-692
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-692/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-692/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-692/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-692/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-691] due to args.save_total_limit
{'eval_loss': 2.5483155250549316, 'eval_f1': 0.45999764345469546, 'eval_runtime': 0.5137, 'eval_samples_per_second': 116.798, 'eval_steps_per_second': 5.84, 'epoch': 57.75}
 58%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                | 693/1200 [34:14<24:46,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                | 693/1200 [34:14<24:46,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-693
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-693/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-693/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-693/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-693/special_tokens_map.json
{'eval_loss': 2.5455448627471924, 'eval_f1': 0.4799147485080989, 'eval_runtime': 0.5129, 'eval_samples_per_second': 116.984, 'eval_steps_per_second': 5.849, 'epoch': 57.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-692] due to args.save_total_limit
 58%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                | 694/1200 [34:16<24:39,  2.92s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                | 694/1200 [34:17<24:39,  2.92s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-694
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-694/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-694/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-694/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-694/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-693] due to args.save_total_limit
{'eval_loss': 2.5179665088653564, 'eval_f1': 0.45999764345469546, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.555, 'eval_steps_per_second': 5.878, 'epoch': 57.92}
 58%|████████████████████████████████████████████████████████████████████████████████████████                                                                | 695/1200 [34:20<25:38,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|████████████████████████████████████████████████████████████████████████████████████████                                                                | 695/1200 [34:20<25:38,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-695
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-695/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-695/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-695/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-695/special_tokens_map.json
{'eval_loss': 2.4879050254821777, 'eval_f1': 0.45999764345469546, 'eval_runtime': 0.5172, 'eval_samples_per_second': 116.0, 'eval_steps_per_second': 5.8, 'epoch': 58.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-694] due to args.save_total_limit
 58%|████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 696/1200 [34:23<25:13,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 696/1200 [34:23<25:13,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-696
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-696/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-696/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-696/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-696/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-695] due to args.save_total_limit
{'eval_loss': 2.4970195293426514, 'eval_f1': 0.45999764345469546, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.571, 'eval_steps_per_second': 5.879, 'epoch': 58.08}
 58%|████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 697/1200 [34:26<25:11,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 697/1200 [34:26<25:11,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-697
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-697/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-697/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-697/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-697/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-696] due to args.save_total_limit
 58%|████████████████████████████████████████████████████████████████████████████████████████▍                                                               | 698/1200 [34:29<24:59,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|████████████████████████████████████████████████████████████████████████████████████████▍                                                               | 698/1200 [34:29<24:59,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-698
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-698/config.json
{'eval_loss': 2.49942946434021, 'eval_f1': 0.4960981912144703, 'eval_runtime': 0.5177, 'eval_samples_per_second': 115.903, 'eval_steps_per_second': 5.795, 'epoch': 58.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-698/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-698/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-698/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-697] due to args.save_total_limit
{'eval_loss': 2.5250303745269775, 'eval_f1': 0.48333333333333334, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.632, 'eval_steps_per_second': 5.882, 'epoch': 58.25}
 58%|████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 699/1200 [34:32<25:46,  3.09s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 699/1200 [34:33<25:46,  3.09s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-699
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-699/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-699/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-699/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-699/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-698] due to args.save_total_limit
 58%|████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 700/1200 [34:35<25:27,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-700/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-700/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-700/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-700/special_tokens_map.json
{'eval_loss': 2.5596401691436768, 'eval_f1': 0.5317667309431208, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.525, 'eval_steps_per_second': 5.876, 'epoch': 58.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-699] due to args.save_total_limit
 58%|████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 701/1200 [34:38<25:03,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 58%|████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 701/1200 [34:38<25:03,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-701
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-701/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-701/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-701/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-701/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-700] due to args.save_total_limit
 58%|████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 702/1200 [34:41<25:14,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.20it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-702/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-702/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-702/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-702/special_tokens_map.json
{'eval_loss': 2.476311206817627, 'eval_f1': 0.534393778720396, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.42, 'eval_steps_per_second': 5.871, 'epoch': 58.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-701] due to args.save_total_limit
 59%|█████████████████████████████████████████████████████████████████████████████████████████                                                               | 703/1200 [34:44<24:50,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 59%|█████████████████████████████████████████████████████████████████████████████████████████                                                               | 703/1200 [34:44<24:50,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-703
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-703/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-703/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-703/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-703/special_tokens_map.json
{'eval_loss': 2.429617404937744, 'eval_f1': 0.534393778720396, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.653, 'eval_steps_per_second': 5.883, 'epoch': 58.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-702] due to args.save_total_limit
 59%|█████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 704/1200 [34:47<24:34,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 59%|█████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 704/1200 [34:47<24:34,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-704
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-704/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-704/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-704/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-704/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-703] due to args.save_total_limit
{'eval_loss': 2.3710336685180664, 'eval_f1': 0.534393778720396, 'eval_runtime': 0.5159, 'eval_samples_per_second': 116.312, 'eval_steps_per_second': 5.816, 'epoch': 58.75}
 59%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                              | 705/1200 [34:50<24:37,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 59%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                              | 705/1200 [34:50<24:37,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-705
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-705/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-705/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-705/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-705/special_tokens_map.json
{'eval_loss': 2.3268003463745117, 'eval_f1': 0.5004668534080299, 'eval_runtime': 0.5119, 'eval_samples_per_second': 117.205, 'eval_steps_per_second': 5.86, 'epoch': 58.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-704] due to args.save_total_limit
 59%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 706/1200 [34:53<24:24,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 59%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 706/1200 [34:53<24:24,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-706
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-706/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-706/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-706/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-706/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-705] due to args.save_total_limit
{'eval_loss': 2.2969040870666504, 'eval_f1': 0.4840401276789785, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.635, 'eval_steps_per_second': 5.882, 'epoch': 58.92}
 59%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 707/1200 [34:56<24:13,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 59%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 707/1200 [34:56<24:13,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-707
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-707/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-707/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-707/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-707/special_tokens_map.json
{'eval_loss': 2.2732834815979004, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.716, 'eval_steps_per_second': 5.886, 'epoch': 59.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-706] due to args.save_total_limit
 59%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                              | 708/1200 [34:59<24:15,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 59%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                              | 708/1200 [34:59<24:15,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-708
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-708/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-708/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-708/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-708/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-707] due to args.save_total_limit
 59%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 709/1200 [35:02<24:04,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.257378578186035, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.544, 'eval_steps_per_second': 5.877, 'epoch': 59.08}
 59%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 709/1200 [35:02<24:04,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-709
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-709/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-709/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-709/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-709/special_tokens_map.json
{'eval_loss': 2.220001220703125, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.776, 'eval_steps_per_second': 5.889, 'epoch': 59.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-708] due to args.save_total_limit
 59%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                              | 710/1200 [35:04<24:03,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 59%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                              | 710/1200 [35:05<24:03,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-710
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-710/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-710/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-710/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-710/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-709] due to args.save_total_limit
 59%|██████████████████████████████████████████████████████████████████████████████████████████                                                              | 711/1200 [35:07<24:09,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-711/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-711/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-711/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-711/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-710] due to args.save_total_limit
 59%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 712/1200 [35:10<24:08,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 59%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 712/1200 [35:11<24:08,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-712
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-712/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-712/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-712/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-712/special_tokens_map.json
{'eval_loss': 2.13975191116333, 'eval_f1': 0.5550471401634192, 'eval_runtime': 0.5119, 'eval_samples_per_second': 117.204, 'eval_steps_per_second': 5.86, 'epoch': 59.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-711] due to args.save_total_limit
 59%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 713/1200 [35:13<23:55,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 59%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 713/1200 [35:14<23:55,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-713
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-713/config.json
{'eval_loss': 2.116454839706421, 'eval_f1': 0.5715985215985216, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.703, 'eval_steps_per_second': 5.885, 'epoch': 59.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-713/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-713/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-713/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-712] due to args.save_total_limit
{'eval_loss': 2.102689266204834, 'eval_f1': 0.5885964912280702, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.535, 'eval_steps_per_second': 5.877, 'epoch': 59.5}
 60%|██████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 714/1200 [35:16<23:50,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|██████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 714/1200 [35:17<23:50,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-714
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-714/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-714/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-714/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-714/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-713] due to args.save_total_limit
 60%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                             | 715/1200 [35:19<23:52,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.53it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-715/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-715/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-715/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-715/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-714] due to args.save_total_limit
{'eval_loss': 2.0956904888153076, 'eval_f1': 0.6198412698412699, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.715, 'eval_steps_per_second': 5.886, 'epoch': 59.67}
 60%|██████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 716/1200 [35:22<23:45,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|██████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 716/1200 [35:23<23:45,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-716
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-716/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-716/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-716/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-716/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-715] due to args.save_total_limit
 60%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 717/1200 [35:26<24:32,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-717/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-717/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-717/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-717/special_tokens_map.json
{'eval_loss': 2.1397950649261475, 'eval_f1': 0.6049913070965703, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.554, 'eval_steps_per_second': 5.878, 'epoch': 59.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-716] due to args.save_total_limit
 60%|██████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 718/1200 [35:28<24:02,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|██████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 718/1200 [35:29<24:02,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-718
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-718/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-718/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-718/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-718/special_tokens_map.json
{'eval_loss': 2.1635351181030273, 'eval_f1': 0.5877793583056741, 'eval_runtime': 0.5162, 'eval_samples_per_second': 116.228, 'eval_steps_per_second': 5.811, 'epoch': 59.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-717] due to args.save_total_limit
 60%|███████████████████████████████████████████████████████████████████████████████████████████                                                             | 719/1200 [35:31<23:49,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|███████████████████████████████████████████████████████████████████████████████████████████                                                             | 719/1200 [35:32<23:49,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-719
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-719/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-719/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-719/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-719/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-718] due to args.save_total_limit
{'eval_loss': 2.1758337020874023, 'eval_f1': 0.5877793583056741, 'eval_runtime': 0.513, 'eval_samples_per_second': 116.948, 'eval_steps_per_second': 5.847, 'epoch': 60.0}
 60%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 720/1200 [35:34<23:34,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 720/1200 [35:35<23:34,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-720
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-720/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-720/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-720/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-720/special_tokens_map.json
{'eval_loss': 2.185558319091797, 'eval_f1': 0.5877793583056741, 'eval_runtime': 0.5183, 'eval_samples_per_second': 115.762, 'eval_steps_per_second': 5.788, 'epoch': 60.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-719] due to args.save_total_limit
 60%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 721/1200 [35:37<23:30,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 721/1200 [35:38<23:30,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-721
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-721/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-721/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-721/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-721/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-720] due to args.save_total_limit
{'eval_loss': 2.220534086227417, 'eval_f1': 0.5877793583056741, 'eval_runtime': 0.5153, 'eval_samples_per_second': 116.432, 'eval_steps_per_second': 5.822, 'epoch': 60.17}
 60%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                            | 722/1200 [35:40<23:30,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                            | 722/1200 [35:41<23:30,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-722
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-722/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-722/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-722/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-722/special_tokens_map.json
{'eval_loss': 2.243980884552002, 'eval_f1': 0.5517460317460317, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.598, 'eval_steps_per_second': 5.88, 'epoch': 60.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-721] due to args.save_total_limit
 60%|███████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 723/1200 [35:43<23:25,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|███████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 723/1200 [35:44<23:25,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-723
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-723/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-723/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-723/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-723/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-722] due to args.save_total_limit
{'eval_loss': 2.3067688941955566, 'eval_f1': 0.5320886615515772, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.71, 'eval_steps_per_second': 5.885, 'epoch': 60.33}
 60%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 724/1200 [35:46<23:23,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 724/1200 [35:46<23:23,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-724
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-724/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-724/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-724/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-724/special_tokens_map.json
{'eval_loss': 2.3779473304748535, 'eval_f1': 0.5320886615515772, 'eval_runtime': 0.5132, 'eval_samples_per_second': 116.903, 'eval_steps_per_second': 5.845, 'epoch': 60.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-723] due to args.save_total_limit
 60%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                            | 725/1200 [35:49<23:15,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 60%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                            | 725/1200 [35:49<23:15,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-725
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-725/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-725/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-725/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-725/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-724] due to args.save_total_limit
 60%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 726/1200 [35:52<23:21,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-726/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-726/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-726/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-726/special_tokens_map.json
{'eval_loss': 2.478905200958252, 'eval_f1': 0.5164663372123918, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.567, 'eval_steps_per_second': 5.878, 'epoch': 60.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-725] due to args.save_total_limit
 61%|████████████████████████████████████████████████████████████████████████████████████████████                                                            | 727/1200 [35:55<24:25,  3.10s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 61%|████████████████████████████████████████████████████████████████████████████████████████████                                                            | 727/1200 [35:56<24:25,  3.10s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-727
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-727/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-727/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-727/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-727/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-726] due to args.save_total_limit
{'eval_loss': 2.5123136043548584, 'eval_f1': 0.5004668534080299, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.799, 'eval_steps_per_second': 5.89, 'epoch': 60.67}
 61%|████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 728/1200 [35:58<24:09,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 61%|████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 728/1200 [35:59<24:09,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-728
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-728/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-728/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-728/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-728/special_tokens_map.json
{'eval_loss': 2.5484557151794434, 'eval_f1': 0.48459383753501406, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.673, 'eval_steps_per_second': 5.884, 'epoch': 60.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-727] due to args.save_total_limit
 61%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 729/1200 [36:01<23:48,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 61%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 729/1200 [36:02<23:48,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-729
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-729/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-729/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-729/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-729/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-728] due to args.save_total_limit
 61%|████████████████████████████████████████████████████████████████████████████████████████████▍                                                           | 730/1200 [36:04<23:31,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-730/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-730/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-730/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-730/special_tokens_map.json
{'eval_loss': 2.6156585216522217, 'eval_f1': 0.48459383753501406, 'eval_runtime': 0.5118, 'eval_samples_per_second': 117.236, 'eval_steps_per_second': 5.862, 'epoch': 60.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-729] due to args.save_total_limit
 61%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 731/1200 [36:07<23:18,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 61%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 731/1200 [36:08<23:18,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-731
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-731/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-731/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-731/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-731/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-730] due to args.save_total_limit
 61%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                           | 732/1200 [36:10<23:02,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 61%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                           | 732/1200 [36:11<23:02,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-732
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-732/config.json
{'eval_loss': 2.642737627029419, 'eval_f1': 0.4652910052910053, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.62, 'eval_steps_per_second': 5.881, 'epoch': 61.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-732/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-732/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-732/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-731] due to args.save_total_limit
{'eval_loss': 2.6844680309295654, 'eval_f1': 0.4484034405561447, 'eval_runtime': 0.5151, 'eval_samples_per_second': 116.48, 'eval_steps_per_second': 5.824, 'epoch': 61.08}
 61%|████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 733/1200 [36:13<22:51,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 61%|████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 733/1200 [36:13<22:51,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-733
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-733/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-733/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-733/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-733/special_tokens_map.json
{'eval_loss': 2.7224199771881104, 'eval_f1': 0.4680124223602485, 'eval_runtime': 0.5142, 'eval_samples_per_second': 116.689, 'eval_steps_per_second': 5.834, 'epoch': 61.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-732] due to args.save_total_limit
 61%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                           | 734/1200 [36:16<22:48,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 61%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                           | 734/1200 [36:16<22:48,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-734
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-734/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-734/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-734/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-734/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-733] due to args.save_total_limit
 61%|█████████████████████████████████████████████████████████████████████████████████████████████                                                           | 735/1200 [36:19<22:47,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.770749092102051, 'eval_f1': 0.4680124223602485, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.743, 'eval_steps_per_second': 5.887, 'epoch': 61.25}
 61%|█████████████████████████████████████████████████████████████████████████████████████████████                                                           | 735/1200 [36:19<22:47,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-735
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-735/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-735/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-735/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-735/special_tokens_map.json
{'eval_loss': 2.817424774169922, 'eval_f1': 0.4680124223602485, 'eval_runtime': 0.5132, 'eval_samples_per_second': 116.91, 'eval_steps_per_second': 5.846, 'epoch': 61.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-734] due to args.save_total_limit
 61%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 736/1200 [36:22<22:40,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 61%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 736/1200 [36:22<22:40,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-736
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-736/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-736/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-736/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-736/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-735] due to args.save_total_limit
{'eval_loss': 2.8615241050720215, 'eval_f1': 0.48424633936261846, 'eval_runtime': 0.5114, 'eval_samples_per_second': 117.325, 'eval_steps_per_second': 5.866, 'epoch': 61.42}
 61%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                          | 737/1200 [36:25<23:37,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 61%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                          | 737/1200 [36:26<23:37,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-737
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-737/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-737/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-737/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-737/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-736] due to args.save_total_limit
 62%|█████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 738/1200 [36:28<23:26,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 62%|█████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 738/1200 [36:29<23:26,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-738
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-738/config.json
{'eval_loss': 2.858119249343872, 'eval_f1': 0.49902670111972436, 'eval_runtime': 0.509, 'eval_samples_per_second': 117.881, 'eval_steps_per_second': 5.894, 'epoch': 61.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-738/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-738/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-738/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-737] due to args.save_total_limit
 62%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                          | 739/1200 [36:31<23:04,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.8551180362701416, 'eval_f1': 0.49902670111972436, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.826, 'eval_steps_per_second': 5.841, 'epoch': 61.58}
 62%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                          | 739/1200 [36:32<23:04,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-739
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-739/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-739/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-739/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-739/special_tokens_map.json
{'eval_loss': 2.82747483253479, 'eval_f1': 0.5143202208419599, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.511, 'eval_steps_per_second': 5.876, 'epoch': 61.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-738] due to args.save_total_limit
 62%|█████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 740/1200 [36:34<22:46,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 62%|█████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 740/1200 [36:34<22:46,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-740
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-740/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-740/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-740/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-740/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-739] due to args.save_total_limit
 62%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 741/1200 [36:37<22:41,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-741/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-741/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-741/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-741/special_tokens_map.json
{'eval_loss': 2.770066976547241, 'eval_f1': 0.5292596436602665, 'eval_runtime': 0.5154, 'eval_samples_per_second': 116.413, 'eval_steps_per_second': 5.821, 'epoch': 61.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-740] due to args.save_total_limit
 62%|█████████████████████████████████████████████████████████████████████████████████████████████▉                                                          | 742/1200 [36:40<22:29,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 62%|█████████████████████████████████████████████████████████████████████████████████████████████▉                                                          | 742/1200 [36:40<22:29,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-742
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-742/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-742/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-742/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-742/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-741] due to args.save_total_limit
 62%|██████████████████████████████████████████████████████████████████████████████████████████████                                                          | 743/1200 [36:43<22:29,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-743/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-743/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-743/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-743/special_tokens_map.json
{'eval_loss': 2.6666061878204346, 'eval_f1': 0.5320886615515772, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.943, 'eval_steps_per_second': 5.847, 'epoch': 62.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-742] due to args.save_total_limit
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                         | 744/1200 [36:46<22:19,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                         | 744/1200 [36:46<22:19,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-744
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-744/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-744/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-744/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-744/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-743] due to args.save_total_limit
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 745/1200 [36:49<22:30,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-745/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-745/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-745/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-745/special_tokens_map.json
{'eval_loss': 2.4869651794433594, 'eval_f1': 0.5320886615515772, 'eval_runtime': 0.5168, 'eval_samples_per_second': 116.093, 'eval_steps_per_second': 5.805, 'epoch': 62.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-744] due to args.save_total_limit
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 746/1200 [36:52<22:24,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 746/1200 [36:52<22:24,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-746
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-746/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-746/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-746/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-746/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-745] due to args.save_total_limit
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                                         | 747/1200 [36:55<22:17,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                                         | 747/1200 [36:55<22:17,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-747
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-747/config.json
{'eval_loss': 2.424886465072632, 'eval_f1': 0.5496866096866098, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.787, 'eval_steps_per_second': 5.889, 'epoch': 62.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-747/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-747/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-747/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-746] due to args.save_total_limit
{'eval_loss': 2.4033987522125244, 'eval_f1': 0.5679595384858541, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.397, 'eval_steps_per_second': 5.87, 'epoch': 62.33}
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 748/1200 [36:57<22:10,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 748/1200 [36:58<22:10,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-748
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-748/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-748/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-748/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-748/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-747] due to args.save_total_limit
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                         | 749/1200 [37:00<22:09,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 62%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                         | 749/1200 [37:01<22:09,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-749
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-749/config.json
{'eval_loss': 2.3762075901031494, 'eval_f1': 0.5856930614825352, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.811, 'eval_steps_per_second': 5.891, 'epoch': 62.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-749/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-749/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-749/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-748] due to args.save_total_limit
{'eval_loss': 2.3665449619293213, 'eval_f1': 0.6029629629629629, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.94, 'eval_steps_per_second': 5.847, 'epoch': 62.5}
 62%|███████████████████████████████████████████████████████████████████████████████████████████████                                                         | 750/1200 [37:03<22:03,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 62%|███████████████████████████████████████████████████████████████████████████████████████████████                                                         | 750/1200 [37:04<22:03,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-750
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-750/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-750/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-750/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-750/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-749] due to args.save_total_limit
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 751/1200 [37:06<22:03,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 751/1200 [37:07<22:03,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-751
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-751/config.json
{'eval_loss': 2.3652408123016357, 'eval_f1': 0.6198412698412699, 'eval_runtime': 0.5129, 'eval_samples_per_second': 116.973, 'eval_steps_per_second': 5.849, 'epoch': 62.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-751/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-751/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-751/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-750] due to args.save_total_limit
{'eval_loss': 2.3703346252441406, 'eval_f1': 0.6198412698412699, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.508, 'eval_steps_per_second': 5.875, 'epoch': 62.67}
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 752/1200 [37:09<22:02,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 752/1200 [37:10<22:02,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-752
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-752/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-752/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-752/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-752/special_tokens_map.json
{'eval_loss': 2.376962900161743, 'eval_f1': 0.6198412698412699, 'eval_runtime': 0.5173, 'eval_samples_per_second': 115.987, 'eval_steps_per_second': 5.799, 'epoch': 62.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-751] due to args.save_total_limit
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▍                                                        | 753/1200 [37:12<21:55,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▍                                                        | 753/1200 [37:13<21:55,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-753
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-753/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-753/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-753/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-753/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-752] due to args.save_total_limit
{'eval_loss': 2.390947103500366, 'eval_f1': 0.6198412698412699, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.764, 'eval_steps_per_second': 5.888, 'epoch': 62.83}
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 754/1200 [37:15<22:38,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 754/1200 [37:16<22:38,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-754
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-754/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-754/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-754/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-754/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-753] due to args.save_total_limit
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 755/1200 [37:18<22:20,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 755/1200 [37:19<22:20,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-755
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-755/config.json
{'eval_loss': 2.394148111343384, 'eval_f1': 0.6198412698412699, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.644, 'eval_steps_per_second': 5.882, 'epoch': 62.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-755/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-755/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-755/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-754] due to args.save_total_limit
{'eval_loss': 2.412902355194092, 'eval_f1': 0.5679595384858541, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.52, 'eval_steps_per_second': 5.876, 'epoch': 63.0}
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 756/1200 [37:21<22:05,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 756/1200 [37:22<22:05,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-756
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-756/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-756/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-756/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-756/special_tokens_map.json
{'eval_loss': 2.448944568634033, 'eval_f1': 0.5496866096866098, 'eval_runtime': 0.5194, 'eval_samples_per_second': 115.525, 'eval_steps_per_second': 5.776, 'epoch': 63.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-755] due to args.save_total_limit
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 757/1200 [37:24<21:55,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 63%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 757/1200 [37:25<21:55,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-757
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-757/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-757/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-757/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-757/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-756] due to args.save_total_limit
 63%|████████████████████████████████████████████████████████████████████████████████████████████████                                                        | 758/1200 [37:27<21:51,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.5156593322753906, 'eval_f1': 0.5671975367627541, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.901, 'eval_steps_per_second': 5.845, 'epoch': 63.17}
 63%|████████████████████████████████████████████████████████████████████████████████████████████████                                                        | 758/1200 [37:28<21:51,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-758
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-758/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-758/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-758/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-758/special_tokens_map.json
{'eval_loss': 2.5816471576690674, 'eval_f1': 0.5473818769187981, 'eval_runtime': 0.518, 'eval_samples_per_second': 115.83, 'eval_steps_per_second': 5.791, 'epoch': 63.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-757] due to args.save_total_limit
 63%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 759/1200 [37:30<21:38,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 63%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 759/1200 [37:31<21:38,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-759
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-759/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-759/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-759/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-759/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-758] due to args.save_total_limit
 63%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 760/1200 [37:33<21:47,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.49it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-760/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-760/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-760/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-760/special_tokens_map.json
{'eval_loss': 2.7007932662963867, 'eval_f1': 0.5521763103269332, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.574, 'eval_steps_per_second': 5.879, 'epoch': 63.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-759] due to args.save_total_limit
 63%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 761/1200 [37:36<21:49,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 63%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 761/1200 [37:37<21:49,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-761
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-761/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-761/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-761/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-761/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-760] due to args.save_total_limit
 64%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 762/1200 [37:39<21:40,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 762/1200 [37:40<21:40,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-762
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-762/config.json
{'eval_loss': 2.754871368408203, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5118, 'eval_samples_per_second': 117.227, 'eval_steps_per_second': 5.861, 'epoch': 63.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-762/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-762/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-762/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-761] due to args.save_total_limit
{'eval_loss': 2.824279308319092, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5172, 'eval_samples_per_second': 116.0, 'eval_steps_per_second': 5.8, 'epoch': 63.58}
 64%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 763/1200 [37:42<21:24,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 763/1200 [37:42<21:24,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-763
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-763/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-763/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-763/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-763/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-762] due to args.save_total_limit
 64%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 764/1200 [37:45<21:31,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-764/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-764/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-764/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-764/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-763] due to args.save_total_limit
{'eval_loss': 2.9443747997283936, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5113, 'eval_samples_per_second': 117.353, 'eval_steps_per_second': 5.868, 'epoch': 63.75}
 64%|████████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 765/1200 [37:48<21:32,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|████████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 765/1200 [37:48<21:32,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-765
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-765/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-765/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-765/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-765/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-764] due to args.save_total_limit
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 766/1200 [37:51<21:24,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 766/1200 [37:51<21:24,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-766
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-766/config.json
{'eval_loss': 2.9848663806915283, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.548, 'eval_steps_per_second': 5.877, 'epoch': 63.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-766/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-766/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-766/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-765] due to args.save_total_limit
{'eval_loss': 2.979851722717285, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.579, 'eval_steps_per_second': 5.879, 'epoch': 63.92}
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                      | 767/1200 [37:54<22:08,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                      | 767/1200 [37:55<22:08,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-767
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-767/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-767/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-767/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-767/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-766] due to args.save_total_limit
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 768/1200 [37:57<21:42,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 768/1200 [37:58<21:42,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-768
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-768/config.json
{'eval_loss': 2.9947471618652344, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.834, 'eval_steps_per_second': 5.892, 'epoch': 64.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-768/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-768/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-768/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-767] due to args.save_total_limit
{'eval_loss': 2.9996721744537354, 'eval_f1': 0.486284348864994, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.782, 'eval_steps_per_second': 5.889, 'epoch': 64.08}
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 769/1200 [38:00<21:22,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 769/1200 [38:01<21:22,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-769
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-769/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-769/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-769/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-769/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-768] due to args.save_total_limit
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                      | 770/1200 [38:03<21:19,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                      | 770/1200 [38:03<21:19,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-770
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-770/config.json
{'eval_loss': 3.0017998218536377, 'eval_f1': 0.486284348864994, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.707, 'eval_steps_per_second': 5.885, 'epoch': 64.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-770/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-770/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-770/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-769] due to args.save_total_limit
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 771/1200 [38:06<21:13,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.9731638431549072, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.5084, 'eval_samples_per_second': 118.009, 'eval_steps_per_second': 5.9, 'epoch': 64.25}
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 771/1200 [38:06<21:13,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-771
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-771/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-771/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-771/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-771/special_tokens_map.json
{'eval_loss': 2.9696896076202393, 'eval_f1': 0.48751322751322756, 'eval_runtime': 0.5083, 'eval_samples_per_second': 118.045, 'eval_steps_per_second': 5.902, 'epoch': 64.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-770] due to args.save_total_limit
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                      | 772/1200 [38:09<21:04,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                      | 772/1200 [38:09<21:04,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-772
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-772/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-772/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-772/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-772/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-771] due to args.save_total_limit
{'eval_loss': 2.9778568744659424, 'eval_f1': 0.48751322751322756, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.156, 'eval_steps_per_second': 5.858, 'epoch': 64.42}
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 773/1200 [38:12<21:06,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 773/1200 [38:12<21:06,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-773
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-773/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-773/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-773/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-773/special_tokens_map.json
{'eval_loss': 2.9800963401794434, 'eval_f1': 0.467192075796727, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.578, 'eval_steps_per_second': 5.879, 'epoch': 64.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-772] due to args.save_total_limit
 64%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 774/1200 [38:15<20:57,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 64%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 774/1200 [38:15<20:57,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-774
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-774/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-774/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-774/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-774/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-773] due to args.save_total_limit
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                     | 775/1200 [38:18<20:49,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-775/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-775/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-775/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-775/special_tokens_map.json
{'eval_loss': 2.967755079269409, 'eval_f1': 0.486284348864994, 'eval_runtime': 0.512, 'eval_samples_per_second': 117.176, 'eval_steps_per_second': 5.859, 'epoch': 64.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-774] due to args.save_total_limit
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 776/1200 [38:21<20:46,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 776/1200 [38:21<20:46,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-776
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-776/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-776/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-776/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-776/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-775] due to args.save_total_limit
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▍                                                     | 777/1200 [38:24<20:50,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.16it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-777/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-777/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-777/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-777/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-776] due to args.save_total_limit
{'eval_loss': 2.9444384574890137, 'eval_f1': 0.5018399044205495, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.638, 'eval_steps_per_second': 5.882, 'epoch': 64.83}
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 778/1200 [38:27<21:29,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 778/1200 [38:27<21:29,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-778
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-778/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-778/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-778/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-778/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-777] due to args.save_total_limit
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 779/1200 [38:30<21:14,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-779/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-779/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-779/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-779/special_tokens_map.json
{'eval_loss': 2.8879523277282715, 'eval_f1': 0.521943367786391, 'eval_runtime': 0.5154, 'eval_samples_per_second': 116.406, 'eval_steps_per_second': 5.82, 'epoch': 65.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-778] due to args.save_total_limit
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▊                                                     | 780/1200 [38:33<20:54,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▊                                                     | 780/1200 [38:33<20:54,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-780
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-780/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-780/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-780/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-780/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-779] due to args.save_total_limit
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 781/1200 [38:36<20:42,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 781/1200 [38:36<20:42,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-781
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-781/config.json
{'eval_loss': 2.8394479751586914, 'eval_f1': 0.521943367786391, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.746, 'eval_steps_per_second': 5.887, 'epoch': 65.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-781/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-781/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-781/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-780] due to args.save_total_limit
{'eval_loss': 2.7939860820770264, 'eval_f1': 0.518941798941799, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.943, 'eval_steps_per_second': 5.847, 'epoch': 65.17}
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 782/1200 [38:39<20:36,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 782/1200 [38:39<20:36,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-782
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-782/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-782/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-782/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-782/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-781] due to args.save_total_limit
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 783/1200 [38:42<20:28,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 783/1200 [38:42<20:28,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-783
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-783/config.json
{'eval_loss': 2.752474069595337, 'eval_f1': 0.518941798941799, 'eval_runtime': 0.5162, 'eval_samples_per_second': 116.245, 'eval_steps_per_second': 5.812, 'epoch': 65.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-783/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-783/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-783/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-782] due to args.save_total_limit
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 784/1200 [38:44<20:18,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.7091920375823975, 'eval_f1': 0.5495035460992909, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.77, 'eval_steps_per_second': 5.889, 'epoch': 65.33}
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 784/1200 [38:45<20:18,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-784
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-784/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-784/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-784/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-784/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-783] due to args.save_total_limit
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                                    | 785/1200 [38:47<20:18,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                                    | 785/1200 [38:48<20:18,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-785
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-785/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-785/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-785/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-785/special_tokens_map.json
{'eval_loss': 2.667044162750244, 'eval_f1': 0.5695993179880647, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.793, 'eval_steps_per_second': 5.89, 'epoch': 65.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-784] due to args.save_total_limit
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 786/1200 [38:50<20:12,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-786/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-786/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-786/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-786/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-785] due to args.save_total_limit
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 787/1200 [38:53<20:13,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 787/1200 [38:54<20:13,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-787
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-787/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-787/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-787/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-787/special_tokens_map.json
{'eval_loss': 2.574496030807495, 'eval_f1': 0.5517460317460317, 'eval_runtime': 0.5178, 'eval_samples_per_second': 115.867, 'eval_steps_per_second': 5.793, 'epoch': 65.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-786] due to args.save_total_limit
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 788/1200 [38:56<20:10,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 788/1200 [38:57<20:10,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-788
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-788/config.json
{'eval_loss': 2.570585012435913, 'eval_f1': 0.5359465737514518, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.467, 'eval_steps_per_second': 5.873, 'epoch': 65.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-788/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-788/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-788/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-787] due to args.save_total_limit
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████▉                                                    | 789/1200 [38:59<20:14,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████▉                                                    | 789/1200 [39:00<20:14,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-789
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-789/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-789/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-789/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-789/special_tokens_map.json
{'eval_loss': 2.569854736328125, 'eval_f1': 0.519748984865264, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.113, 'eval_steps_per_second': 5.856, 'epoch': 65.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-788] due to args.save_total_limit
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 790/1200 [39:02<20:08,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 790/1200 [39:03<20:08,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-790
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-790/config.json
{'eval_loss': 2.6013007164001465, 'eval_f1': 0.5135165227621268, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.16, 'eval_steps_per_second': 5.858, 'epoch': 65.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-790/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-790/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-790/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-789] due to args.save_total_limit
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 791/1200 [39:05<20:09,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 791/1200 [39:06<20:09,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-791
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-791/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-791/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-791/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-791/special_tokens_map.json
{'eval_loss': 2.65346097946167, 'eval_f1': 0.49588719153936545, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.538, 'eval_steps_per_second': 5.877, 'epoch': 65.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-790] due to args.save_total_limit
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                   | 792/1200 [39:08<20:46,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.6921465396881104, 'eval_f1': 0.49588719153936545, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.686, 'eval_steps_per_second': 5.884, 'epoch': 66.0}
                                                                                                                                                                                                Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-792
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-792/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-792/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-792/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-792/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-791] due to args.save_total_limit
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 793/1200 [39:11<20:25,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 793/1200 [39:12<20:25,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-793
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-793/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-793/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-793/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-793/special_tokens_map.json
{'eval_loss': 2.718644618988037, 'eval_f1': 0.4807817415880125, 'eval_runtime': 0.5167, 'eval_samples_per_second': 116.123, 'eval_steps_per_second': 5.806, 'epoch': 66.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-792] due to args.save_total_limit
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 794/1200 [39:15<21:04,  3.11s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.76471209526062, 'eval_f1': 0.4807817415880125, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.78, 'eval_steps_per_second': 5.889, 'epoch': 66.17}
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 794/1200 [39:15<21:04,  3.11s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-794
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-794/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-794/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-794/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-794/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-793] due to args.save_total_limit
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 795/1200 [39:18<20:37,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 795/1200 [39:18<20:37,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-795
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-795/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-795/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-795/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-795/special_tokens_map.json
{'eval_loss': 2.844904661178589, 'eval_f1': 0.5022838377031118, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.932, 'eval_steps_per_second': 5.847, 'epoch': 66.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-794] due to args.save_total_limit
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 796/1200 [39:21<20:31,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-796/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-796/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-796/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-796/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-795] due to args.save_total_limit
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 797/1200 [39:23<20:12,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 797/1200 [39:24<20:12,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-797
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-797/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-797/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-797/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-797/special_tokens_map.json
{'eval_loss': 2.970459222793579, 'eval_f1': 0.5011702127659574, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.662, 'eval_steps_per_second': 5.883, 'epoch': 66.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-796] due to args.save_total_limit
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 798/1200 [39:26<20:02,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 798/1200 [39:27<20:02,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-798
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-798/config.json
{'eval_loss': 3.006098508834839, 'eval_f1': 0.5001060445387062, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.688, 'eval_steps_per_second': 5.884, 'epoch': 66.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-798/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-798/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-798/special_tokens_map.json
{'eval_loss': 3.067706823348999, 'eval_f1': 0.5148028673835124, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.631, 'eval_steps_per_second': 5.882, 'epoch': 66.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-797] due to args.save_total_limit
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                  | 799/1200 [39:29<19:57,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                  | 799/1200 [39:30<19:57,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-799
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-799/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-799/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-799/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-799/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-798] due to args.save_total_limit
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 800/1200 [39:32<19:46,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 800/1200 [39:33<19:46,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-800
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-800/config.json
{'eval_loss': 3.1230008602142334, 'eval_f1': 0.5169857681811757, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.571, 'eval_steps_per_second': 5.879, 'epoch': 66.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-800/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-800/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-800/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-799] due to args.save_total_limit
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 801/1200 [39:35<19:38,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 801/1200 [39:36<19:38,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-801
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-801/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-801/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-801/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-801/special_tokens_map.json
{'eval_loss': 3.15337872505188, 'eval_f1': 0.5317667309431208, 'eval_runtime': 0.5134, 'eval_samples_per_second': 116.875, 'eval_steps_per_second': 5.844, 'epoch': 66.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-800] due to args.save_total_limit
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                  | 802/1200 [39:38<19:32,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                  | 802/1200 [39:39<19:32,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-802
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-802/config.json
{'eval_loss': 3.1902287006378174, 'eval_f1': 0.5462256316111548, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.746, 'eval_steps_per_second': 5.887, 'epoch': 66.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-802/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-802/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-802/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-801] due to args.save_total_limit
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 803/1200 [39:41<19:30,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.231555223464966, 'eval_f1': 0.5462256316111548, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.526, 'eval_steps_per_second': 5.876, 'epoch': 66.92}
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 803/1200 [39:42<19:30,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-803
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-803/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-803/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-803/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-803/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-802] due to args.save_total_limit
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                  | 804/1200 [39:44<19:36,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                  | 804/1200 [39:45<19:36,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-804
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-804/config.json
{'eval_loss': 3.2779645919799805, 'eval_f1': 0.5168702908441248, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.112, 'eval_steps_per_second': 5.856, 'epoch': 67.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-804/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-804/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-804/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-803] due to args.save_total_limit
{'eval_loss': 3.3021788597106934, 'eval_f1': 0.5168702908441248, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.486, 'eval_steps_per_second': 5.874, 'epoch': 67.08}
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 805/1200 [39:47<19:28,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 805/1200 [39:48<19:28,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-805
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-805/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-805/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-805/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-805/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-804] due to args.save_total_limit
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████                                                  | 806/1200 [39:50<19:26,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████                                                  | 806/1200 [39:51<19:26,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-806
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-806/config.json
{'eval_loss': 3.299851894378662, 'eval_f1': 0.5168702908441248, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.537, 'eval_steps_per_second': 5.877, 'epoch': 67.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-806/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-806/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-806/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-805] due to args.save_total_limit
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 807/1200 [39:53<19:19,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.3141791820526123, 'eval_f1': 0.5305155030961483, 'eval_runtime': 0.5135, 'eval_samples_per_second': 116.845, 'eval_steps_per_second': 5.842, 'epoch': 67.25}
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 807/1200 [39:54<19:19,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-807
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-807/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-807/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-807/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-807/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-806] due to args.save_total_limit
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 808/1200 [39:56<19:20,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 808/1200 [39:56<19:20,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-808
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-808/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-808/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-808/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-808/special_tokens_map.json
{'eval_loss': 3.288080930709839, 'eval_f1': 0.5305155030961483, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.644, 'eval_steps_per_second': 5.882, 'epoch': 67.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-807] due to args.save_total_limit
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                 | 809/1200 [39:59<20:02,  3.08s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                 | 809/1200 [40:00<20:02,  3.08s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-809
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-809/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-809/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-809/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-809/special_tokens_map.json
{'eval_loss': 3.239772081375122, 'eval_f1': 0.5305155030961483, 'eval_runtime': 0.5141, 'eval_samples_per_second': 116.703, 'eval_steps_per_second': 5.835, 'epoch': 67.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-808] due to args.save_total_limit
 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 810/1200 [40:02<19:38,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 810/1200 [40:03<19:38,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-810
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-810/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-810/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-810/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-810/special_tokens_map.json
{'eval_loss': 3.1814072132110596, 'eval_f1': 0.5168702908441248, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.612, 'eval_steps_per_second': 5.881, 'epoch': 67.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-809] due to args.save_total_limit
 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                 | 811/1200 [40:05<19:21,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-811/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-811/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-811/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-811/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-810] due to args.save_total_limit
 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 812/1200 [40:08<19:14,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 812/1200 [40:09<19:14,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-812
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-812/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-812/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-812/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-812/special_tokens_map.json
{'eval_loss': 3.010770320892334, 'eval_f1': 0.5321044546850998, 'eval_runtime': 0.508, 'eval_samples_per_second': 118.119, 'eval_steps_per_second': 5.906, 'epoch': 67.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-811] due to args.save_total_limit
 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 813/1200 [40:11<19:07,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 813/1200 [40:12<19:07,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-813
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-813/config.json
{'eval_loss': 2.9322495460510254, 'eval_f1': 0.5462256316111548, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.819, 'eval_steps_per_second': 5.841, 'epoch': 67.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-813/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-813/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-813/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-812] due to args.save_total_limit
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                 | 814/1200 [40:14<18:59,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                 | 814/1200 [40:14<18:59,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-814
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-814/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-814/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-814/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-814/special_tokens_map.json
{'eval_loss': 2.8540258407592773, 'eval_f1': 0.5292596436602665, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.514, 'eval_steps_per_second': 5.876, 'epoch': 67.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-813] due to args.save_total_limit
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 815/1200 [40:17<18:54,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-815/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-815/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-815/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-815/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-814] due to args.save_total_limit
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 816/1200 [40:20<18:48,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 816/1200 [40:20<18:48,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-816
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-816/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-816/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-816/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-816/special_tokens_map.json
{'eval_loss': 2.7503530979156494, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5175, 'eval_samples_per_second': 115.951, 'eval_steps_per_second': 5.798, 'epoch': 68.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-815] due to args.save_total_limit
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 817/1200 [40:23<18:55,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 817/1200 [40:23<18:55,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-817
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-817/config.json
{'eval_loss': 2.7241969108581543, 'eval_f1': 0.5159539647344524, 'eval_runtime': 0.5113, 'eval_samples_per_second': 117.34, 'eval_steps_per_second': 5.867, 'epoch': 68.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-817/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-817/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-817/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-816] due to args.save_total_limit
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 818/1200 [40:26<18:44,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 818/1200 [40:26<18:44,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-818
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-818/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-818/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-818/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-818/special_tokens_map.json
{'eval_loss': 2.71132755279541, 'eval_f1': 0.5135165227621268, 'eval_runtime': 0.5159, 'eval_samples_per_second': 116.293, 'eval_steps_per_second': 5.815, 'epoch': 68.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-817] due to args.save_total_limit
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 819/1200 [40:29<18:40,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 819/1200 [40:29<18:40,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-819
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-819/config.json
{'eval_loss': 2.6983840465545654, 'eval_f1': 0.5141582491582491, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.829, 'eval_steps_per_second': 5.841, 'epoch': 68.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-819/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-819/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-819/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-818] due to args.save_total_limit
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 820/1200 [40:32<18:35,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.7107203006744385, 'eval_f1': 0.5141582491582491, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.054, 'eval_steps_per_second': 5.853, 'epoch': 68.33}
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 820/1200 [40:32<18:35,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-820
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-820/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-820/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-820/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-820/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-819] due to args.save_total_limit
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                | 821/1200 [40:34<18:32,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                | 821/1200 [40:35<18:32,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-821
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-821/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-821/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-821/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-821/special_tokens_map.json
{'eval_loss': 2.7292494773864746, 'eval_f1': 0.5141582491582491, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.499, 'eval_steps_per_second': 5.875, 'epoch': 68.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-820] due to args.save_total_limit
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 822/1200 [40:38<19:11,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 822/1200 [40:38<19:11,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-822
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-822/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-822/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-822/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-822/special_tokens_map.json
{'eval_loss': 2.761652708053589, 'eval_f1': 0.5167460317460317, 'eval_runtime': 0.5162, 'eval_samples_per_second': 116.238, 'eval_steps_per_second': 5.812, 'epoch': 68.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-821] due to args.save_total_limit
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                               | 823/1200 [40:41<19:00,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                               | 823/1200 [40:41<19:00,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-823
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-823/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-823/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-823/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-823/special_tokens_map.json
{'eval_loss': 2.7895727157592773, 'eval_f1': 0.4990815947337686, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.608, 'eval_steps_per_second': 5.88, 'epoch': 68.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-822] due to args.save_total_limit
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 824/1200 [40:44<18:48,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-824/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-824/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-824/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-824/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-823] due to args.save_total_limit
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                               | 825/1200 [40:47<18:36,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                               | 825/1200 [40:47<18:36,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-825
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-825/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-825/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-825/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-825/special_tokens_map.json
{'eval_loss': 2.8207437992095947, 'eval_f1': 0.4990815947337686, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.88, 'eval_steps_per_second': 5.844, 'epoch': 68.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-824] due to args.save_total_limit
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 826/1200 [40:50<18:37,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-826/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-826/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-826/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-826/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-825] due to args.save_total_limit
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 827/1200 [40:53<18:28,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 827/1200 [40:53<18:28,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-827
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-827/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-827/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-827/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-827/special_tokens_map.json
{'eval_loss': 2.79374098777771, 'eval_f1': 0.4990815947337686, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.585, 'eval_steps_per_second': 5.879, 'epoch': 68.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-826] due to args.save_total_limit
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 828/1200 [40:56<18:23,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.45it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-828/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-828/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-828/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-828/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-827] due to args.save_total_limit
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 829/1200 [40:58<18:18,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 829/1200 [40:59<18:18,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-829
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-829/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-829/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-829/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-829/special_tokens_map.json
{'eval_loss': 2.7347335815429688, 'eval_f1': 0.5167460317460317, 'eval_runtime': 0.5168, 'eval_samples_per_second': 116.108, 'eval_steps_per_second': 5.805, 'epoch': 69.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-828] due to args.save_total_limit
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 830/1200 [41:01<18:11,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 830/1200 [41:02<18:11,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-830
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-830/config.json
{'eval_loss': 2.726531505584717, 'eval_f1': 0.5159539647344524, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.672, 'eval_steps_per_second': 5.884, 'epoch': 69.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-830/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-830/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-830/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-829] due to args.save_total_limit
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 831/1200 [41:04<18:11,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 831/1200 [41:05<18:11,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-831
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-831/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-831/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-831/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-831/special_tokens_map.json
{'eval_loss': 2.7504630088806152, 'eval_f1': 0.5031007751937985, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.785, 'eval_steps_per_second': 5.889, 'epoch': 69.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-830] due to args.save_total_limit
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                              | 832/1200 [41:07<18:03,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                              | 832/1200 [41:08<18:03,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-832
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-832/config.json
{'eval_loss': 2.774779796600342, 'eval_f1': 0.5517460317460317, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.695, 'eval_steps_per_second': 5.885, 'epoch': 69.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-832/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-832/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-832/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-831] due to args.save_total_limit
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 833/1200 [41:10<17:56,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 833/1200 [41:11<17:56,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-833
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-833/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-833/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-833/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-833/special_tokens_map.json
{'eval_loss': 2.7928967475891113, 'eval_f1': 0.5517460317460317, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.436, 'eval_steps_per_second': 5.872, 'epoch': 69.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-832] due to args.save_total_limit
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 834/1200 [41:13<18:01,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 834/1200 [41:14<18:01,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-834
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-834/config.json
{'eval_loss': 2.813939094543457, 'eval_f1': 0.5121715564981737, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.73, 'eval_steps_per_second': 5.886, 'epoch': 69.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-834/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-834/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-834/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-833] due to args.save_total_limit
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                              | 835/1200 [41:16<17:56,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                              | 835/1200 [41:17<17:56,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-835
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-835/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-835/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-835/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-835/special_tokens_map.json
{'eval_loss': 2.8240747451782227, 'eval_f1': 0.5121715564981737, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.902, 'eval_steps_per_second': 5.845, 'epoch': 69.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-834] due to args.save_total_limit
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 836/1200 [41:19<17:47,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 836/1200 [41:20<17:47,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-836
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-836/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-836/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-836/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-836/special_tokens_map.json
{'eval_loss': 2.8085107803344727, 'eval_f1': 0.5292596436602665, 'eval_runtime': 0.5134, 'eval_samples_per_second': 116.869, 'eval_steps_per_second': 5.843, 'epoch': 69.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-835] due to args.save_total_limit
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 837/1200 [41:22<18:27,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 837/1200 [41:23<18:27,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-837
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-837/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-837/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-837/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-837/special_tokens_map.json
{'eval_loss': 2.7953054904937744, 'eval_f1': 0.5495035460992909, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.407, 'eval_steps_per_second': 5.87, 'epoch': 69.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-836] due to args.save_total_limit
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 838/1200 [41:25<18:13,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 838/1200 [41:26<18:13,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-838
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-838/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-838/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-838/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-838/special_tokens_map.json
{'eval_loss': 2.789017677307129, 'eval_f1': 0.5495035460992909, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.502, 'eval_steps_per_second': 5.875, 'epoch': 69.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-837] due to args.save_total_limit
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                             | 839/1200 [41:28<18:02,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.54it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-839/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-839/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-839/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-839/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-838] due to args.save_total_limit
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 840/1200 [41:31<17:57,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 840/1200 [41:32<17:57,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-840
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-840/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-840/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-840/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-840/special_tokens_map.json
{'eval_loss': 2.778217077255249, 'eval_f1': 0.5495035460992909, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.444, 'eval_steps_per_second': 5.872, 'epoch': 70.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-839] due to args.save_total_limit
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 841/1200 [41:34<17:50,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.53it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-841/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-841/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-841/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-841/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-840] due to args.save_total_limit
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 842/1200 [41:37<17:43,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 842/1200 [41:38<17:43,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-842
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-842/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-842/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-842/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-842/special_tokens_map.json
{'eval_loss': 2.7533767223358154, 'eval_f1': 0.5695993179880647, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.735, 'eval_steps_per_second': 5.887, 'epoch': 70.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-841] due to args.save_total_limit
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 843/1200 [41:40<18:15,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-843/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-843/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-843/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-843/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-842] due to args.save_total_limit
{'eval_loss': 2.732828378677368, 'eval_f1': 0.5695993179880647, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.656, 'eval_steps_per_second': 5.883, 'epoch': 70.25}
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                             | 844/1200 [41:43<17:55,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                             | 844/1200 [41:44<17:55,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-844
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-844/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-844/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-844/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-844/special_tokens_map.json
{'eval_loss': 2.734869956970215, 'eval_f1': 0.5695993179880647, 'eval_runtime': 0.5164, 'eval_samples_per_second': 116.185, 'eval_steps_per_second': 5.809, 'epoch': 70.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-843] due to args.save_total_limit
 70%|███████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 845/1200 [41:46<17:43,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-845/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-845/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-845/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-845/special_tokens_map.json
{'eval_loss': 2.7281062602996826, 'eval_f1': 0.5337037037037038, 'eval_runtime': 0.5137, 'eval_samples_per_second': 116.794, 'eval_steps_per_second': 5.84, 'epoch': 70.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-844] due to args.save_total_limit
 70%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 846/1200 [41:49<17:30,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 70%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 846/1200 [41:50<17:30,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-846
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-846/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-846/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-846/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-846/special_tokens_map.json
{'eval_loss': 2.7252299785614014, 'eval_f1': 0.5337037037037038, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.575, 'eval_steps_per_second': 5.879, 'epoch': 70.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-845] due to args.save_total_limit
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                            | 847/1200 [41:52<17:30,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.54it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-847/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-847/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-847/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-847/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-846] due to args.save_total_limit
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 848/1200 [41:55<17:33,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 848/1200 [41:56<17:33,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-848
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-848/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-848/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-848/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-848/special_tokens_map.json
{'eval_loss': 2.7030813694000244, 'eval_f1': 0.5173357702569273, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.578, 'eval_steps_per_second': 5.879, 'epoch': 70.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-847] due to args.save_total_limit
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 849/1200 [41:58<17:22,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 849/1200 [41:59<17:22,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-849
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-849/config.json
{'eval_loss': 2.6921372413635254, 'eval_f1': 0.5337037037037038, 'eval_runtime': 0.5152, 'eval_samples_per_second': 116.455, 'eval_steps_per_second': 5.823, 'epoch': 70.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-849/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-849/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-849/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-848] due to args.save_total_limit
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 850/1200 [42:01<17:21,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 850/1200 [42:02<17:21,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-850
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-850/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-850/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-850/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-850/special_tokens_map.json
{'eval_loss': 2.6936404705047607, 'eval_f1': 0.5005291005291005, 'eval_runtime': 0.514, 'eval_samples_per_second': 116.721, 'eval_steps_per_second': 5.836, 'epoch': 70.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-849] due to args.save_total_limit
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 851/1200 [42:04<17:13,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 851/1200 [42:05<17:13,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-851
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-851/config.json
{'eval_loss': 2.7178802490234375, 'eval_f1': 0.5005291005291005, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.581, 'eval_steps_per_second': 5.879, 'epoch': 70.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-851/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-851/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-851/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-850] due to args.save_total_limit
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                            | 852/1200 [42:07<17:07,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                            | 852/1200 [42:07<17:07,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-852
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-852/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-852/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-852/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-852/special_tokens_map.json
{'eval_loss': 2.7375855445861816, 'eval_f1': 0.5005291005291005, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.59, 'eval_steps_per_second': 5.88, 'epoch': 71.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-851] due to args.save_total_limit
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 853/1200 [42:10<17:03,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 853/1200 [42:10<17:03,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-853
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-853/config.json
{'eval_loss': 2.7575438022613525, 'eval_f1': 0.5005291005291005, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.743, 'eval_steps_per_second': 5.887, 'epoch': 71.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-853/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-853/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-853/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-852] due to args.save_total_limit
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 854/1200 [42:13<17:03,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 854/1200 [42:13<17:03,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-854
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-854/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-854/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-854/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-854/special_tokens_map.json
{'eval_loss': 2.7638139724731445, 'eval_f1': 0.5005291005291005, 'eval_runtime': 0.5131, 'eval_samples_per_second': 116.937, 'eval_steps_per_second': 5.847, 'epoch': 71.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-853] due to args.save_total_limit
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 855/1200 [42:16<16:53,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 855/1200 [42:16<16:53,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-855
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-855/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-855/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-855/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-855/special_tokens_map.json
{'eval_loss': 2.7633299827575684, 'eval_f1': 0.5135165227621268, 'eval_runtime': 0.5125, 'eval_samples_per_second': 117.07, 'eval_steps_per_second': 5.853, 'epoch': 71.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-854] due to args.save_total_limit
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 856/1200 [42:19<17:30,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 856/1200 [42:20<17:30,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-856
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-856/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-856/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-856/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-856/special_tokens_map.json
{'eval_loss': 2.7785112857818604, 'eval_f1': 0.5141582491582491, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.757, 'eval_steps_per_second': 5.888, 'epoch': 71.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-855] due to args.save_total_limit
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 857/1200 [42:22<17:11,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 857/1200 [42:23<17:11,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-857
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-857/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-857/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-857/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-857/special_tokens_map.json
{'eval_loss': 2.7955143451690674, 'eval_f1': 0.5167460317460317, 'eval_runtime': 0.5114, 'eval_samples_per_second': 117.324, 'eval_steps_per_second': 5.866, 'epoch': 71.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-856] due to args.save_total_limit
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 858/1200 [42:25<17:06,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-858/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-858/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-858/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-858/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-857] due to args.save_total_limit
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                           | 859/1200 [42:28<16:53,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                           | 859/1200 [42:28<16:53,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-859
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-859/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-859/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-859/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-859/special_tokens_map.json
{'eval_loss': 2.799077033996582, 'eval_f1': 0.5038327526132403, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.651, 'eval_steps_per_second': 5.883, 'epoch': 71.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-858] due to args.save_total_limit
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 860/1200 [42:31<16:45,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 860/1200 [42:31<16:45,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-860
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-860/config.json
{'eval_loss': 2.8069875240325928, 'eval_f1': 0.5038327526132403, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.055, 'eval_steps_per_second': 5.853, 'epoch': 71.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-860/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-860/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-860/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-859] due to args.save_total_limit
{'eval_loss': 2.814552068710327, 'eval_f1': 0.5038327526132403, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.68, 'eval_steps_per_second': 5.884, 'epoch': 71.75}
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                           | 861/1200 [42:34<16:41,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                           | 861/1200 [42:34<16:41,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-861
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-861/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-861/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-861/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-861/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-860] due to args.save_total_limit
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 862/1200 [42:37<16:46,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 862/1200 [42:37<16:46,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-862
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-862/config.json
{'eval_loss': 2.81766676902771, 'eval_f1': 0.4899963086009598, 'eval_runtime': 0.5144, 'eval_samples_per_second': 116.642, 'eval_steps_per_second': 5.832, 'epoch': 71.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-862/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-862/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-862/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-861] due to args.save_total_limit
{'eval_loss': 2.816053628921509, 'eval_f1': 0.5062717770034844, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.565, 'eval_steps_per_second': 5.878, 'epoch': 71.92}
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 863/1200 [42:40<16:44,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 863/1200 [42:40<16:44,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-863
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-863/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-863/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-863/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-863/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-862] due to args.save_total_limit
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                          | 864/1200 [42:43<16:45,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-864/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-864/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-864/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-864/special_tokens_map.json
{'eval_loss': 2.7917816638946533, 'eval_f1': 0.5062717770034844, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.11, 'eval_steps_per_second': 5.855, 'epoch': 72.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-863] due to args.save_total_limit
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 865/1200 [42:46<16:32,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 865/1200 [42:46<16:32,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-865
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-865/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-865/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-865/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-865/special_tokens_map.json
{'eval_loss': 2.7882726192474365, 'eval_f1': 0.5197150997150997, 'eval_runtime': 0.5182, 'eval_samples_per_second': 115.783, 'eval_steps_per_second': 5.789, 'epoch': 72.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-864] due to args.save_total_limit
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                          | 866/1200 [42:49<16:25,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                          | 866/1200 [42:49<16:25,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-866
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-866/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-866/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-866/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-866/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-865] due to args.save_total_limit
{'eval_loss': 2.788520336151123, 'eval_f1': 0.5197150997150997, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.501, 'eval_steps_per_second': 5.875, 'epoch': 72.25}
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 867/1200 [42:52<16:22,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 867/1200 [42:52<16:22,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-867
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-867/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-867/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-867/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-867/special_tokens_map.json
{'eval_loss': 2.7872345447540283, 'eval_f1': 0.5197150997150997, 'eval_runtime': 0.5184, 'eval_samples_per_second': 115.733, 'eval_steps_per_second': 5.787, 'epoch': 72.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-866] due to args.save_total_limit
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 868/1200 [42:55<16:21,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 868/1200 [42:55<16:21,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-868
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-868/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-868/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-868/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-868/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-867] due to args.save_total_limit
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                                          | 869/1200 [42:58<16:22,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.786451816558838, 'eval_f1': 0.5353589287227731, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.587, 'eval_steps_per_second': 5.879, 'epoch': 72.42}
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                                          | 869/1200 [42:58<16:22,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-869
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-869/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-869/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-869/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-869/special_tokens_map.json
{'eval_loss': 2.7969815731048584, 'eval_f1': 0.5353589287227731, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.618, 'eval_steps_per_second': 5.881, 'epoch': 72.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-868] due to args.save_total_limit
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 870/1200 [43:00<16:17,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 870/1200 [43:01<16:17,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-870
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-870/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-870/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-870/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-870/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-869] due to args.save_total_limit
{'eval_loss': 2.7983217239379883, 'eval_f1': 0.5353589287227731, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.467, 'eval_steps_per_second': 5.873, 'epoch': 72.58}
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                         | 871/1200 [43:04<16:51,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                         | 871/1200 [43:04<16:51,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-871
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-871/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-871/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-871/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-871/special_tokens_map.json
{'eval_loss': 2.8147289752960205, 'eval_f1': 0.5353589287227731, 'eval_runtime': 0.5164, 'eval_samples_per_second': 116.198, 'eval_steps_per_second': 5.81, 'epoch': 72.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-870] due to args.save_total_limit
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 872/1200 [43:07<16:42,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-872/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-872/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-872/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-872/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-871] due to args.save_total_limit
{'eval_loss': 2.832045793533325, 'eval_f1': 0.5353589287227731, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.763, 'eval_steps_per_second': 5.888, 'epoch': 72.75}
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 873/1200 [43:10<16:30,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 873/1200 [43:10<16:30,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-873
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-873/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-873/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-873/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-873/special_tokens_map.json
{'eval_loss': 2.8568599224090576, 'eval_f1': 0.5375802941020332, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.49, 'eval_steps_per_second': 5.874, 'epoch': 72.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-872] due to args.save_total_limit
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                         | 874/1200 [43:13<16:21,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                         | 874/1200 [43:13<16:21,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-874
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-874/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-874/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-874/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-874/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-873] due to args.save_total_limit
{'eval_loss': 2.867009401321411, 'eval_f1': 0.5375802941020332, 'eval_runtime': 0.5172, 'eval_samples_per_second': 116.005, 'eval_steps_per_second': 5.8, 'epoch': 72.92}
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 875/1200 [43:16<16:12,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 875/1200 [43:16<16:12,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-875
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-875/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-875/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-875/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-875/special_tokens_map.json
{'eval_loss': 2.8810532093048096, 'eval_f1': 0.5375802941020332, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.623, 'eval_steps_per_second': 5.881, 'epoch': 73.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-874] due to args.save_total_limit
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                         | 876/1200 [43:19<16:05,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                         | 876/1200 [43:19<16:05,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-876
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-876/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-876/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-876/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-876/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-875] due to args.save_total_limit
{'eval_loss': 2.8941595554351807, 'eval_f1': 0.5375802941020332, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.732, 'eval_steps_per_second': 5.887, 'epoch': 73.08}
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 877/1200 [43:22<15:56,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 877/1200 [43:22<15:56,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-877
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-877/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-877/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-877/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-877/special_tokens_map.json
{'eval_loss': 2.907424211502075, 'eval_f1': 0.5375802941020332, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.794, 'eval_steps_per_second': 5.89, 'epoch': 73.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-876] due to args.save_total_limit
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 878/1200 [43:25<15:51,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 878/1200 [43:25<15:51,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-878
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-878/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-878/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-878/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-878/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-877] due to args.save_total_limit
{'eval_loss': 2.9264116287231445, 'eval_f1': 0.5375802941020332, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.586, 'eval_steps_per_second': 5.879, 'epoch': 73.25}
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 879/1200 [43:28<16:26,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 879/1200 [43:28<16:26,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-879
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-879/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-879/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-879/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-879/special_tokens_map.json
{'eval_loss': 2.9477338790893555, 'eval_f1': 0.5375802941020332, 'eval_runtime': 0.5153, 'eval_samples_per_second': 116.43, 'eval_steps_per_second': 5.821, 'epoch': 73.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-878] due to args.save_total_limit
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 880/1200 [43:31<16:10,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 880/1200 [43:31<16:10,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-880
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-880/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-880/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-880/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-880/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-879] due to args.save_total_limit
{'eval_loss': 2.9605536460876465, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.769, 'eval_steps_per_second': 5.888, 'epoch': 73.42}
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 881/1200 [43:34<15:59,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 881/1200 [43:34<15:59,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-881
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-881/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-881/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-881/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-881/special_tokens_map.json
{'eval_loss': 2.97627329826355, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5089, 'eval_samples_per_second': 117.904, 'eval_steps_per_second': 5.895, 'epoch': 73.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-880] due to args.save_total_limit
 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 882/1200 [43:37<15:44,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 882/1200 [43:37<15:44,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-882
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-882/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-882/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-882/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-882/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-881] due to args.save_total_limit
{'eval_loss': 2.987740993499756, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.817, 'eval_steps_per_second': 5.841, 'epoch': 73.58}
 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                        | 883/1200 [43:40<15:43,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                        | 883/1200 [43:40<15:43,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-883
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-883/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-883/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-883/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-883/special_tokens_map.json
{'eval_loss': 3.0073509216308594, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.452, 'eval_steps_per_second': 5.873, 'epoch': 73.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-882] due to args.save_total_limit
 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 884/1200 [43:43<15:42,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 884/1200 [43:43<15:42,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-884
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-884/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-884/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-884/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-884/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-883] due to args.save_total_limit
{'eval_loss': 3.026569366455078, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.595, 'eval_steps_per_second': 5.88, 'epoch': 73.75}
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 885/1200 [43:46<15:43,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 885/1200 [43:46<15:43,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-885
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-885/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-885/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-885/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-885/special_tokens_map.json
{'eval_loss': 3.024794816970825, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.628, 'eval_steps_per_second': 5.881, 'epoch': 73.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-884] due to args.save_total_limit
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                       | 886/1200 [43:49<15:35,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                       | 886/1200 [43:49<15:35,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-886
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-886/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-886/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-886/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-886/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-885] due to args.save_total_limit
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 887/1200 [43:52<15:32,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-887/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-887/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-887/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-887/special_tokens_map.json
{'eval_loss': 3.038578987121582, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5162, 'eval_samples_per_second': 116.228, 'eval_steps_per_second': 5.811, 'epoch': 74.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-886] due to args.save_total_limit
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                       | 888/1200 [43:54<15:21,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                       | 888/1200 [43:55<15:21,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-888
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-888/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-888/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-888/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-888/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-887] due to args.save_total_limit
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 889/1200 [43:57<15:14,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-889/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-889/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-889/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-889/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-888] due to args.save_total_limit
{'eval_loss': 3.0679452419281006, 'eval_f1': 0.5034582071310909, 'eval_runtime': 0.513, 'eval_samples_per_second': 116.95, 'eval_steps_per_second': 5.848, 'epoch': 74.17}
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 890/1200 [44:00<15:07,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 890/1200 [44:01<15:07,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-890
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-890/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-890/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-890/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-890/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-889] due to args.save_total_limit
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                       | 891/1200 [44:03<15:14,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                       | 891/1200 [44:04<15:14,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-891
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-891/config.json
{'eval_loss': 3.0684449672698975, 'eval_f1': 0.5034582071310909, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.39, 'eval_steps_per_second': 5.869, 'epoch': 74.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-891/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-891/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-891/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-890] due to args.save_total_limit
{'eval_loss': 3.0627987384796143, 'eval_f1': 0.5403239556692242, 'eval_runtime': 0.523, 'eval_samples_per_second': 114.726, 'eval_steps_per_second': 5.736, 'epoch': 74.33}
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 892/1200 [44:07<15:45,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 892/1200 [44:07<15:45,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-892
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-892/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-892/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-892/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-892/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-891] due to args.save_total_limit
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                       | 893/1200 [44:10<15:36,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-893/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-893/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-893/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-893/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-892] due to args.save_total_limit
{'eval_loss': 3.0844085216522217, 'eval_f1': 0.5062717770034844, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.669, 'eval_steps_per_second': 5.883, 'epoch': 74.5}
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 894/1200 [44:13<15:22,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 894/1200 [44:13<15:22,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-894
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-894/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-894/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-894/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-894/special_tokens_map.json
{'eval_loss': 3.103492498397827, 'eval_f1': 0.5062717770034844, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.588, 'eval_steps_per_second': 5.879, 'epoch': 74.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-893] due to args.save_total_limit
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 895/1200 [44:16<15:09,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 895/1200 [44:16<15:09,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-895
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-895/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-895/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-895/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-895/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-894] due to args.save_total_limit
{'eval_loss': 3.115222215652466, 'eval_f1': 0.5062717770034844, 'eval_runtime': 0.5219, 'eval_samples_per_second': 114.957, 'eval_steps_per_second': 5.748, 'epoch': 74.67}
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 896/1200 [44:18<15:02,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 896/1200 [44:19<15:02,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-896
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-896/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-896/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-896/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-896/special_tokens_map.json
{'eval_loss': 3.1290571689605713, 'eval_f1': 0.5062717770034844, 'eval_runtime': 0.5128, 'eval_samples_per_second': 117.001, 'eval_steps_per_second': 5.85, 'epoch': 74.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-895] due to args.save_total_limit
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 897/1200 [44:21<15:02,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 897/1200 [44:22<15:02,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-897
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-897/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-897/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-897/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-897/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-896] due to args.save_total_limit
{'eval_loss': 3.134293556213379, 'eval_f1': 0.5062717770034844, 'eval_runtime': 0.5143, 'eval_samples_per_second': 116.662, 'eval_steps_per_second': 5.833, 'epoch': 74.83}
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                      | 898/1200 [44:25<15:09,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                      | 898/1200 [44:25<15:09,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-898
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-898/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-898/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-898/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-898/special_tokens_map.json
{'eval_loss': 3.1282479763031006, 'eval_f1': 0.5062717770034844, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.591, 'eval_steps_per_second': 5.88, 'epoch': 74.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-897] due to args.save_total_limit
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 899/1200 [44:27<15:01,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 899/1200 [44:28<15:01,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-899
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-899/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-899/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-899/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-899/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-898] due to args.save_total_limit
{'eval_loss': 3.1219875812530518, 'eval_f1': 0.5250268345820713, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.767, 'eval_steps_per_second': 5.888, 'epoch': 75.0}
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 900/1200 [44:30<14:53,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 900/1200 [44:31<14:53,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-900
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-900/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-900/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-900/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-900/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-899] due to args.save_total_limit
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 901/1200 [44:33<14:54,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 901/1200 [44:34<14:54,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-901
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-901/config.json
{'eval_loss': 3.1215755939483643, 'eval_f1': 0.5403239556692242, 'eval_runtime': 0.5141, 'eval_samples_per_second': 116.702, 'eval_steps_per_second': 5.835, 'epoch': 75.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-901/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-901/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-901/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-900] due to args.save_total_limit
{'eval_loss': 3.123298168182373, 'eval_f1': 0.5403239556692242, 'eval_runtime': 0.5134, 'eval_samples_per_second': 116.871, 'eval_steps_per_second': 5.844, 'epoch': 75.17}
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 902/1200 [44:36<14:51,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 902/1200 [44:37<14:51,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-902
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-902/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-902/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-902/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-902/special_tokens_map.json
{'eval_loss': 3.128743886947632, 'eval_f1': 0.5403239556692242, 'eval_runtime': 0.5143, 'eval_samples_per_second': 116.652, 'eval_steps_per_second': 5.833, 'epoch': 75.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-901] due to args.save_total_limit
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 903/1200 [44:39<14:38,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 903/1200 [44:40<14:38,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-903
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-903/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-903/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-903/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-903/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-902] due to args.save_total_limit
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 904/1200 [44:42<14:35,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-904/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-904/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-904/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-904/special_tokens_map.json
{'eval_loss': 3.1371662616729736, 'eval_f1': 0.5403239556692242, 'eval_runtime': 0.5155, 'eval_samples_per_second': 116.403, 'eval_steps_per_second': 5.82, 'epoch': 75.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-903] due to args.save_total_limit
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 905/1200 [44:45<14:32,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 905/1200 [44:46<14:32,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-905
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-905/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-905/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-905/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-905/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-904] due to args.save_total_limit
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 906/1200 [44:48<14:25,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.1421310901641846, 'eval_f1': 0.5403239556692242, 'eval_runtime': 0.5192, 'eval_samples_per_second': 115.562, 'eval_steps_per_second': 5.778, 'epoch': 75.5}
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 906/1200 [44:49<14:25,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-906
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-906/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-906/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-906/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-906/special_tokens_map.json
{'eval_loss': 3.1451995372772217, 'eval_f1': 0.5552752906945648, 'eval_runtime': 0.5129, 'eval_samples_per_second': 116.991, 'eval_steps_per_second': 5.85, 'epoch': 75.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-905] due to args.save_total_limit
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                     | 907/1200 [44:51<14:22,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                     | 907/1200 [44:52<14:22,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-907
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-907/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-907/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-907/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-907/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-906] due to args.save_total_limit
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 908/1200 [44:54<14:25,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.49it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-908/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-908/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-908/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-908/special_tokens_map.json
{'eval_loss': 3.1578986644744873, 'eval_f1': 0.5717257683215131, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.605, 'eval_steps_per_second': 5.88, 'epoch': 75.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-907] due to args.save_total_limit
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                    | 909/1200 [44:57<14:19,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                    | 909/1200 [44:58<14:19,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-909
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-909/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-909/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-909/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-909/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-908] due to args.save_total_limit
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 910/1200 [45:00<14:16,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 910/1200 [45:00<14:16,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-910
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-910/config.json
{'eval_loss': 3.1799559593200684, 'eval_f1': 0.5717257683215131, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.523, 'eval_steps_per_second': 5.876, 'epoch': 75.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-910/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-910/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-910/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-909] due to args.save_total_limit
{'eval_loss': 3.1991498470306396, 'eval_f1': 0.5717257683215131, 'eval_runtime': 0.5132, 'eval_samples_per_second': 116.917, 'eval_steps_per_second': 5.846, 'epoch': 75.92}
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 911/1200 [45:03<14:48,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 911/1200 [45:04<14:48,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-911
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-911/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-911/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-911/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-911/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-910] due to args.save_total_limit
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 912/1200 [45:06<14:32,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-912/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-912/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-912/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-912/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-911] due to args.save_total_limit
{'eval_loss': 3.2029130458831787, 'eval_f1': 0.5717257683215131, 'eval_runtime': 0.5157, 'eval_samples_per_second': 116.342, 'eval_steps_per_second': 5.817, 'epoch': 76.08}
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 913/1200 [45:09<14:18,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 913/1200 [45:10<14:18,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-913
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-913/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-913/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-913/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-913/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-912] due to args.save_total_limit
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                    | 914/1200 [45:13<14:45,  3.10s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-914/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-914/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-914/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-914/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-913] due to args.save_total_limit
{'eval_loss': 3.208087205886841, 'eval_f1': 0.5521763103269332, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.74, 'eval_steps_per_second': 5.887, 'epoch': 76.25}
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 915/1200 [45:15<14:25,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 915/1200 [45:16<14:25,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-915
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-915/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-915/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-915/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-915/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-914] due to args.save_total_limit
 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 916/1200 [45:18<14:12,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-916/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-916/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-916/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-916/special_tokens_map.json
{'eval_loss': 3.2096574306488037, 'eval_f1': 0.5521763103269332, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.538, 'eval_steps_per_second': 5.877, 'epoch': 76.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-915] due to args.save_total_limit
 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 917/1200 [45:21<14:02,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 917/1200 [45:22<14:02,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-917
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-917/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-917/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-917/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-917/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-916] due to args.save_total_limit
 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 918/1200 [45:24<13:56,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-918/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-918/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-918/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-918/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-917] due to args.save_total_limit
{'eval_loss': 3.2017319202423096, 'eval_f1': 0.5372368875086266, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.526, 'eval_steps_per_second': 5.876, 'epoch': 76.58}
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                   | 919/1200 [45:27<13:49,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                   | 919/1200 [45:28<13:49,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-919
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-919/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-919/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-919/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-919/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-918] due to args.save_total_limit
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 920/1200 [45:30<13:44,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 920/1200 [45:31<13:44,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-920
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-920/config.json
{'eval_loss': 3.1931889057159424, 'eval_f1': 0.5566160009426182, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.784, 'eval_steps_per_second': 5.889, 'epoch': 76.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-920/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-920/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-920/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-919] due to args.save_total_limit
{'eval_loss': 3.198803186416626, 'eval_f1': 0.5372368875086266, 'eval_runtime': 0.5161, 'eval_samples_per_second': 116.263, 'eval_steps_per_second': 5.813, 'epoch': 76.75}
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                   | 921/1200 [45:33<13:44,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                   | 921/1200 [45:34<13:44,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-921
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-921/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-921/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-921/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-921/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-920] due to args.save_total_limit
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 922/1200 [45:36<13:42,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 922/1200 [45:36<13:42,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-922
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-922/config.json
{'eval_loss': 3.1873786449432373, 'eval_f1': 0.5566160009426182, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.611, 'eval_steps_per_second': 5.881, 'epoch': 76.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-922/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-922/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-922/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-921] due to args.save_total_limit
{'eval_loss': 3.161332845687866, 'eval_f1': 0.5566160009426182, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.589, 'eval_steps_per_second': 5.879, 'epoch': 76.92}
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 923/1200 [45:39<13:44,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 923/1200 [45:40<13:44,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-923
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-923/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-923/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-923/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-923/special_tokens_map.json
{'eval_loss': 3.119188070297241, 'eval_f1': 0.5411640211640212, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.552, 'eval_steps_per_second': 5.878, 'epoch': 77.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-922] due to args.save_total_limit
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                   | 924/1200 [45:42<13:36,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                   | 924/1200 [45:42<13:36,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-924
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-924/config.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-923] due to args.save_total_limit
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 925/1200 [45:45<13:30,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-925/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-925/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-925/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-925/special_tokens_map.json
{'eval_loss': 3.043781280517578, 'eval_f1': 0.5250268345820713, 'eval_runtime': 0.5175, 'eval_samples_per_second': 115.936, 'eval_steps_per_second': 5.797, 'epoch': 77.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-924] due to args.save_total_limit
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                  | 926/1200 [45:48<13:31,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                  | 926/1200 [45:48<13:31,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-926
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-926/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-926/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-926/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-926/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-925] due to args.save_total_limit
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 927/1200 [45:51<13:27,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.47it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-927/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-927/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-927/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-927/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-926] due to args.save_total_limit
{'eval_loss': 2.9876646995544434, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.593, 'eval_steps_per_second': 5.88, 'epoch': 77.33}
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 928/1200 [45:54<13:25,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 928/1200 [45:54<13:25,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-928
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-928/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-928/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-928/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-928/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-927] due to args.save_total_limit
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                  | 929/1200 [45:57<13:51,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-929/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-929/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-929/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-929/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-928] due to args.save_total_limit
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 930/1200 [46:00<13:33,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 930/1200 [46:00<13:33,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-930
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-930/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-930/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-930/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-930/special_tokens_map.json
{'eval_loss': 2.9508984088897705, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.537, 'eval_steps_per_second': 5.877, 'epoch': 77.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-929] due to args.save_total_limit
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                  | 931/1200 [46:03<13:28,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                  | 931/1200 [46:03<13:28,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-931
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-931/config.json
{'eval_loss': 2.9391486644744873, 'eval_f1': 0.5375802941020332, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.515, 'eval_steps_per_second': 5.876, 'epoch': 77.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-931/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-931/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-931/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-930] due to args.save_total_limit
{'eval_loss': 2.9348714351654053, 'eval_f1': 0.5376281544702597, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.608, 'eval_steps_per_second': 5.88, 'epoch': 77.67}
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 932/1200 [46:06<13:17,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 932/1200 [46:06<13:17,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-932
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-932/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-932/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-932/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-932/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-931] due to args.save_total_limit
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 933/1200 [46:09<13:11,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 933/1200 [46:09<13:11,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-933
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-933/config.json
{'eval_loss': 2.93782114982605, 'eval_f1': 0.5376281544702597, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.668, 'eval_steps_per_second': 5.883, 'epoch': 77.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-933/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-933/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-933/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-932] due to args.save_total_limit
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 934/1200 [46:12<13:05,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.93654727935791, 'eval_f1': 0.5376281544702597, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.496, 'eval_steps_per_second': 5.875, 'epoch': 77.83}
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 934/1200 [46:12<13:05,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-934
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-934/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-934/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-934/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-934/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-933] due to args.save_total_limit
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 935/1200 [46:15<13:00,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 935/1200 [46:15<13:00,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-935
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-935/config.json
{'eval_loss': 2.931002616882324, 'eval_f1': 0.5549823507718245, 'eval_runtime': 0.5157, 'eval_samples_per_second': 116.358, 'eval_steps_per_second': 5.818, 'epoch': 77.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-935/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-935/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-935/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-934] due to args.save_total_limit
{'eval_loss': 2.923746347427368, 'eval_f1': 0.5385964912280701, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.582, 'eval_steps_per_second': 5.879, 'epoch': 78.0}
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 936/1200 [46:18<13:01,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 936/1200 [46:18<13:01,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-936
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-936/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-936/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-936/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-936/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-935] due to args.save_total_limit
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 937/1200 [46:21<13:00,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 937/1200 [46:21<13:00,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-937
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-937/config.json
{'eval_loss': 2.9169692993164062, 'eval_f1': 0.5385964912280701, 'eval_runtime': 0.513, 'eval_samples_per_second': 116.963, 'eval_steps_per_second': 5.848, 'epoch': 78.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-937/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-937/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-937/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-936] due to args.save_total_limit
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 938/1200 [46:24<12:53,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.9078783988952637, 'eval_f1': 0.5385964912280701, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.722, 'eval_steps_per_second': 5.886, 'epoch': 78.17}
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 938/1200 [46:24<12:53,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-938
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-938/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-938/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-938/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-938/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-937] due to args.save_total_limit
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 939/1200 [46:26<12:51,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 939/1200 [46:27<12:51,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-939
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-939/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-939/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-939/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-939/special_tokens_map.json
{'eval_loss': 2.9026784896850586, 'eval_f1': 0.5385964912280701, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.48, 'eval_steps_per_second': 5.874, 'epoch': 78.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-938] due to args.save_total_limit
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 940/1200 [46:29<12:49,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-940/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-940/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-940/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-940/special_tokens_map.json
{'eval_loss': 2.900296688079834, 'eval_f1': 0.5385964912280701, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.635, 'eval_steps_per_second': 5.882, 'epoch': 78.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-939] due to args.save_total_limit
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                | 941/1200 [46:32<12:45,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                | 941/1200 [46:33<12:45,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-941
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-941/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-941/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-941/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-941/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-940] due to args.save_total_limit
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 942/1200 [46:35<12:40,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 942/1200 [46:36<12:40,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-942
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-942/config.json
{'eval_loss': 2.897545337677002, 'eval_f1': 0.5385964912280701, 'eval_runtime': 0.5128, 'eval_samples_per_second': 117.0, 'eval_steps_per_second': 5.85, 'epoch': 78.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-942/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-942/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-942/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-941] due to args.save_total_limit
{'eval_loss': 2.890108346939087, 'eval_f1': 0.5385964912280701, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.435, 'eval_steps_per_second': 5.872, 'epoch': 78.58}
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                | 943/1200 [46:38<12:46,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                | 943/1200 [46:39<12:46,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-943
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-943/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-943/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-943/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-943/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-942] due to args.save_total_limit
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 944/1200 [46:41<12:41,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 944/1200 [46:42<12:41,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-944
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-944/config.json
{'eval_loss': 2.888136863708496, 'eval_f1': 0.5385964912280701, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.576, 'eval_steps_per_second': 5.879, 'epoch': 78.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-944/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-944/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-944/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-943] due to args.save_total_limit
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 945/1200 [46:44<12:36,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 945/1200 [46:45<12:36,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-945
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-945/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-945/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-945/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-945/special_tokens_map.json
{'eval_loss': 2.886396646499634, 'eval_f1': 0.5385964912280701, 'eval_runtime': 0.5132, 'eval_samples_per_second': 116.922, 'eval_steps_per_second': 5.846, 'epoch': 78.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-944] due to args.save_total_limit
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 946/1200 [46:47<12:39,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 946/1200 [46:48<12:39,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-946
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-946/config.json
{'eval_loss': 2.8947999477386475, 'eval_f1': 0.5574479742900795, 'eval_runtime': 0.5118, 'eval_samples_per_second': 117.243, 'eval_steps_per_second': 5.862, 'epoch': 78.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-946/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-946/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-946/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-945] due to args.save_total_limit
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 947/1200 [46:51<12:59,  3.08s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 947/1200 [46:51<12:59,  3.08s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-947
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-947/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-947/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-947/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-947/special_tokens_map.json
{'eval_loss': 2.909127950668335, 'eval_f1': 0.5400854700854701, 'eval_runtime': 0.5084, 'eval_samples_per_second': 118.016, 'eval_steps_per_second': 5.901, 'epoch': 78.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-946] due to args.save_total_limit
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 948/1200 [46:54<12:48,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 948/1200 [46:54<12:48,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-948
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-948/config.json
{'eval_loss': 2.9162709712982178, 'eval_f1': 0.5400854700854701, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.697, 'eval_steps_per_second': 5.885, 'epoch': 79.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-948/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-948/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-948/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-947] due to args.save_total_limit
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 949/1200 [46:57<12:36,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 949/1200 [46:57<12:36,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-949
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-949/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-949/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-949/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-949/special_tokens_map.json
{'eval_loss': 2.924258232116699, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.73, 'eval_steps_per_second': 5.887, 'epoch': 79.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-948] due to args.save_total_limit
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                               | 950/1200 [46:59<12:25,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                               | 950/1200 [47:00<12:25,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-950
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-950/config.json
{'eval_loss': 2.9321694374084473, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5141, 'eval_samples_per_second': 116.704, 'eval_steps_per_second': 5.835, 'epoch': 79.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-950/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-950/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-950/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-949] due to args.save_total_limit
{'eval_loss': 2.935837507247925, 'eval_f1': 0.5221164021164021, 'eval_runtime': 0.5118, 'eval_samples_per_second': 117.233, 'eval_steps_per_second': 5.862, 'epoch': 79.25}
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 951/1200 [47:02<12:17,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 951/1200 [47:03<12:17,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-951
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-951/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-951/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-951/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-951/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-950] due to args.save_total_limit
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 952/1200 [47:05<12:21,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 952/1200 [47:06<12:21,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-952
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-952/config.json
{'eval_loss': 2.938269853591919, 'eval_f1': 0.5037037037037037, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.727, 'eval_steps_per_second': 5.886, 'epoch': 79.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-952/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-952/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-952/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-951] due to args.save_total_limit
{'eval_loss': 2.942608118057251, 'eval_f1': 0.5037037037037037, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.735, 'eval_steps_per_second': 5.887, 'epoch': 79.42}
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                               | 953/1200 [47:08<12:14,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                               | 953/1200 [47:09<12:14,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-953
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-953/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-953/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-953/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-953/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-952] due to args.save_total_limit
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 954/1200 [47:11<12:07,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 954/1200 [47:12<12:07,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-954
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-954/config.json
{'eval_loss': 2.9543776512145996, 'eval_f1': 0.4878306878306879, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.683, 'eval_steps_per_second': 5.884, 'epoch': 79.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-954/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-954/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-954/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-953] due to args.save_total_limit
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                               | 955/1200 [47:14<12:04,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 2.969399929046631, 'eval_f1': 0.501113421986933, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.464, 'eval_steps_per_second': 5.873, 'epoch': 79.58}
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                               | 955/1200 [47:15<12:04,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-955
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-955/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-955/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-955/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-955/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-954] due to args.save_total_limit
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 956/1200 [47:17<12:02,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 956/1200 [47:18<12:02,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-956
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-956/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-956/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-956/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-956/special_tokens_map.json
{'eval_loss': 2.9910004138946533, 'eval_f1': 0.501113421986933, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.7, 'eval_steps_per_second': 5.885, 'epoch': 79.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-955] due to args.save_total_limit
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 957/1200 [47:20<11:56,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.10it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-957/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-957/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-957/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-957/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-956] due to args.save_total_limit
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                              | 958/1200 [47:23<12:03,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                              | 958/1200 [47:24<12:03,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-958
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-958/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-958/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-958/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-958/special_tokens_map.json
{'eval_loss': 3.0160210132598877, 'eval_f1': 0.5194521265451498, 'eval_runtime': 0.5169, 'eval_samples_per_second': 116.067, 'eval_steps_per_second': 5.803, 'epoch': 79.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-957] due to args.save_total_limit
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 959/1200 [47:27<12:24,  3.09s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.025205135345459, 'eval_f1': 0.5194521265451498, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.675, 'eval_steps_per_second': 5.884, 'epoch': 79.92}
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 959/1200 [47:27<12:24,  3.09s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-959
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-959/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-959/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-959/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-959/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-958] due to args.save_total_limit
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 960/1200 [47:29<12:07,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 960/1200 [47:30<12:07,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-960
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-960/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-960/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-960/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-960/special_tokens_map.json
{'eval_loss': 3.031947612762451, 'eval_f1': 0.5194521265451498, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.4, 'eval_steps_per_second': 5.87, 'epoch': 80.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-959] due to args.save_total_limit
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 961/1200 [47:32<11:56,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.52it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-961/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-961/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-961/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-961/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-960] due to args.save_total_limit
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 962/1200 [47:35<11:48,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 962/1200 [47:36<11:48,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-962
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-962/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-962/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-962/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-962/special_tokens_map.json
{'eval_loss': 3.0283658504486084, 'eval_f1': 0.501113421986933, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.656, 'eval_steps_per_second': 5.883, 'epoch': 80.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-961] due to args.save_total_limit
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                              | 963/1200 [47:38<11:39,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                              | 963/1200 [47:39<11:39,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-963
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-963/config.json
{'eval_loss': 3.0358951091766357, 'eval_f1': 0.5038327526132403, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.824, 'eval_steps_per_second': 5.891, 'epoch': 80.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-963/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-963/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-963/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-962] due to args.save_total_limit
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 964/1200 [47:41<11:33,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 964/1200 [47:42<11:33,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-964
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-964/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-964/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-964/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-964/special_tokens_map.json
{'eval_loss': 3.04364013671875, 'eval_f1': 0.5038327526132403, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.565, 'eval_steps_per_second': 5.878, 'epoch': 80.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-963] due to args.save_total_limit
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                             | 965/1200 [47:44<11:34,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                             | 965/1200 [47:45<11:34,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-965
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-965/config.json
{'eval_loss': 3.041274309158325, 'eval_f1': 0.5236227824463119, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.644, 'eval_steps_per_second': 5.882, 'epoch': 80.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-965/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-965/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-965/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-964] due to args.save_total_limit
{'eval_loss': 3.031885862350464, 'eval_f1': 0.5236227824463119, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.561, 'eval_steps_per_second': 5.878, 'epoch': 80.5}
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 966/1200 [47:47<11:33,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 966/1200 [47:48<11:33,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-966
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-966/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-966/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-966/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-966/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-965] due to args.save_total_limit
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                             | 967/1200 [47:50<11:30,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                             | 967/1200 [47:51<11:30,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-967
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-967/config.json
{'eval_loss': 3.0180296897888184, 'eval_f1': 0.5236227824463119, 'eval_runtime': 0.5129, 'eval_samples_per_second': 116.985, 'eval_steps_per_second': 5.849, 'epoch': 80.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-967/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-967/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-967/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-966] due to args.save_total_limit
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 968/1200 [47:53<11:54,  3.08s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 968/1200 [47:54<11:54,  3.08s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-968
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-968/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-968/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-968/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-968/special_tokens_map.json
{'eval_loss': 2.995610237121582, 'eval_f1': 0.5397172822617419, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.79, 'eval_steps_per_second': 5.89, 'epoch': 80.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-967] due to args.save_total_limit
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 969/1200 [47:56<11:40,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 969/1200 [47:57<11:40,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-969
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-969/config.json
{'eval_loss': 2.9796793460845947, 'eval_f1': 0.538702147525677, 'eval_runtime': 0.5111, 'eval_samples_per_second': 117.394, 'eval_steps_per_second': 5.87, 'epoch': 80.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-969/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-969/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-969/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-968] due to args.save_total_limit
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                             | 970/1200 [47:59<11:31,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                             | 970/1200 [48:00<11:31,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-970
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-970/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-970/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-970/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-970/special_tokens_map.json
{'eval_loss': 2.969111442565918, 'eval_f1': 0.5250268345820713, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.367, 'eval_steps_per_second': 5.868, 'epoch': 80.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-969] due to args.save_total_limit
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 971/1200 [48:02<11:20,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 971/1200 [48:03<11:20,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-971
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-971/config.json
{'eval_loss': 2.9585037231445312, 'eval_f1': 0.5250268345820713, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.651, 'eval_steps_per_second': 5.883, 'epoch': 80.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-971/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-971/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-971/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-970] due to args.save_total_limit
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                             | 972/1200 [48:05<11:20,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                             | 972/1200 [48:06<11:20,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-972
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-972/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-972/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-972/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-972/special_tokens_map.json
{'eval_loss': 2.960324764251709, 'eval_f1': 0.5250268345820713, 'eval_runtime': 0.5128, 'eval_samples_per_second': 117.008, 'eval_steps_per_second': 5.85, 'epoch': 81.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-971] due to args.save_total_limit
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 973/1200 [48:09<11:42,  3.09s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-973/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-973/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-973/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-973/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-972] due to args.save_total_limit
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 974/1200 [48:11<11:31,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 974/1200 [48:12<11:31,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-974
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-974/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-974/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-974/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-974/special_tokens_map.json
{'eval_loss': 2.9953978061676025, 'eval_f1': 0.5381944444444445, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.558, 'eval_steps_per_second': 5.878, 'epoch': 81.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-973] due to args.save_total_limit
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 975/1200 [48:14<11:22,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 975/1200 [48:15<11:22,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-975
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-975/config.json
{'eval_loss': 3.0260519981384277, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.66, 'eval_steps_per_second': 5.883, 'epoch': 81.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-975/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-975/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-975/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-974] due to args.save_total_limit
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                            | 976/1200 [48:17<11:14,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                            | 976/1200 [48:18<11:14,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-976
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-976/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-976/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-976/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-976/special_tokens_map.json
{'eval_loss': 3.05123233795166, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.554, 'eval_steps_per_second': 5.878, 'epoch': 81.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-975] due to args.save_total_limit
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 977/1200 [48:20<11:13,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 977/1200 [48:21<11:13,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-977
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-977/config.json
{'eval_loss': 3.0863382816314697, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5091, 'eval_samples_per_second': 117.845, 'eval_steps_per_second': 5.892, 'epoch': 81.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-977/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-977/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-977/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-976] due to args.save_total_limit
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 978/1200 [48:23<11:03,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 978/1200 [48:24<11:03,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-978
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-978/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-978/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-978/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-978/special_tokens_map.json
{'eval_loss': 3.106842517852783, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5146, 'eval_samples_per_second': 116.595, 'eval_steps_per_second': 5.83, 'epoch': 81.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-977] due to args.save_total_limit
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 979/1200 [48:26<10:56,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 979/1200 [48:27<10:56,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-979
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-979/config.json
{'eval_loss': 3.1319422721862793, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5241, 'eval_samples_per_second': 114.479, 'eval_steps_per_second': 5.724, 'epoch': 81.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-979/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-979/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-979/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-978] due to args.save_total_limit
{'eval_loss': 3.1518850326538086, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.549, 'eval_steps_per_second': 5.877, 'epoch': 81.67}
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 980/1200 [48:29<10:54,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 980/1200 [48:30<10:54,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-980
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-980/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-980/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-980/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-980/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-979] due to args.save_total_limit
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                           | 981/1200 [48:32<10:53,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                           | 981/1200 [48:33<10:53,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-981
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-981/config.json
{'eval_loss': 3.1536061763763428, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5178, 'eval_samples_per_second': 115.867, 'eval_steps_per_second': 5.793, 'epoch': 81.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-981/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-981/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-981/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-980] due to args.save_total_limit
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 982/1200 [48:35<10:52,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 982/1200 [48:36<10:52,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-982
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-982/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-982/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-982/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-982/special_tokens_map.json
{'eval_loss': 3.161759614944458, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5132, 'eval_samples_per_second': 116.907, 'eval_steps_per_second': 5.845, 'epoch': 81.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-981] due to args.save_total_limit
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 983/1200 [48:38<10:44,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 983/1200 [48:39<10:44,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-983
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-983/config.json
{'eval_loss': 3.1583497524261475, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5142, 'eval_samples_per_second': 116.693, 'eval_steps_per_second': 5.835, 'epoch': 81.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-983/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-983/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-983/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-982] due to args.save_total_limit
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 984/1200 [48:41<10:41,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.154026508331299, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.5152, 'eval_samples_per_second': 116.462, 'eval_steps_per_second': 5.823, 'epoch': 82.0}
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 984/1200 [48:42<10:41,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-984
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-984/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-984/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-984/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-984/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-983] due to args.save_total_limit
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 985/1200 [48:44<10:40,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 985/1200 [48:45<10:40,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-985
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-985/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-985/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-985/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-985/special_tokens_map.json
{'eval_loss': 3.1407089233398438, 'eval_f1': 0.5666008771929825, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.639, 'eval_steps_per_second': 5.882, 'epoch': 82.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-984] due to args.save_total_limit
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                           | 986/1200 [48:47<10:35,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.54it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-986/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-986/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-986/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-986/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-985] due to args.save_total_limit
 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 987/1200 [48:50<10:31,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 987/1200 [48:51<10:31,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-987
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-987/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-987/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-987/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-987/special_tokens_map.json
{'eval_loss': 3.1078941822052, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5171, 'eval_samples_per_second': 116.036, 'eval_steps_per_second': 5.802, 'epoch': 82.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-986] due to args.save_total_limit
 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                          | 988/1200 [48:53<10:31,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                          | 988/1200 [48:54<10:31,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-988
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-988/config.json
{'eval_loss': 3.0834624767303467, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5137, 'eval_samples_per_second': 116.81, 'eval_steps_per_second': 5.841, 'epoch': 82.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-988/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-988/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-988/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-987] due to args.save_total_limit
 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 989/1200 [48:56<10:24,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 989/1200 [48:57<10:24,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-989
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-989/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-989/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-989/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-989/special_tokens_map.json
{'eval_loss': 3.0657739639282227, 'eval_f1': 0.5381944444444445, 'eval_runtime': 0.5153, 'eval_samples_per_second': 116.428, 'eval_steps_per_second': 5.821, 'epoch': 82.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-988] due to args.save_total_limit
 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 990/1200 [48:59<10:19,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-990/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-990/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-990/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-990/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-989] due to args.save_total_limit
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 991/1200 [49:02<10:15,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 991/1200 [49:02<10:15,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-991
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-991/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-991/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-991/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-991/special_tokens_map.json
{'eval_loss': 3.040067195892334, 'eval_f1': 0.5235653433661996, 'eval_runtime': 0.5144, 'eval_samples_per_second': 116.634, 'eval_steps_per_second': 5.832, 'epoch': 82.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-990] due to args.save_total_limit
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 992/1200 [49:05<10:10,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 992/1200 [49:05<10:10,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-992
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-992/config.json
{'eval_loss': 3.020775079727173, 'eval_f1': 0.5372368875086266, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.552, 'eval_steps_per_second': 5.878, 'epoch': 82.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-992/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-992/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-992/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-991] due to args.save_total_limit
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 993/1200 [49:08<10:30,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 993/1200 [49:09<10:30,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-993
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-993/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-993/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-993/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-993/special_tokens_map.json
{'eval_loss': 3.0034918785095215, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5178, 'eval_samples_per_second': 115.867, 'eval_steps_per_second': 5.793, 'epoch': 82.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-992] due to args.save_total_limit
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 994/1200 [49:11<10:21,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.53it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-994/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-994/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-994/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-994/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-993] due to args.save_total_limit
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 995/1200 [49:14<10:13,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 995/1200 [49:14<10:13,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-995
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-995/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-995/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-995/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-995/special_tokens_map.json
{'eval_loss': 2.9879021644592285, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.606, 'eval_steps_per_second': 5.88, 'epoch': 82.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-994] due to args.save_total_limit
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                         | 996/1200 [49:17<10:08,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                         | 996/1200 [49:17<10:08,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-996
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-996/config.json
{'eval_loss': 2.9837355613708496, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5129, 'eval_samples_per_second': 116.981, 'eval_steps_per_second': 5.849, 'epoch': 83.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-996/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-996/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-996/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-995] due to args.save_total_limit
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 997/1200 [49:20<10:04,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 997/1200 [49:20<10:04,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-997
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-997/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-997/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-997/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-997/special_tokens_map.json
{'eval_loss': 2.974226474761963, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.374, 'eval_steps_per_second': 5.869, 'epoch': 83.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-996] due to args.save_total_limit
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 998/1200 [49:23<09:58,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 998/1200 [49:23<09:58,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-998
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-998/config.json
{'eval_loss': 2.954214572906494, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5176, 'eval_samples_per_second': 115.925, 'eval_steps_per_second': 5.796, 'epoch': 83.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-998/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-998/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-998/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-997] due to args.save_total_limit
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 999/1200 [49:26<09:56,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 999/1200 [49:26<09:56,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-999
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-999/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-999/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-999/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-999/special_tokens_map.json
{'eval_loss': 2.9401261806488037, 'eval_f1': 0.5726787034104107, 'eval_runtime': 0.5151, 'eval_samples_per_second': 116.473, 'eval_steps_per_second': 5.824, 'epoch': 83.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-998] due to args.save_total_limit
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 1000/1200 [49:29<10:29,  3.15s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 1000/1200 [49:30<10:29,  3.15s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1000
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1000/config.json
{'loss': 0.1377, 'learning_rate': 3.3333333333333333e-06, 'epoch': 83.33}
{'eval_loss': 2.9299848079681396, 'eval_f1': 0.5696592508560745, 'eval_runtime': 0.5039, 'eval_samples_per_second': 119.079, 'eval_steps_per_second': 5.954, 'epoch': 83.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1000/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1000/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1000/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-999] due to args.save_total_limit
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 1001/1200 [49:32<10:11,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 1001/1200 [49:33<10:11,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1001
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1001/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1001/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1001/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1001/special_tokens_map.json
{'eval_loss': 2.913196325302124, 'eval_f1': 0.5528619528619529, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.369, 'eval_steps_per_second': 5.868, 'epoch': 83.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1000] due to args.save_total_limit
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                         | 1002/1200 [49:35<10:02,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.34it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1002/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1002/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1002/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1002/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1001] due to args.save_total_limit
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 1003/1200 [49:39<10:19,  3.15s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 1003/1200 [49:39<10:19,  3.15s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1003
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1003/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1003/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1003/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1003/special_tokens_map.json
{'eval_loss': 2.8892054557800293, 'eval_f1': 0.5528619528619529, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.697, 'eval_steps_per_second': 5.885, 'epoch': 83.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1002] due to args.save_total_limit
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                        | 1004/1200 [49:42<10:09,  3.11s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1004/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1004/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1004/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1004/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1003] due to args.save_total_limit
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 1005/1200 [49:45<09:55,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 1005/1200 [49:45<09:55,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1005
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1005/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1005/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1005/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1005/special_tokens_map.json
{'eval_loss': 2.861734628677368, 'eval_f1': 0.5528619528619529, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.509, 'eval_steps_per_second': 5.875, 'epoch': 83.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1004] due to args.save_total_limit
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 1006/1200 [49:47<09:43,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.46it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1006/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1006/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1006/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1006/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1005] due to args.save_total_limit
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                        | 1007/1200 [49:50<09:37,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                        | 1007/1200 [49:51<09:37,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1007
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1007/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1007/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1007/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1007/special_tokens_map.json
{'eval_loss': 2.8412678241729736, 'eval_f1': 0.5696592508560745, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.482, 'eval_steps_per_second': 5.874, 'epoch': 83.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1006] due to args.save_total_limit
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 1008/1200 [49:53<09:31,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 1008/1200 [49:54<09:31,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1008
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1008/config.json
{'eval_loss': 2.8384716510772705, 'eval_f1': 0.5696592508560745, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.759, 'eval_steps_per_second': 5.888, 'epoch': 84.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1008/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1008/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1008/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1007] due to args.save_total_limit
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                        | 1009/1200 [49:56<09:27,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                        | 1009/1200 [49:57<09:27,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1009
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1009/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1009/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1009/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1009/special_tokens_map.json
{'eval_loss': 2.833009958267212, 'eval_f1': 0.5696592508560745, 'eval_runtime': 0.5141, 'eval_samples_per_second': 116.718, 'eval_steps_per_second': 5.836, 'epoch': 84.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1008] due to args.save_total_limit
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 1010/1200 [49:59<09:21,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 1010/1200 [50:00<09:21,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1010
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1010/config.json
{'eval_loss': 2.8350448608398438, 'eval_f1': 0.5696592508560745, 'eval_runtime': 0.517, 'eval_samples_per_second': 116.05, 'eval_steps_per_second': 5.802, 'epoch': 84.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1010/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1010/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1010/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1009] due to args.save_total_limit
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 1011/1200 [50:02<09:21,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 1011/1200 [50:03<09:21,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1011
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1011/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1011/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1011/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1011/special_tokens_map.json
{'eval_loss': 2.84291934967041, 'eval_f1': 0.5696592508560745, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.49, 'eval_steps_per_second': 5.874, 'epoch': 84.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1010] due to args.save_total_limit
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 1012/1200 [50:06<09:39,  3.08s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 1012/1200 [50:06<09:39,  3.08s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1012
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1012/config.json
{'eval_loss': 2.8554961681365967, 'eval_f1': 0.5696592508560745, 'eval_runtime': 0.5168, 'eval_samples_per_second': 116.103, 'eval_steps_per_second': 5.805, 'epoch': 84.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1012/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1012/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1012/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1011] due to args.save_total_limit
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 1013/1200 [50:09<09:29,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 1013/1200 [50:09<09:29,  3.05s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1013
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1013/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1013/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1013/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1013/special_tokens_map.json
{'eval_loss': 2.8667027950286865, 'eval_f1': 0.5696592508560745, 'eval_runtime': 0.5117, 'eval_samples_per_second': 117.259, 'eval_steps_per_second': 5.863, 'epoch': 84.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1012] due to args.save_total_limit
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                       | 1014/1200 [50:12<09:29,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                       | 1014/1200 [50:12<09:29,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1014
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1014/config.json
{'eval_loss': 2.8765554428100586, 'eval_f1': 0.5696592508560745, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.706, 'eval_steps_per_second': 5.885, 'epoch': 84.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1014/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1014/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1014/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1013] due to args.save_total_limit
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 1015/1200 [50:15<09:21,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 1015/1200 [50:15<09:21,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1015
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1015/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1015/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1015/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1015/special_tokens_map.json
{'eval_loss': 2.8860580921173096, 'eval_f1': 0.5504245108896272, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.671, 'eval_steps_per_second': 5.884, 'epoch': 84.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1014] due to args.save_total_limit
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 1016/1200 [50:18<09:15,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.53it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1016/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1016/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1016/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1016/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1015] due to args.save_total_limit
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                       | 1017/1200 [50:21<09:07,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                       | 1017/1200 [50:21<09:07,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1017
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1017/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1017/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1017/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1017/special_tokens_map.json
{'eval_loss': 2.920309543609619, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.833, 'eval_steps_per_second': 5.842, 'epoch': 84.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1016] due to args.save_total_limit
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 1018/1200 [50:24<09:02,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 1018/1200 [50:24<09:02,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1018
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1018/config.json
{'eval_loss': 2.9372761249542236, 'eval_f1': 0.538702147525677, 'eval_runtime': 0.5183, 'eval_samples_per_second': 115.771, 'eval_steps_per_second': 5.789, 'epoch': 84.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1018/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1018/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1018/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1017] due to args.save_total_limit
{'eval_loss': 2.9495904445648193, 'eval_f1': 0.538702147525677, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.634, 'eval_steps_per_second': 5.882, 'epoch': 84.92}
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                      | 1019/1200 [50:26<08:59,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                      | 1019/1200 [50:27<08:59,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1019
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1019/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1019/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1019/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1019/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1018] due to args.save_total_limit
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 1020/1200 [50:29<08:51,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 1020/1200 [50:30<08:51,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1020
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1020/config.json
{'eval_loss': 2.973527431488037, 'eval_f1': 0.5250268345820713, 'eval_runtime': 0.5125, 'eval_samples_per_second': 117.071, 'eval_steps_per_second': 5.854, 'epoch': 85.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1020/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1020/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1020/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1019] due to args.save_total_limit
{'eval_loss': 2.9897491931915283, 'eval_f1': 0.5583924349881798, 'eval_runtime': 0.5118, 'eval_samples_per_second': 117.229, 'eval_steps_per_second': 5.861, 'epoch': 85.08}
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                      | 1021/1200 [50:32<08:51,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                      | 1021/1200 [50:33<08:51,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1021
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1021/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1021/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1021/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1021/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1020] due to args.save_total_limit
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 1022/1200 [50:35<08:48,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 1022/1200 [50:36<08:48,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1022
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1022/config.json
{'eval_loss': 3.0046534538269043, 'eval_f1': 0.5583924349881798, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.791, 'eval_steps_per_second': 5.89, 'epoch': 85.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1022/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1022/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1022/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1021] due to args.save_total_limit
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 1023/1200 [50:38<08:43,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.0144574642181396, 'eval_f1': 0.5728632478632479, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.686, 'eval_steps_per_second': 5.884, 'epoch': 85.25}
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 1023/1200 [50:39<08:43,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1023
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1023/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1023/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1023/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1023/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1022] due to args.save_total_limit
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                      | 1024/1200 [50:42<08:58,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                      | 1024/1200 [50:42<08:58,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1024
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1024/config.json
{'eval_loss': 3.028244972229004, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.798, 'eval_steps_per_second': 5.89, 'epoch': 85.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1024/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1024/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1024/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1023] due to args.save_total_limit
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 1025/1200 [50:44<08:47,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.0491225719451904, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.679, 'eval_steps_per_second': 5.884, 'epoch': 85.42}
 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 1025/1200 [50:45<08:47,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1025
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1025/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1025/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1025/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1025/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1024] due to args.save_total_limit
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 1026/1200 [50:47<08:38,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 1026/1200 [50:48<08:38,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1026
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1026/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1026/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1026/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1026/special_tokens_map.json
{'eval_loss': 3.0606226921081543, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.625, 'eval_steps_per_second': 5.881, 'epoch': 85.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1025] due to args.save_total_limit
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 1027/1200 [50:50<08:36,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1027/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1027/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1027/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1027/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1026] due to args.save_total_limit
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 1028/1200 [50:53<08:28,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 1028/1200 [50:54<08:28,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1028
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1028/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1028/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1028/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1028/special_tokens_map.json
{'eval_loss': 3.105830430984497, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.514, 'eval_samples_per_second': 116.739, 'eval_steps_per_second': 5.837, 'epoch': 85.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1027] due to args.save_total_limit
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 1029/1200 [50:56<08:24,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1029/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1029/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1029/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1029/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1028] due to args.save_total_limit
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 1030/1200 [50:59<08:21,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 1030/1200 [51:00<08:21,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1030
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1030/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1030/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1030/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1030/special_tokens_map.json
{'eval_loss': 3.161031484603882, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.557, 'eval_steps_per_second': 5.878, 'epoch': 85.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1029] due to args.save_total_limit
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 1031/1200 [51:02<08:19,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1031/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1031/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1031/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1031/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1030] due to args.save_total_limit
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 1032/1200 [51:05<08:18,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 1032/1200 [51:06<08:18,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1032
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1032/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1032/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1032/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1032/special_tokens_map.json
{'eval_loss': 3.1965596675872803, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5201, 'eval_samples_per_second': 115.359, 'eval_steps_per_second': 5.768, 'epoch': 86.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1031] due to args.save_total_limit
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 1033/1200 [51:08<08:16,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 1033/1200 [51:09<08:16,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1033
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1033/config.json
{'eval_loss': 3.214185953140259, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.681, 'eval_steps_per_second': 5.884, 'epoch': 86.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1033/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1033/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1033/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1032] due to args.save_total_limit
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 1034/1200 [51:11<08:12,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 1034/1200 [51:12<08:12,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1034
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1034/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1034/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1034/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1034/special_tokens_map.json
{'eval_loss': 3.2239458560943604, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.505, 'eval_steps_per_second': 5.875, 'epoch': 86.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1033] due to args.save_total_limit
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 1035/1200 [51:14<08:26,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 1035/1200 [51:15<08:26,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1035
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1035/config.json
{'eval_loss': 3.220529079437256, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.648, 'eval_steps_per_second': 5.882, 'epoch': 86.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1035/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1035/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1035/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1034] due to args.save_total_limit
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                    | 1036/1200 [51:17<08:16,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                    | 1036/1200 [51:18<08:16,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1036
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1036/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1036/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1036/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1036/special_tokens_map.json
{'eval_loss': 3.218493938446045, 'eval_f1': 0.5525259462759462, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.758, 'eval_steps_per_second': 5.888, 'epoch': 86.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1035] due to args.save_total_limit
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 1037/1200 [51:20<08:08,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.11it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1037/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1037/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1037/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1037/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1036] due to args.save_total_limit
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                    | 1038/1200 [51:23<08:06,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                    | 1038/1200 [51:24<08:06,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1038
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1038/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1038/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1038/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1038/special_tokens_map.json
{'eval_loss': 3.2160532474517822, 'eval_f1': 0.5668055555555556, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.459, 'eval_steps_per_second': 5.873, 'epoch': 86.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1037] due to args.save_total_limit
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 1039/1200 [51:26<08:00,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 1039/1200 [51:27<08:00,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1039
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1039/config.json
{'eval_loss': 3.220736503601074, 'eval_f1': 0.5521763103269332, 'eval_runtime': 0.5121, 'eval_samples_per_second': 117.173, 'eval_steps_per_second': 5.859, 'epoch': 86.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1039/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1039/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1039/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1038] due to args.save_total_limit
{'eval_loss': 3.2218031883239746, 'eval_f1': 0.5372368875086266, 'eval_runtime': 0.5113, 'eval_samples_per_second': 117.339, 'eval_steps_per_second': 5.867, 'epoch': 86.67}
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 1040/1200 [51:29<07:56,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 1040/1200 [51:30<07:56,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1040
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1040/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1040/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1040/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1040/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1039] due to args.save_total_limit
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                    | 1041/1200 [51:32<07:50,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                    | 1041/1200 [51:33<07:50,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1041
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1041/config.json
{'eval_loss': 3.2189414501190186, 'eval_f1': 0.5506427648578812, 'eval_runtime': 0.5138, 'eval_samples_per_second': 116.769, 'eval_steps_per_second': 5.838, 'epoch': 86.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1041/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1041/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1041/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1040] due to args.save_total_limit
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 1042/1200 [51:35<07:44,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.2169368267059326, 'eval_f1': 0.5506427648578812, 'eval_runtime': 0.5176, 'eval_samples_per_second': 115.911, 'eval_steps_per_second': 5.796, 'epoch': 86.83}
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 1042/1200 [51:35<07:44,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1042
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1042/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1042/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1042/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1042/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1041] due to args.save_total_limit
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                   | 1043/1200 [51:38<07:39,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                   | 1043/1200 [51:38<07:39,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1043
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1043/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1043/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1043/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1043/special_tokens_map.json
{'eval_loss': 3.211930990219116, 'eval_f1': 0.5506427648578812, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.837, 'eval_steps_per_second': 5.892, 'epoch': 86.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1042] due to args.save_total_limit
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 1044/1200 [51:41<07:39,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.1980292797088623, 'eval_f1': 0.5710594315245477, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.053, 'eval_steps_per_second': 5.853, 'epoch': 87.0}
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 1044/1200 [51:41<07:39,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1044
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1044/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1044/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1044/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1044/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1043] due to args.save_total_limit
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 1045/1200 [51:44<07:35,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 1045/1200 [51:44<07:35,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1045
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1045/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1045/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1045/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1045/special_tokens_map.json
{'eval_loss': 3.18284010887146, 'eval_f1': 0.5710594315245477, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.443, 'eval_steps_per_second': 5.872, 'epoch': 87.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1044] due to args.save_total_limit
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                   | 1046/1200 [51:47<07:37,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1046/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1046/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1046/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1046/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1045] due to args.save_total_limit
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 1047/1200 [51:50<07:33,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 1047/1200 [51:50<07:33,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1047
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1047/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1047/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1047/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1047/special_tokens_map.json
{'eval_loss': 3.1711537837982178, 'eval_f1': 0.5723279304674652, 'eval_runtime': 0.5185, 'eval_samples_per_second': 115.729, 'eval_steps_per_second': 5.786, 'epoch': 87.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1046] due to args.save_total_limit
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                   | 1048/1200 [51:53<07:30,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.51it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1048/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1048/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1048/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1048/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1047] due to args.save_total_limit
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 1049/1200 [51:56<07:25,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 1049/1200 [51:56<07:25,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1049
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1049/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1049/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1049/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1049/special_tokens_map.json
{'eval_loss': 3.1566336154937744, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5158, 'eval_samples_per_second': 116.315, 'eval_steps_per_second': 5.816, 'epoch': 87.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1048] due to args.save_total_limit
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                  | 1050/1200 [51:59<07:21,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                  | 1050/1200 [51:59<07:21,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1050
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1050/config.json
{'eval_loss': 3.1479971408843994, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.754, 'eval_steps_per_second': 5.888, 'epoch': 87.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1050/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1050/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1050/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1049] due to args.save_total_limit
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 1051/1200 [52:02<07:23,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 1051/1200 [52:02<07:23,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1051
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1051/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1051/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1051/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1051/special_tokens_map.json
{'eval_loss': 3.142263889312744, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.738, 'eval_steps_per_second': 5.887, 'epoch': 87.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1050] due to args.save_total_limit
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 1052/1200 [52:05<07:18,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 1052/1200 [52:05<07:18,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1052
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1052/config.json
{'eval_loss': 3.1346724033355713, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.69, 'eval_steps_per_second': 5.885, 'epoch': 87.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1052/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1052/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1052/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1051] due to args.save_total_limit
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 1053/1200 [52:08<07:29,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 1053/1200 [52:08<07:29,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1053
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1053/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1053/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1053/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1053/special_tokens_map.json
{'eval_loss': 3.1155245304107666, 'eval_f1': 0.5532043120278414, 'eval_runtime': 0.5115, 'eval_samples_per_second': 117.3, 'eval_steps_per_second': 5.865, 'epoch': 87.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1052] due to args.save_total_limit
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                  | 1054/1200 [52:11<07:19,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1054/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1054/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1054/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1054/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1053] due to args.save_total_limit
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 1055/1200 [52:14<07:15,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 1055/1200 [52:14<07:15,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1055
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1055/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1055/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1055/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1055/special_tokens_map.json
{'eval_loss': 3.105018138885498, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5172, 'eval_samples_per_second': 115.999, 'eval_steps_per_second': 5.8, 'epoch': 87.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1054] due to args.save_total_limit
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 1056/1200 [52:17<07:09,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 1056/1200 [52:17<07:09,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1056
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1056/config.json
{'eval_loss': 3.1038193702697754, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5113, 'eval_samples_per_second': 117.348, 'eval_steps_per_second': 5.867, 'epoch': 88.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1056/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1056/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1056/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1055] due to args.save_total_limit
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                  | 1057/1200 [52:20<07:09,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                  | 1057/1200 [52:20<07:09,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1057
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1057/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1057/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1057/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1057/special_tokens_map.json
{'eval_loss': 3.0930027961730957, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.612, 'eval_steps_per_second': 5.881, 'epoch': 88.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1056] due to args.save_total_limit
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 1058/1200 [52:23<07:02,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 1058/1200 [52:23<07:02,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1058
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1058/config.json
{'eval_loss': 3.0878164768218994, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.569, 'eval_steps_per_second': 5.878, 'epoch': 88.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1058/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1058/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1058/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1057] due to args.save_total_limit
{'eval_loss': 3.0821845531463623, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5134, 'eval_samples_per_second': 116.874, 'eval_steps_per_second': 5.844, 'epoch': 88.25}
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 1059/1200 [52:26<06:58,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 1059/1200 [52:26<06:58,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1059
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1059/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1059/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1059/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1059/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1058] due to args.save_total_limit
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 1060/1200 [52:29<06:54,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 1060/1200 [52:29<06:54,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1060
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1060/config.json
{'eval_loss': 3.077740430831909, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.042, 'eval_steps_per_second': 5.852, 'epoch': 88.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1060/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1060/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1060/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1059] due to args.save_total_limit
{'eval_loss': 3.0741641521453857, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.756, 'eval_steps_per_second': 5.888, 'epoch': 88.42}
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 1061/1200 [52:31<06:52,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 1061/1200 [52:32<06:52,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1061
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1061/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1061/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1061/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1061/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1060] due to args.save_total_limit
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                 | 1062/1200 [52:34<06:46,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                 | 1062/1200 [52:35<06:46,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1062
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1062/config.json
{'eval_loss': 3.063701868057251, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5116, 'eval_samples_per_second': 117.277, 'eval_steps_per_second': 5.864, 'epoch': 88.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1062/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1062/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1062/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1061] due to args.save_total_limit
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 1063/1200 [52:37<06:46,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.065730571746826, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.513, 'eval_samples_per_second': 116.965, 'eval_steps_per_second': 5.848, 'epoch': 88.58}
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 1063/1200 [52:38<06:46,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1063
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1063/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1063/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1063/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1063/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1062] due to args.save_total_limit
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                 | 1064/1200 [52:40<06:42,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                 | 1064/1200 [52:41<06:42,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1064
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1064/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1064/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1064/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1064/special_tokens_map.json
{'eval_loss': 3.0662286281585693, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5119, 'eval_samples_per_second': 117.2, 'eval_steps_per_second': 5.86, 'epoch': 88.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1063] due to args.save_total_limit
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 1065/1200 [52:43<06:40,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1065/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1065/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1065/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1065/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1064] due to args.save_total_limit
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 1066/1200 [52:47<06:51,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 1066/1200 [52:47<06:51,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1066
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1066/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1066/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1066/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1066/special_tokens_map.json
{'eval_loss': 3.058035373687744, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.696, 'eval_steps_per_second': 5.885, 'epoch': 88.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1065] due to args.save_total_limit
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 1067/1200 [52:50<06:44,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1067/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1067/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1067/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1067/special_tokens_map.json
{'eval_loss': 3.050243616104126, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.697, 'eval_steps_per_second': 5.885, 'epoch': 88.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1066] due to args.save_total_limit
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 1068/1200 [52:53<06:39,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 1068/1200 [52:53<06:39,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1068
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1068/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1068/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1068/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1068/special_tokens_map.json
{'eval_loss': 3.0427489280700684, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.589, 'eval_steps_per_second': 5.879, 'epoch': 89.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1067] due to args.save_total_limit
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                | 1069/1200 [52:56<06:33,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.53it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1069/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1069/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1069/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1069/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1068] due to args.save_total_limit
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 1070/1200 [52:59<06:41,  3.09s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 1070/1200 [52:59<06:41,  3.09s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1070
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1070/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1070/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1070/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1070/special_tokens_map.json
{'eval_loss': 3.0214788913726807, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.704, 'eval_steps_per_second': 5.885, 'epoch': 89.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1069] due to args.save_total_limit
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 1071/1200 [53:02<06:32,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1071/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1071/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1071/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1071/special_tokens_map.json
{'eval_loss': 3.013066530227661, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.508, 'eval_steps_per_second': 5.875, 'epoch': 89.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1070] due to args.save_total_limit
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 1072/1200 [53:05<06:25,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 1072/1200 [53:05<06:25,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1072
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1072/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1072/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1072/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1072/special_tokens_map.json
{'eval_loss': 3.0055456161499023, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5128, 'eval_samples_per_second': 117.0, 'eval_steps_per_second': 5.85, 'epoch': 89.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1071] due to args.save_total_limit
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 1073/1200 [53:08<06:21,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 1073/1200 [53:08<06:21,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1073
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1073/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1073/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1073/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1073/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1072] due to args.save_total_limit
{'eval_loss': 2.9900927543640137, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.541, 'eval_steps_per_second': 5.877, 'epoch': 89.42}
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 1074/1200 [53:11<06:18,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 1074/1200 [53:11<06:18,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1074
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1074/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1074/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1074/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1074/special_tokens_map.json
{'eval_loss': 2.97683048248291, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5159, 'eval_samples_per_second': 116.302, 'eval_steps_per_second': 5.815, 'epoch': 89.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1073] due to args.save_total_limit
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 1075/1200 [53:14<06:15,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 1075/1200 [53:14<06:15,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1075
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1075/config.json
{'eval_loss': 2.9673333168029785, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5127, 'eval_samples_per_second': 117.026, 'eval_steps_per_second': 5.851, 'epoch': 89.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1075/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1075/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1075/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1074] due to args.save_total_limit
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 1076/1200 [53:17<06:12,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 1076/1200 [53:17<06:12,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1076
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1076/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1076/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1076/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1076/special_tokens_map.json
{'eval_loss': 2.9591071605682373, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.737, 'eval_steps_per_second': 5.887, 'epoch': 89.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1075] due to args.save_total_limit
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 1077/1200 [53:20<06:06,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 1077/1200 [53:20<06:06,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1077
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1077/config.json
{'eval_loss': 2.9541172981262207, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.823, 'eval_steps_per_second': 5.891, 'epoch': 89.75}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1077/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1077/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1077/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1076] due to args.save_total_limit
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 1078/1200 [53:23<06:02,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 1078/1200 [53:23<06:02,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1078
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1078/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1078/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1078/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1078/special_tokens_map.json
{'eval_loss': 2.949425458908081, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5139, 'eval_samples_per_second': 116.765, 'eval_steps_per_second': 5.838, 'epoch': 89.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1077] due to args.save_total_limit
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 1079/1200 [53:25<05:57,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 1079/1200 [53:26<05:57,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1079
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1079/config.json
{'eval_loss': 2.9458110332489014, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5133, 'eval_samples_per_second': 116.889, 'eval_steps_per_second': 5.844, 'epoch': 89.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1079/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1079/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1079/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1078] due to args.save_total_limit
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 1080/1200 [53:28<05:53,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 1080/1200 [53:29<05:53,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1080
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1080/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1080/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1080/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1080/special_tokens_map.json
{'eval_loss': 2.9336965084075928, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5132, 'eval_samples_per_second': 116.905, 'eval_steps_per_second': 5.845, 'epoch': 90.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1079] due to args.save_total_limit
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 1081/1200 [53:31<05:49,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 1081/1200 [53:32<05:49,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1081
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1081/config.json
{'eval_loss': 2.923295736312866, 'eval_f1': 0.5495016611295681, 'eval_runtime': 0.5196, 'eval_samples_per_second': 115.466, 'eval_steps_per_second': 5.773, 'epoch': 90.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1081/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1081/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1081/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1080] due to args.save_total_limit
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 1082/1200 [53:34<05:48,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 1082/1200 [53:35<05:48,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1082
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1082/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1082/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1082/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1082/special_tokens_map.json
{'eval_loss': 2.910163402557373, 'eval_f1': 0.5495016611295681, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.443, 'eval_steps_per_second': 5.872, 'epoch': 90.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1081] due to args.save_total_limit
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 1083/1200 [53:37<05:48,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 1083/1200 [53:38<05:48,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1083
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1083/config.json
{'eval_loss': 2.89247465133667, 'eval_f1': 0.5495016611295681, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.473, 'eval_steps_per_second': 5.874, 'epoch': 90.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1083/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1083/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1083/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1082] due to args.save_total_limit
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 1084/1200 [53:40<05:47,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 1084/1200 [53:41<05:47,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1084
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1084/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1084/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1084/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1084/special_tokens_map.json
{'eval_loss': 2.880335569381714, 'eval_f1': 0.5495016611295681, 'eval_runtime': 0.515, 'eval_samples_per_second': 116.512, 'eval_steps_per_second': 5.826, 'epoch': 90.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1083] due to args.save_total_limit
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 1085/1200 [53:43<05:47,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 1085/1200 [53:44<05:47,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1085
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1085/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1085/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1085/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1085/special_tokens_map.json
{'eval_loss': 2.873867988586426, 'eval_f1': 0.5495016611295681, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.633, 'eval_steps_per_second': 5.882, 'epoch': 90.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1084] due to args.save_total_limit
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 1086/1200 [53:46<05:41,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1086/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1086/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1086/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1086/special_tokens_map.json
{'eval_loss': 2.870128870010376, 'eval_f1': 0.5685185185185185, 'eval_runtime': 0.5098, 'eval_samples_per_second': 117.692, 'eval_steps_per_second': 5.885, 'epoch': 90.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1085] due to args.save_total_limit
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 1087/1200 [53:49<05:35,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 1087/1200 [53:50<05:35,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1087
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1087/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1087/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1087/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1087/special_tokens_map.json
{'eval_loss': 2.869373083114624, 'eval_f1': 0.5685185185185185, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.708, 'eval_steps_per_second': 5.885, 'epoch': 90.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1086] due to args.save_total_limit
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 1088/1200 [53:52<05:32,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1088/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1088/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1088/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1088/special_tokens_map.json
{'eval_loss': 2.868999481201172, 'eval_f1': 0.5685185185185185, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.624, 'eval_steps_per_second': 5.881, 'epoch': 90.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1087] due to args.save_total_limit
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████              | 1089/1200 [53:55<05:29,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████              | 1089/1200 [53:56<05:29,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1089
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1089/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1089/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1089/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1089/special_tokens_map.json
{'eval_loss': 2.869534492492676, 'eval_f1': 0.5685185185185185, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.524, 'eval_steps_per_second': 5.876, 'epoch': 90.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1088] due to args.save_total_limit
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 1090/1200 [53:58<05:25,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1090/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1090/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1090/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1090/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1089] due to args.save_total_limit
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 1091/1200 [54:01<05:33,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 1091/1200 [54:02<05:33,  3.06s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1091
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1091/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1091/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1091/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1091/special_tokens_map.json
{'eval_loss': 2.86812686920166, 'eval_f1': 0.5685185185185185, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.777, 'eval_steps_per_second': 5.889, 'epoch': 90.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1090] due to args.save_total_limit
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 1092/1200 [54:04<05:26,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1092/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1092/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1092/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1092/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1091] due to args.save_total_limit
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 1093/1200 [54:08<05:33,  3.11s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 1093/1200 [54:08<05:33,  3.11s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1093
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1093/config.json
{'eval_loss': 2.873178005218506, 'eval_f1': 0.5685185185185185, 'eval_runtime': 0.5169, 'eval_samples_per_second': 116.08, 'eval_steps_per_second': 5.804, 'epoch': 91.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1093/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1093/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1093/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1092] due to args.save_total_limit
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 1094/1200 [54:11<05:24,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 1094/1200 [54:11<05:24,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1094
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1094/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1094/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1094/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1094/special_tokens_map.json
{'eval_loss': 2.8840622901916504, 'eval_f1': 0.5685185185185185, 'eval_runtime': 0.5185, 'eval_samples_per_second': 115.721, 'eval_steps_per_second': 5.786, 'epoch': 91.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1093] due to args.save_total_limit
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 1095/1200 [54:14<05:17,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 1095/1200 [54:14<05:17,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1095
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1095/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1095/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1095/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1095/special_tokens_map.json
{'eval_loss': 2.8947553634643555, 'eval_f1': 0.5495016611295681, 'eval_runtime': 0.5159, 'eval_samples_per_second': 116.292, 'eval_steps_per_second': 5.815, 'epoch': 91.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1094] due to args.save_total_limit
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉             | 1096/1200 [54:17<05:11,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.54it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1096/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1096/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1096/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1096/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1095] due to args.save_total_limit
{'eval_loss': 2.922089099884033, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.578, 'eval_steps_per_second': 5.879, 'epoch': 91.42}
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 1097/1200 [54:19<05:06,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 1097/1200 [54:20<05:06,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1097
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1097/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1097/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1097/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1097/special_tokens_map.json
{'eval_loss': 2.9402666091918945, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.746, 'eval_steps_per_second': 5.887, 'epoch': 91.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1096] due to args.save_total_limit
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 1098/1200 [54:22<05:02,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 1098/1200 [54:23<05:02,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1098
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1098/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1098/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1098/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1098/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1097] due to args.save_total_limit
{'eval_loss': 2.9587364196777344, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.504, 'eval_steps_per_second': 5.875, 'epoch': 91.58}
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 1099/1200 [54:25<04:58,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 1099/1200 [54:26<04:58,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1099
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1099/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1099/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1099/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1099/special_tokens_map.json
{'eval_loss': 2.9746315479278564, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.66, 'eval_steps_per_second': 5.883, 'epoch': 91.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1098] due to args.save_total_limit
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 1100/1200 [54:28<04:55,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 1100/1200 [54:29<04:55,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1100
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1100/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1100/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1100/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1100/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1099] due to args.save_total_limit
{'eval_loss': 2.9936625957489014, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.578, 'eval_steps_per_second': 5.879, 'epoch': 91.75}
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌            | 1101/1200 [54:31<04:54,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌            | 1101/1200 [54:32<04:54,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1101
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1101/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1101/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1101/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1101/special_tokens_map.json
{'eval_loss': 3.0179433822631836, 'eval_f1': 0.5680672268907563, 'eval_runtime': 0.5116, 'eval_samples_per_second': 117.268, 'eval_steps_per_second': 5.863, 'epoch': 91.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1100] due to args.save_total_limit
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 1102/1200 [54:34<04:49,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 1102/1200 [54:35<04:49,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1102
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1102/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1102/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1102/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1102/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1101] due to args.save_total_limit
{'eval_loss': 3.0405237674713135, 'eval_f1': 0.5680672268907563, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.712, 'eval_steps_per_second': 5.886, 'epoch': 91.92}
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 1103/1200 [54:37<04:46,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 1103/1200 [54:38<04:46,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1103
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1103/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1103/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1103/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1103/special_tokens_map.json
{'eval_loss': 3.057274341583252, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.674, 'eval_steps_per_second': 5.884, 'epoch': 92.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1102] due to args.save_total_limit
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 1104/1200 [54:40<04:42,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 1104/1200 [54:41<04:42,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1104
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1104/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1104/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1104/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1104/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1103] due to args.save_total_limit
{'eval_loss': 3.070298671722412, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.626, 'eval_steps_per_second': 5.881, 'epoch': 92.08}
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 1105/1200 [54:43<04:40,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 1105/1200 [54:44<04:40,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1105
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1105/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1105/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1105/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1105/special_tokens_map.json
{'eval_loss': 3.08205509185791, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5185, 'eval_samples_per_second': 115.714, 'eval_steps_per_second': 5.786, 'epoch': 92.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1104] due to args.save_total_limit
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏           | 1106/1200 [54:46<04:36,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏           | 1106/1200 [54:47<04:36,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1106
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1106/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1106/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1106/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1106/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1105] due to args.save_total_limit
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 1107/1200 [54:49<04:36,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1107/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1107/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1107/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1107/special_tokens_map.json
{'eval_loss': 3.089416742324829, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.514, 'eval_samples_per_second': 116.74, 'eval_steps_per_second': 5.837, 'epoch': 92.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1106] due to args.save_total_limit
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 1108/1200 [54:52<04:32,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 1108/1200 [54:52<04:32,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1108
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1108/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1108/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1108/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1108/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1107] due to args.save_total_limit
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 1109/1200 [54:55<04:30,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.15it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1109/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1109/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1109/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1109/special_tokens_map.json
{'eval_loss': 3.0921850204467773, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.55, 'eval_steps_per_second': 5.877, 'epoch': 92.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1108] due to args.save_total_limit
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 1110/1200 [54:58<04:26,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 1110/1200 [54:58<04:26,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1110
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1110/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1110/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1110/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1110/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1109] due to args.save_total_limit
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 1111/1200 [55:01<04:32,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1111/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1111/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1111/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1111/special_tokens_map.json
{'eval_loss': 3.095283269882202, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5105, 'eval_samples_per_second': 117.538, 'eval_steps_per_second': 5.877, 'epoch': 92.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1110] due to args.save_total_limit
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 1112/1200 [55:04<04:27,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 1112/1200 [55:05<04:27,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1112
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1112/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1112/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1112/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1112/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1111] due to args.save_total_limit
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 1113/1200 [55:07<04:23,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1113/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1113/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1113/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1113/special_tokens_map.json
{'eval_loss': 3.1077020168304443, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.577, 'eval_steps_per_second': 5.879, 'epoch': 92.83}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1112] due to args.save_total_limit
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 1114/1200 [55:10<04:19,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 1114/1200 [55:11<04:19,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1114
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1114/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1114/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1114/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1114/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1113] due to args.save_total_limit
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 1115/1200 [55:13<04:14,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 1115/1200 [55:14<04:14,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1115
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1115/config.json
{'eval_loss': 3.112396001815796, 'eval_f1': 0.5658773291925466, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.464, 'eval_steps_per_second': 5.873, 'epoch': 92.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1115/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1115/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1115/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1114] due to args.save_total_limit
{'eval_loss': 3.11601185798645, 'eval_f1': 0.5807872772876667, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.508, 'eval_steps_per_second': 5.875, 'epoch': 93.0}
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 1116/1200 [55:16<04:12,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 1116/1200 [55:17<04:12,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1116
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1116/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1116/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1116/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1116/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1115] due to args.save_total_limit
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 1117/1200 [55:19<04:08,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 1117/1200 [55:20<04:08,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1117
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1117/config.json
{'eval_loss': 3.115778684616089, 'eval_f1': 0.5807872772876667, 'eval_runtime': 0.5096, 'eval_samples_per_second': 117.75, 'eval_steps_per_second': 5.887, 'epoch': 93.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1117/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1117/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1117/special_tokens_map.json
{'eval_loss': 3.115424394607544, 'eval_f1': 0.5807872772876667, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.639, 'eval_steps_per_second': 5.882, 'epoch': 93.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1116] due to args.save_total_limit
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 1118/1200 [55:22<04:05,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 1118/1200 [55:23<04:05,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1118
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1118/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1118/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1118/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1118/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1117] due to args.save_total_limit
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 1119/1200 [55:25<04:02,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1119/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1119/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1119/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1119/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1118] due to args.save_total_limit
{'eval_loss': 3.111963987350464, 'eval_f1': 0.5807872772876667, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.592, 'eval_steps_per_second': 5.88, 'epoch': 93.33}
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 1120/1200 [55:28<03:57,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 1120/1200 [55:29<03:57,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1120
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1120/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1120/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1120/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1120/special_tokens_map.json
{'eval_loss': 3.1073386669158936, 'eval_f1': 0.5807872772876667, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.04, 'eval_steps_per_second': 5.852, 'epoch': 93.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1119] due to args.save_total_limit
 93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 1121/1200 [55:31<03:55,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 1121/1200 [55:32<03:55,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1121
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1121/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1121/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1121/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1121/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1120] due to args.save_total_limit
{'eval_loss': 3.1033976078033447, 'eval_f1': 0.5807872772876667, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.43, 'eval_steps_per_second': 5.871, 'epoch': 93.5}
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 1122/1200 [55:34<03:51,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 1122/1200 [55:34<03:51,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1122
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1122/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1122/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1122/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1122/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1121] due to args.save_total_limit
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 1123/1200 [55:37<03:48,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 1123/1200 [55:37<03:48,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1123
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1123/config.json
{'eval_loss': 3.098093271255493, 'eval_f1': 0.5807872772876667, 'eval_runtime': 0.5126, 'eval_samples_per_second': 117.039, 'eval_steps_per_second': 5.852, 'epoch': 93.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1123/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1123/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1123/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1122] due to args.save_total_limit
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 1124/1200 [55:40<03:44,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.094825029373169, 'eval_f1': 0.6015081889949335, 'eval_runtime': 0.5156, 'eval_samples_per_second': 116.369, 'eval_steps_per_second': 5.818, 'epoch': 93.67}
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 1124/1200 [55:40<03:44,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1124
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1124/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1124/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1124/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1124/special_tokens_map.json
{'eval_loss': 3.090289354324341, 'eval_f1': 0.6015081889949335, 'eval_runtime': 0.5114, 'eval_samples_per_second': 117.32, 'eval_steps_per_second': 5.866, 'epoch': 93.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1123] due to args.save_total_limit
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 1125/1200 [55:43<03:41,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 1125/1200 [55:43<03:41,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1125
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1125/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1125/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1125/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1125/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1124] due to args.save_total_limit
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 1126/1200 [55:46<03:38,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.55it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1126/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1126/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1126/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1126/special_tokens_map.json
{'eval_loss': 3.076718807220459, 'eval_f1': 0.6015081889949335, 'eval_runtime': 0.5231, 'eval_samples_per_second': 114.709, 'eval_steps_per_second': 5.735, 'epoch': 93.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1125] due to args.save_total_limit
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 1127/1200 [55:49<03:34,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 1127/1200 [55:49<03:34,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1127
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1127/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1127/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1127/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1127/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1126] due to args.save_total_limit
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 1128/1200 [55:52<03:40,  3.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1128/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1128/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1128/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1128/special_tokens_map.json
{'eval_loss': 3.06811261177063, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5078, 'eval_samples_per_second': 118.157, 'eval_steps_per_second': 5.908, 'epoch': 94.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1127] due to args.save_total_limit
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 1129/1200 [55:55<03:33,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 1129/1200 [55:55<03:33,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1129
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1129/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1129/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1129/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1129/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1128] due to args.save_total_limit
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 1130/1200 [55:58<03:28,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.0644590854644775, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.666, 'eval_steps_per_second': 5.883, 'epoch': 94.17}
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 1130/1200 [55:58<03:28,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1130
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1130/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1130/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1130/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1130/special_tokens_map.json
{'eval_loss': 3.061492443084717, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.754, 'eval_steps_per_second': 5.888, 'epoch': 94.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1129] due to args.save_total_limit
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 1131/1200 [56:01<03:25,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 1131/1200 [56:01<03:25,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1131
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1131/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1131/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1131/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1131/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1130] due to args.save_total_limit
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 1132/1200 [56:04<03:20,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.56it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1132/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1132/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1132/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1132/special_tokens_map.json
{'eval_loss': 3.0542261600494385, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.374, 'eval_steps_per_second': 5.869, 'epoch': 94.42}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1131] due to args.save_total_limit
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 1133/1200 [56:07<03:16,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 1133/1200 [56:07<03:16,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1133
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1133/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1133/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1133/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1133/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1132] due to args.save_total_limit
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 1134/1200 [56:10<03:20,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1134/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1134/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1134/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1134/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1133] due to args.save_total_limit
{'eval_loss': 3.0527429580688477, 'eval_f1': 0.5680672268907563, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.589, 'eval_steps_per_second': 5.879, 'epoch': 94.58}
 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 1135/1200 [56:13<03:15,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 1135/1200 [56:13<03:15,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1135
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1135/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1135/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1135/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1135/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1134] due to args.save_total_limit
 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 1136/1200 [56:16<03:11,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 1136/1200 [56:16<03:11,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1136
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1136/config.json
{'eval_loss': 3.053213596343994, 'eval_f1': 0.5680672268907563, 'eval_runtime': 0.5147, 'eval_samples_per_second': 116.566, 'eval_steps_per_second': 5.828, 'epoch': 94.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1136/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1136/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1136/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1135] due to args.save_total_limit
{'eval_loss': 3.0538036823272705, 'eval_f1': 0.5680672268907563, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.415, 'eval_steps_per_second': 5.871, 'epoch': 94.75}
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 1137/1200 [56:19<03:07,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 1137/1200 [56:19<03:07,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1137
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1137/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1137/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1137/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1137/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1136] due to args.save_total_limit
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 1138/1200 [56:22<03:03,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 1138/1200 [56:22<03:03,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1138
{'eval_loss': 3.0595343112945557, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5142, 'eval_samples_per_second': 116.686, 'eval_steps_per_second': 5.834, 'epoch': 94.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1138/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1138/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1138/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1137] due to args.save_total_limit
{'eval_loss': 3.0646095275878906, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.829, 'eval_steps_per_second': 5.841, 'epoch': 94.92}
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 1139/1200 [56:25<03:01,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 1139/1200 [56:25<03:01,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1139
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1139/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1139/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1139/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1139/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1138] due to args.save_total_limit
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 1140/1200 [56:28<02:59,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 1140/1200 [56:28<02:59,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1140
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1140/config.json
{'eval_loss': 3.0694782733917236, 'eval_f1': 0.5680672268907563, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.464, 'eval_steps_per_second': 5.873, 'epoch': 95.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1140/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1140/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1140/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1139] due to args.save_total_limit
{'eval_loss': 3.0729475021362305, 'eval_f1': 0.5680672268907563, 'eval_runtime': 0.5164, 'eval_samples_per_second': 116.194, 'eval_steps_per_second': 5.81, 'epoch': 95.08}
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 1141/1200 [56:31<02:55,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 1141/1200 [56:31<02:55,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1141
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1141/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1141/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1141/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1141/special_tokens_map.json
{'eval_loss': 3.074692726135254, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.633, 'eval_steps_per_second': 5.882, 'epoch': 95.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1140] due to args.save_total_limit
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 1142/1200 [56:34<02:53,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 1142/1200 [56:34<02:53,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1142
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1142/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1142/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1142/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1142/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1141] due to args.save_total_limit
{'eval_loss': 3.0778231620788574, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.615, 'eval_steps_per_second': 5.881, 'epoch': 95.25}
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 1143/1200 [56:37<02:49,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 1143/1200 [56:37<02:49,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1143
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1143/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1143/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1143/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1143/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1142] due to args.save_total_limit
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 1144/1200 [56:39<02:45,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 1144/1200 [56:40<02:45,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1144
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1144/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1144/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1144/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1144/special_tokens_map.json
{'eval_loss': 3.0791239738464355, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.605, 'eval_steps_per_second': 5.88, 'epoch': 95.33}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1143] due to args.save_total_limit
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 1145/1200 [56:42<02:42,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1145/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1145/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1145/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1145/special_tokens_map.json
{'eval_loss': 3.086413621902466, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5194, 'eval_samples_per_second': 115.522, 'eval_steps_per_second': 5.776, 'epoch': 95.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1144] due to args.save_total_limit
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 1146/1200 [56:45<02:39,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 1146/1200 [56:46<02:39,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1146
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1146/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1146/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1146/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1146/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1145] due to args.save_total_limit
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎      | 1147/1200 [56:48<02:35,  2.93s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.0897018909454346, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.51, 'eval_samples_per_second': 117.657, 'eval_steps_per_second': 5.883, 'epoch': 95.58}
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎      | 1147/1200 [56:49<02:35,  2.93s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1147
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1147/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1147/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1147/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1147/special_tokens_map.json
{'eval_loss': 3.0956976413726807, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.677, 'eval_steps_per_second': 5.884, 'epoch': 95.67}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1146] due to args.save_total_limit
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 1148/1200 [56:51<02:32,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 1148/1200 [56:52<02:32,  2.94s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1148
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1148/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1148/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1148/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1148/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1147] due to args.save_total_limit
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 1149/1200 [56:54<02:29,  2.94s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.54it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1149/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1149/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1149/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1149/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1148] due to args.save_total_limit
{'eval_loss': 3.108558416366577, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5255, 'eval_samples_per_second': 114.179, 'eval_steps_per_second': 5.709, 'epoch': 95.83}
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 1150/1200 [56:57<02:27,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 1150/1200 [56:58<02:27,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1150
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1150/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1150/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1150/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1150/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1149] due to args.save_total_limit
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 1151/1200 [57:00<02:25,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 1151/1200 [57:01<02:25,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1151
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1151/config.json
{'eval_loss': 3.113574504852295, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5167, 'eval_samples_per_second': 116.113, 'eval_steps_per_second': 5.806, 'epoch': 95.92}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1151/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1151/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1151/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1150] due to args.save_total_limit
{'eval_loss': 3.118929386138916, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.725, 'eval_steps_per_second': 5.886, 'epoch': 96.0}
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 1152/1200 [57:03<02:27,  3.08s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 1152/1200 [57:04<02:27,  3.08s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1152
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1152/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1152/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1152/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1152/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1151] due to args.save_total_limit
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 1153/1200 [57:06<02:23,  3.05s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.58it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1153/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1153/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1153/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1153/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1152] due to args.save_total_limit
{'eval_loss': 3.1281607151031494, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5145, 'eval_samples_per_second': 116.618, 'eval_steps_per_second': 5.831, 'epoch': 96.17}
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏     | 1154/1200 [57:09<02:18,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏     | 1154/1200 [57:10<02:18,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1154
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1154/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1154/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1154/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1154/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1153] due to args.save_total_limit
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 1155/1200 [57:12<02:15,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 1155/1200 [57:13<02:15,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1155
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1155/config.json
{'eval_loss': 3.131929636001587, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5118, 'eval_samples_per_second': 117.237, 'eval_steps_per_second': 5.862, 'epoch': 96.25}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1155/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1155/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1155/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1154] due to args.save_total_limit
{'eval_loss': 3.1346113681793213, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5146, 'eval_samples_per_second': 116.589, 'eval_steps_per_second': 5.829, 'epoch': 96.33}
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 1156/1200 [57:15<02:11,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 1156/1200 [57:16<02:11,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1156
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1156/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1156/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1156/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1156/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1155] due to args.save_total_limit
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌     | 1157/1200 [57:18<02:08,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌     | 1157/1200 [57:19<02:08,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1157
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1157/config.json
{'eval_loss': 3.1377341747283936, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5123, 'eval_samples_per_second': 117.129, 'eval_steps_per_second': 5.856, 'epoch': 96.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1157/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1157/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1157/special_tokens_map.json
{'eval_loss': 3.1440179347991943, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5104, 'eval_samples_per_second': 117.546, 'eval_steps_per_second': 5.877, 'epoch': 96.5}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1156] due to args.save_total_limit
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 1158/1200 [57:21<02:04,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 1158/1200 [57:22<02:04,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1158
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1158/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1158/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1158/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1158/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1157] due to args.save_total_limit
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 1159/1200 [57:24<02:02,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 1159/1200 [57:25<02:02,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1159
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1159/config.json
{'eval_loss': 3.1495792865753174, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5161, 'eval_samples_per_second': 116.252, 'eval_steps_per_second': 5.813, 'epoch': 96.58}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1159/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1159/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1159/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1158] due to args.save_total_limit
{'eval_loss': 3.154499053955078, 'eval_f1': 0.5521203830369357, 'eval_runtime': 0.5108, 'eval_samples_per_second': 117.456, 'eval_steps_per_second': 5.873, 'epoch': 96.67}
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 1160/1200 [57:27<01:58,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 1160/1200 [57:28<01:58,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1160
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1160/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1160/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1160/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1160/special_tokens_map.json
{'eval_loss': 3.159034013748169, 'eval_f1': 0.5710594315245477, 'eval_runtime': 0.5165, 'eval_samples_per_second': 116.176, 'eval_steps_per_second': 5.809, 'epoch': 96.75}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1159] due to args.save_total_limit
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 1161/1200 [57:30<01:55,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 1161/1200 [57:31<01:55,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1161
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1161/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1161/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1161/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1161/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1160] due to args.save_total_limit
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 1162/1200 [57:33<01:52,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.163637399673462, 'eval_f1': 0.5710594315245477, 'eval_runtime': 0.511, 'eval_samples_per_second': 117.424, 'eval_steps_per_second': 5.871, 'epoch': 96.83}
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 1162/1200 [57:34<01:52,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1162
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1162/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1162/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1162/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1162/special_tokens_map.json
{'eval_loss': 3.1669375896453857, 'eval_f1': 0.5710594315245477, 'eval_runtime': 0.5112, 'eval_samples_per_second': 117.378, 'eval_steps_per_second': 5.869, 'epoch': 96.92}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1161] due to args.save_total_limit
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 1163/1200 [57:36<01:49,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 1163/1200 [57:37<01:49,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1163
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1163/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1163/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1163/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1163/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1162] due to args.save_total_limit
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 1164/1200 [57:39<01:50,  3.08s/it]
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 1164/1200 [57:39<01:50,  3.08s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 1164/1200 [57:40<01:50,  3.08s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1164
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1164/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1164/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1164/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1164/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1163] due to args.save_total_limit
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 1165/1200 [57:42<01:46,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 1165/1200 [57:43<01:46,  3.04s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1165
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1165/config.json
{'eval_loss': 3.17270827293396, 'eval_f1': 0.5710594315245477, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.792, 'eval_steps_per_second': 5.89, 'epoch': 97.08}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1165/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1165/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1165/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1164] due to args.save_total_limit
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 1166/1200 [57:45<01:42,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1166/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1166/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1166/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1166/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1165] due to args.save_total_limit
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 1167/1200 [57:48<01:39,  3.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 1167/1200 [57:49<01:39,  3.02s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1167
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1167/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1167/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1167/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1167/special_tokens_map.json
{'eval_loss': 3.1795449256896973, 'eval_f1': 0.5710594315245477, 'eval_runtime': 0.5093, 'eval_samples_per_second': 117.813, 'eval_steps_per_second': 5.891, 'epoch': 97.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1166] due to args.save_total_limit
 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 1168/1200 [57:51<01:36,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1168/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1168/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1168/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1168/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1167] due to args.save_total_limit
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 1169/1200 [57:54<01:32,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 1169/1200 [57:55<01:32,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1169
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1169/config.json
{'eval_loss': 3.186912775039673, 'eval_f1': 0.5710594315245477, 'eval_runtime': 0.5159, 'eval_samples_per_second': 116.297, 'eval_steps_per_second': 5.815, 'epoch': 97.42}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1169/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1169/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1169/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1168] due to args.save_total_limit
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 1170/1200 [57:57<01:28,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1170/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1170/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1170/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1170/special_tokens_map.json
{'eval_loss': 3.1922826766967773, 'eval_f1': 0.5710594315245477, 'eval_runtime': 0.5153, 'eval_samples_per_second': 116.435, 'eval_steps_per_second': 5.822, 'epoch': 97.58}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1169] due to args.save_total_limit
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 1171/1200 [58:00<01:25,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 1171/1200 [58:01<01:25,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1171
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1171/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1171/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1171/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1171/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1170] due to args.save_total_limit
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 1172/1200 [58:03<01:22,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.53it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1172/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1172/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1172/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1172/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1171] due to args.save_total_limit
{'eval_loss': 3.1943013668060303, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5207, 'eval_samples_per_second': 115.228, 'eval_steps_per_second': 5.761, 'epoch': 97.75}
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 1173/1200 [58:06<01:19,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 1173/1200 [58:07<01:19,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1173
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1173/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1173/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1173/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1173/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1172] due to args.save_total_limit
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 1174/1200 [58:09<01:16,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 1174/1200 [58:09<01:16,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1174
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1174/config.json
{'eval_loss': 3.1947238445281982, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5116, 'eval_samples_per_second': 117.27, 'eval_steps_per_second': 5.863, 'epoch': 97.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1174/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1174/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1174/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1173] due to args.save_total_limit
{'eval_loss': 3.1930813789367676, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5095, 'eval_samples_per_second': 117.763, 'eval_steps_per_second': 5.888, 'epoch': 97.92}
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 1175/1200 [58:12<01:16,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 1175/1200 [58:13<01:16,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1175
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1175/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1175/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1175/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1175/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1174] due to args.save_total_limit
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉   | 1176/1200 [58:15<01:12,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉   | 1176/1200 [58:16<01:12,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1176
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1176/config.json
{'eval_loss': 3.191538095474243, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.479, 'eval_steps_per_second': 5.874, 'epoch': 98.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1176/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1176/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1176/special_tokens_map.json
{'eval_loss': 3.188490867614746, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5094, 'eval_samples_per_second': 117.794, 'eval_steps_per_second': 5.89, 'epoch': 98.08}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1175] due to args.save_total_limit
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 1177/1200 [58:18<01:08,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 1177/1200 [58:19<01:08,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1177
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1177/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1177/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1177/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1177/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1176] due to args.save_total_limit
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 1178/1200 [58:21<01:05,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 1178/1200 [58:22<01:05,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1178
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1178/config.json
{'eval_loss': 3.18658709526062, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5107, 'eval_samples_per_second': 117.485, 'eval_steps_per_second': 5.874, 'epoch': 98.17}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1178/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1178/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1178/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1177] due to args.save_total_limit
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎  | 1179/1200 [58:24<01:04,  3.09s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎  | 1179/1200 [58:25<01:04,  3.09s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1179
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1179/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1179/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1179/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1179/special_tokens_map.json
{'eval_loss': 3.18509840965271, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5092, 'eval_samples_per_second': 117.821, 'eval_steps_per_second': 5.891, 'epoch': 98.25}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1178] due to args.save_total_limit
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 1180/1200 [58:27<01:00,  3.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 2/3 [00:00<00:00, 11.57it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1180/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1180/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1180/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1180/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1179] due to args.save_total_limit
{'eval_loss': 3.1839191913604736, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.434, 'eval_steps_per_second': 5.872, 'epoch': 98.42}
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌  | 1181/1200 [58:30<00:57,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌  | 1181/1200 [58:31<00:57,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1181
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1181/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1181/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1181/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1181/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1180] due to args.save_total_limit
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 1182/1200 [58:33<00:53,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 1182/1200 [58:34<00:53,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1182
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1182/config.json
{'eval_loss': 3.184044361114502, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5097, 'eval_samples_per_second': 117.718, 'eval_steps_per_second': 5.886, 'epoch': 98.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1182/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1182/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1182/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1181] due to args.save_total_limit
{'eval_loss': 3.18363881111145, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5184, 'eval_samples_per_second': 115.731, 'eval_steps_per_second': 5.787, 'epoch': 98.58}
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 1183/1200 [58:36<00:50,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 1183/1200 [58:37<00:50,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1183
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1183/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1183/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1183/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1183/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1182] due to args.save_total_limit
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 1184/1200 [58:39<00:47,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 1184/1200 [58:40<00:47,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1184
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1184/config.json
{'eval_loss': 3.183802843093872, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5136, 'eval_samples_per_second': 116.815, 'eval_steps_per_second': 5.841, 'epoch': 98.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1184/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1184/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1184/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1183] due to args.save_total_limit
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 1185/1200 [58:42<00:44,  2.96s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.184267997741699, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5128, 'eval_samples_per_second': 117.012, 'eval_steps_per_second': 5.851, 'epoch': 98.75}
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 1185/1200 [58:43<00:44,  2.96s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1185
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1185/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1185/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1185/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1185/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1184] due to args.save_total_limit
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ | 1186/1200 [58:45<00:42,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ | 1186/1200 [58:46<00:42,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1186
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1186/config.json
{'eval_loss': 3.18499493598938, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5147, 'eval_samples_per_second': 116.57, 'eval_steps_per_second': 5.828, 'epoch': 98.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1186/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1186/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1186/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1185] due to args.save_total_limit
{'eval_loss': 3.1851437091827393, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5138, 'eval_samples_per_second': 116.773, 'eval_steps_per_second': 5.839, 'epoch': 98.92}
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 1187/1200 [58:48<00:39,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 1187/1200 [58:49<00:39,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1187
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1187/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1187/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1187/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1187/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1186] due to args.save_total_limit
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 1188/1200 [58:51<00:35,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 1188/1200 [58:52<00:35,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1188
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1188/config.json
{'eval_loss': 3.1852328777313232, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5101, 'eval_samples_per_second': 117.628, 'eval_steps_per_second': 5.881, 'epoch': 99.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1188/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1188/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1188/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1187] due to args.save_total_limit
{'eval_loss': 3.185436487197876, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5102, 'eval_samples_per_second': 117.593, 'eval_steps_per_second': 5.88, 'epoch': 99.08}
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 1189/1200 [58:54<00:32,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 1189/1200 [58:55<00:32,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1189
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1189/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1189/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1189/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1189/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1188] due to args.save_total_limit
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 1190/1200 [58:57<00:29,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 1190/1200 [58:58<00:29,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1190
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1190/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1190/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1190/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1190/special_tokens_map.json
{'eval_loss': 3.185608386993408, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5162, 'eval_samples_per_second': 116.24, 'eval_steps_per_second': 5.812, 'epoch': 99.17}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1189] due to args.save_total_limit
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 1191/1200 [59:00<00:27,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
{'eval_loss': 3.186243772506714, 'eval_f1': 0.5658773291925466, 'eval_runtime': 0.5179, 'eval_samples_per_second': 115.851, 'eval_steps_per_second': 5.793, 'epoch': 99.25}
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 1191/1200 [59:01<00:27,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1191
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1191/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1191/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1191/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1191/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1190] due to args.save_total_limit
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 1192/1200 [59:03<00:23,  3.00s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 1192/1200 [59:04<00:23,  3.00s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1192
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1192/config.json
{'eval_loss': 3.1858010292053223, 'eval_f1': 0.5658773291925466, 'eval_runtime': 0.5103, 'eval_samples_per_second': 117.571, 'eval_steps_per_second': 5.879, 'epoch': 99.33}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1192/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1192/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1192/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1191] due to args.save_total_limit
{'eval_loss': 3.1854238510131836, 'eval_f1': 0.5658773291925466, 'eval_runtime': 0.5109, 'eval_samples_per_second': 117.436, 'eval_steps_per_second': 5.872, 'epoch': 99.42}
 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 1193/1200 [59:06<00:20,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 1193/1200 [59:07<00:20,  2.97s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1193
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1193/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1193/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1193/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1193/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1192] due to args.save_total_limit
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 1194/1200 [59:09<00:18,  3.07s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 1194/1200 [59:10<00:18,  3.07s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1194
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1194/config.json
{'eval_loss': 3.184758424758911, 'eval_f1': 0.5658773291925466, 'eval_runtime': 0.5091, 'eval_samples_per_second': 117.844, 'eval_steps_per_second': 5.892, 'epoch': 99.5}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1194/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1194/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1194/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1193] due to args.save_total_limit
{'eval_loss': 3.1841771602630615, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5099, 'eval_samples_per_second': 117.68, 'eval_steps_per_second': 5.884, 'epoch': 99.58}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 1195/1200 [59:12<00:15,  3.03s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 1195/1200 [59:13<00:15,  3.03s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1195
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1195/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1195/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1195/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1195/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1194] due to args.save_total_limit
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 1196/1200 [59:15<00:12,  3.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 1196/1200 [59:16<00:12,  3.01s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1196
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1196/config.json
{'eval_loss': 3.183183193206787, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5167, 'eval_samples_per_second': 116.122, 'eval_steps_per_second': 5.806, 'epoch': 99.67}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1196/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1196/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1196/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1195] due to args.save_total_limit
{'eval_loss': 3.1823647022247314, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5106, 'eval_samples_per_second': 117.507, 'eval_steps_per_second': 5.875, 'epoch': 99.75}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 1197/1200 [59:18<00:08,  2.99s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 1197/1200 [59:19<00:08,  2.99s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1197
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1197/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1197/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1197/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1197/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1196] due to args.save_total_limit
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 1198/1200 [59:21<00:05,  2.98s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 1198/1200 [59:22<00:05,  2.98s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1198
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1198/config.json
{'eval_loss': 3.181823253631592, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5135, 'eval_samples_per_second': 116.854, 'eval_steps_per_second': 5.843, 'epoch': 99.83}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1198/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1198/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1198/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1197] due to args.save_total_limit
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 1199/1200 [59:24<00:02,  2.97s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
  0%|                                                                                                                                                                     | 0/3 [00:00<?, ?it/s]
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1199/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1199/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1199/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1199/special_tokens_map.json
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1198] due to args.save_total_limit
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [59:27<00:00,  2.95s/it]The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 60
  Batch size = 5
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [59:28<00:00,  2.95s/it]Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1200
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1200/config.json
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1200/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1200/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-1200/special_tokens_map.json
{'eval_loss': 3.1814029216766357, 'eval_f1': 0.5864550264550265, 'eval_runtime': 0.5127, 'eval_samples_per_second': 117.037, 'eval_steps_per_second': 5.852, 'epoch': 100.0}
Deleting older checkpoint [/home/ravi/raviProject/DataModelsResults/Results/OpenAIGPT2_1/checkpoint-1199] due to args.save_total_limit
Training completed. Do not forget to share your model on huggingface.co/models =)
Loading best model from /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/checkpoint-143 (score: 1.0546271800994873).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [59:30<00:00,  2.98s/it]
2024-04-10 00:04:13,926 | Transformers_model.py: 355: Transformers_train() | INFO: ========Saving Model=========
Saving model checkpoint to /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/
Configuration saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/config.json
{'train_runtime': 3572.8593, 'train_samples_per_second': 6.717, 'train_steps_per_second': 0.336, 'train_loss': 0.3839105780919393, 'epoch': 100.0}
Model weights saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/pytorch_model.bin
tokenizer config file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/tokenizer_config.json
Special tokens file saved in /home/ravi/raviProject/DataModelsResults//Results/OpenAIGPT2_1/special_tokens_map.json
2024-04-10 00:04:14,703 | Transformers_model.py: 359: Transformers_train() | INFO: train time 3577.6972291469574 seconds
2024-04-10 00:04:14,711 | transformersMain.py: 134: <module>() | INFO: Execution time 3577.705319404602 seconds